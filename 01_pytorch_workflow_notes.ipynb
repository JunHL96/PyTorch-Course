{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHL96/PyTorch-Course/blob/main/01_pytorch_workflow_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GAuU1xbkS1"
      },
      "source": [
        "# 01. PyTorch Workflow\n",
        "\n",
        "Let's explore an example of a PyTorch end-to-end workflow\n",
        "\n",
        "* Ground truth notebook: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow\n",
        "* Book version of notebook: https://github.com/mrdbourke/pytorch-deep-learning-book/blob/main/01_pytorch_workflow\n",
        "* Ask a question: https://github.com/mrdbourke/pytorch-deep-learning/discussions\n",
        "\n",
        "## Example Workflow:\n",
        "\n",
        "1. Get data ready (turn into tensors)\n",
        "2. Build or pick a pretrained model (to suit your problem)\n",
        "* 2.1) Pick a loss function & optimizer\n",
        "* 2.2) Build a training loop\n",
        "* 2.3) Repeat step 2 until ready to move to step 3\n",
        "3. Fit the model to the data and make a prediction\n",
        "4. Evaluate the model\n",
        "5. Improve through experimentation\n",
        "6. Save and reload your trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I7hBhz9bkS4",
        "outputId": "89383e3f-1e7f-4cba-d7d1-f8a059589aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 2.5.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"Pytorch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIjSPKTnbkS6",
        "outputId": "c677a84d-d8fc-4a19-f505-1df66615641f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Setup device-agnostic code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl-4yhy5bkS6",
        "outputId": "02f03421-a03c-4135-f5dc-4eb519feef04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'data (prepare and load)',\n",
              " 2: 'build model',\n",
              " 3: 'fitting the model to data (training)',\n",
              " 4: 'making predictions and evaluating a model (inference)',\n",
              " 5: 'saving and loading a model',\n",
              " 6: 'putting it all together'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "what_we_are_covering = {1: \"data (prepare and load)\",\n",
        "                        2: \"build model\",\n",
        "                        3: \"fitting the model to data (training)\",\n",
        "                        4: \"making predictions and evaluating a model (inference)\",\n",
        "                        5: \"saving and loading a model\",\n",
        "                        6: \"putting it all together\"}\n",
        "\n",
        "what_we_are_covering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d33dknIQbkS6"
      },
      "source": [
        "## 1. Data (preparing and loading)\n",
        "\n",
        "Data can be almost everything in ML:\n",
        "* Excel spreadsheet\n",
        "* Images of any kind\n",
        "* Videos (YouTube has lots of data)\n",
        "* Audio (Songs, podcasts, etc.)\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "ML is a game of two parts:\n",
        "1. Get data into a numerical representation\n",
        "2. Build a model to learn patterns in that numerical representation.\n",
        "\n",
        "![machine learning is a game of two parts: 1. turn your data into a representative set of numbers and 2. build or pick a model to learn the representation as best as possible](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-machine-learning-a-game-of-two-parts.png)\n",
        "\n",
        "To showcase this, let's create some *known* data using the linear regression formula:\n",
        "\n",
        "### Linear Regression Formula\n",
        "\n",
        "Linear regression models the relationship between a dependent variable (target) and one or more independent variables (features). The formula is:\n",
        "\n",
        "**y = β<sub>0</sub> + β<sub>1</sub>x<sub>1</sub> + β<sub>2</sub>x<sub>2</sub> + ... + β<sub>n</sub>x<sub>n</sub> + ε**\n",
        "\n",
        "- **y**: The predicted output (dependent variable).\n",
        "- **β<sub>0</sub>**: The intercept (constant term).\n",
        "- **β<sub>1</sub>, β<sub>2</sub>, ..., β<sub>n</sub>**: Coefficients representing the impact of each independent variable (x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>).\n",
        "- **x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>**: Independent variables (features).\n",
        "- **ε**: Error term (difference between predicted and actual values).\n",
        "\n",
        "In simple linear regression (one feature), the formula simplifies to:\n",
        "\n",
        "**y = β<sub>0</sub> + β<sub>1</sub>x + ε**\n",
        "\n",
        "We'll use a linear regression formula to make a straight line with *known* **parameters**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raf-oKirbkS7",
        "outputId": "bd00b451-1064-423b-a5da-ed0c90cd2d2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Create *known* parameters for linear regression\n",
        "# The weight determines how much influence the input feature x has on the output y.\n",
        "weight = 0.7  # The slope (coefficient) of the line (β₁ in y = β₀ + β₁x)\n",
        "# The bias adjusts the output independently of the input x.\n",
        "bias = 0.3    # The intercept (constant) of the line (β₀ in y = β₀ + β₁x)\n",
        "\n",
        "# Create input data (X) for linear regression\n",
        "start = 0     # Starting value of X (independent variable)\n",
        "end = 1       # Ending value of X\n",
        "step = 0.02   # Step size for generating values of X (i.e., increments of 0.02)\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "# torch.arange creates a range of values from 0 to 1 (exclusive) with step size of 0.02\n",
        "# unsqueeze adds a dimension to the tensor (makes it a column vector). This is important to do for later on when we work with models\n",
        "\n",
        "# Generate target values (y) using the linear regression formula\n",
        "y = weight * X + bias  # This simulates a linear relationship between X and y (y = β₀ + β₁x)\n",
        "\n",
        "# Output the first 10 values of X and y (input and output #s)\n",
        "X[:10], y[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_fAMvBVbkS7",
        "outputId": "2a6f91e8-116c-49e4-f5a1-655c00f1ad77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(X), len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfMPavexbkS7"
      },
      "source": [
        "### Splitting data into training and test sets (one of the most important concepts in ML in general)\n",
        "\n",
        "| Split | Purpose | Amount of total data | How often is it used? |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **Training set** | The model learns from this data (like the course materials you study during the semester). | ~60-80% | Always |\n",
        "| **Validation set** | The model gets tuned on this data (like the practice exam you take before the final exam). | ~10-20% | Often but not always |\n",
        "| **Testing set** | The model gets evaluated on this data to test what it has learned (like the final exam you take at the end of the semester). | ~10-20% | Always |\n",
        "\n",
        "**Goal**: Generalization - The ability for a ML model to perform well on data it hasn't seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VONksApZbkS7",
        "outputId": "5cd66157-4977-4d04-b95c-3f9902eaafd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Create a train/test split\n",
        "\n",
        "# Calculate the index to split the data (80% for training, 20% for testing)\n",
        "train_split = int(0.8 * len(X))  # 80% of the length of the dataset will be for training\n",
        "train_split  # This variable holds the index for splitting the data\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, y_train = X[:train_split], y[:train_split]  # The first 80% of X and y for training\n",
        "X_test, y_test = X[train_split:], y[train_split:]    # The remaining 20% of X and y for testing\n",
        "\n",
        "# Output the lengths of the training and testing sets for verification (training split + test split))\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azXga9cfbkS8"
      },
      "source": [
        "How might we better visualize our data?\n",
        "\n",
        "This is where the data explorer's motto comes in!\n",
        "\n",
        "\"Visualize, visualize, visualize!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": false,
        "id": "hrKIq6AZbkS8"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "    \"\"\"\n",
        "    Plots training data, test data, and compares predictions if provided.\n",
        "\n",
        "    Parameters:\n",
        "    - train_data: The input features for training data (X_train).\n",
        "    - train_labels: The corresponding target values for training data (y_train).\n",
        "    - test_data: The input features for test data (X_test).\n",
        "    - test_labels: The corresponding target values for test data (y_test).\n",
        "    - predictions: The predicted values (optional) for the test data.\n",
        "    \"\"\"\n",
        "\n",
        "    # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
        "\n",
        "    # Plot training data in blue\n",
        "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "    # `plt.scatter` creates a scatter plot for the training data (X_train, y_train) in blue (c=\"b\").\n",
        "    # `s=4` sets the size of the points to 4, and `label` adds a legend entry for the training data.\n",
        "\n",
        "    # Plot test data in green\n",
        "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Test data\")\n",
        "    # Similarly, test data (X_test, y_test) is plotted in green (c=\"g\") with a legend entry for the test data.\n",
        "\n",
        "    # Plot predictions in red if they exist\n",
        "    if predictions is not None:\n",
        "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "        # If predictions are provided, they are plotted in red (c=\"r\").\n",
        "        # This shows how the predicted values compare to the actual test data.\n",
        "\n",
        "    # Plot a line of best fit (if predictions exist)\n",
        "    if predictions is not None:\n",
        "        plt.plot(test_data, predictions, c=\"r\", label=\"Line of best fit\")\n",
        "        # `plt.plot` creates a line of best fit using the test data and the predictions.\n",
        "        # This red line represents the linear relationship the model has learned.\n",
        "\n",
        "     # Add legend and labels\n",
        "    plt.legend(prop={\"size\": 14})  # Displays the legend with font size 14 to differentiate training, test data, and predictions.\n",
        "\n",
        "    plt.xlabel(\"X\")  # Labels the x-axis as \"X\" (the input feature).\n",
        "\n",
        "    plt.ylabel(\"y\")  # Labels the y-axis as \"y\" (the target/output variable).\n",
        "\n",
        "    # The final plot will show:\n",
        "    # - Training data in blue\n",
        "    # - Test data in green\n",
        "    # - Predictions and line of best fit (if provided) in red\n",
        "    # With a larger, clearer legend to distinguish between these elements.\n",
        "\n",
        "\n",
        "    # The final plot will show training data in blue, test data in green, and, if provided, predictions and the line of best fit in red.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8z3q1mvNbkS8",
        "outputId": "a1cdeae0-f73b-47ac-bc9b-da518e119504"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_predictions();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC2u6K62bkS8"
      },
      "source": [
        "## 2. Build Model\n",
        "\n",
        "Now that we've got some data, let's build a model to use the blue dots to predict the green dots.\n",
        "\n",
        "This is where we will need OOP.\n",
        "\n",
        "### What our model does (in the code below):\n",
        "* Start with random values (weight & bias)\n",
        "* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight and bias values we used to create the data).\n",
        "\n",
        "### How does it work?\n",
        "Through two main algorithms:\n",
        "\n",
        "1. **Gradient Descent**:\n",
        "   - **Goal**: Gradient descent is an optimization algorithm that helps adjust the model’s parameters (weights and biases) to minimize a **loss function** (which tells us how far off our predictions are from the actual data). The lower the loss, the better the model is performing.\n",
        "   - **Process**:\n",
        "     1. **Start with random values**: The model begins with random values for its weights and biases.\n",
        "     2. **Calculate the loss**: For every prediction the model makes, compare it to the actual data using a loss function like **Mean Squared Error (MSE)**. MSE measures how far the predicted values are from the actual values.\n",
        "     3. **Compute the gradient**: In math, gradient is a slope that is the change in y over change in x. In ML, the gradient is a vector that is measure of how much the loss will change if you adjust each weight and bias. Gradients point in the direction of increasing loss, so by following the opposite direction, we can reduce the loss.\n",
        "     4. **Update parameters**: The model's weights and biases are updated by a small amount in the direction that reduces the loss. This process is repeated until the model's parameters settle at values that minimize the error.\n",
        "     - **Key Idea**: We want to reduce the error between the predicted and actual values, so the weights and biases are adjusted iteratively by using gradients to guide those adjustments.\n",
        "   \n",
        "2. **Backpropagation**:\n",
        "   - **Goal**: Backpropagation computes how much each parameter (weight and bias) contributed to the overall error (loss), so the model knows exactly how to adjust them.\n",
        "   - **Process**:\n",
        "     1. **Forward pass**: Input data passes through the network, layer by layer, and the model makes a prediction using the current weights and biases.\n",
        "     2. **Calculate the loss**: The model compares the prediction to the actual data using the loss function (e.g., MSE) to determine how far off the prediction was.\n",
        "     3. **Backward pass (Backpropagation)**: The loss is then “propagated backward” through the network by calculating how much each weight and bias influenced the loss. This is done using the **chain rule** from calculus, which breaks the error into pieces that allow the model to understand the impact of each parameter.\n",
        "     4. **Gradient computation**: Backpropagation computes the gradient (or slope) of the loss function with respect to each parameter in the network, starting from the output layer and moving backward to the input layer.\n",
        "     5. **Update parameters**: These gradients are then used by gradient descent to update the weights and biases in a way that reduces the error for the next prediction.\n",
        "\n",
        "   - **Key Idea**: Backpropagation helps calculate the gradients needed to update each weight and bias by understanding how each one contributed to the error. This is critical for making the model learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": false,
        "id": "TlRRZcXxbkS8"
      },
      "outputs": [],
      "source": [
        "# Create a linear regression model class inheriting from nn.Module (the base class for all neural network modules)\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    # Constructor method for the class. It's called when a new instance of the class is created.\n",
        "    def __init__(self):\n",
        "        # super will call the __init__ method of the parent class (nn.Module) to ensure that all its functionality is initialized\n",
        "        super().__init__()\n",
        "        # Define the weights parameter initialized randomly with requires_grad=True to compute gradients for optimization\n",
        "        self.weight = nn.Parameter(torch.randn(1, # start with a random weight and try to adjust it to the ideal weight\n",
        "                                                requires_grad=True, # This is true by default so we don't need to explicitly set it True here\n",
        "                                                dtype=torch.float))  # <- This is float32 by default so we don't need to explicitly set it like this here\n",
        "\n",
        "        # Define the bias parameter initialized randomly with requires_grad=True to compute gradients\n",
        "        self.bias = nn.Parameter(torch.randn(1, # start with a random bias and try to adjust it to the ideal bias\n",
        "                                             requires_grad=True,\n",
        "                                             dtype=torch.float))\n",
        "\n",
        "    # Forward method defines how input data x is transformed to produce the output data\n",
        "    # Implements the forward pass, where 'x' is an input tensor and the output is a processed tensor, both of type torch.Tensor.\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Apply the linear regression formula y = wx + b\n",
        "        return self.weight * x + self.bias\n",
        "\n",
        "# The goal is to start with random weights and biases, run it through the forward pass,\n",
        "# and then update the weights and biases to represent the known parameters (currently 0.7 and 0.3) as closely as possible\n",
        "# Through an algorithm called gradient descent, this is achieved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDWg1sNBbkS8"
      },
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "PyTorch has four (give or take) essential modules you can use to create almost any kind of neural network you can imagine.\n",
        "\n",
        "They are [`torch.nn`](https://pytorch.org/docs/stable/nn.html), [`torch.optim`](https://pytorch.org/docs/stable/optim.html), [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html). For now, we'll focus on the first two and get to the other two later (though you may be able to guess what they do).\n",
        "\n",
        "| PyTorch module | What does it do? |\n",
        "| ----- | ----- |\n",
        "| [`torch.nn`](https://pytorch.org/docs/stable/nn.html) | Contains all of the building blocks for computational graphs (essentially a series of computations executed in a particular way). |\n",
        "| [`torch.nn.Parameter`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter) | This is a special kind of tensor that is specifically designed to be used as part of the learnable parameters in a neural network. It essentially stores tensors that can be used with `nn.Module`. If `requires_grad=True` gradients (used for updating model parameters via [**gradient descent**](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html))  are calculated automatically, this is often referred to as \"autograd\".  |\n",
        "| [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) | The base class for all neural network modules, all the building blocks for neural networks are subclasses. If you're building a neural network in PyTorch, your models should subclass `nn.Module`. Requires a `forward()` method be implemented. |\n",
        "| [`torch.optim`](https://pytorch.org/docs/stable/optim.html) | Contains various optimization algorithms (these tell the model parameters stored in `nn.Parameter` how to best change to improve gradient descent and in turn reduce the loss). |\n",
        "| `def forward()` | All `nn.Module` subclasses require a `forward()` method, this defines the computation that will take place on the data passed to the particular `nn.Module` (e.g. the linear regression formula above). |\n",
        "\n",
        "If the above sounds complex, think of like this, almost everything in a PyTorch neural network comes from `torch.nn`,\n",
        "* `nn.Module` contains the larger building blocks (layers)\n",
        "* `nn.Parameter` contains the smaller parameters like weights and biases (put these together to make `nn.Module`(s))\n",
        "* `forward()` tells the larger blocks how to make calculations on inputs (tensors full of data) within  `nn.Module`(s)\n",
        "* `torch.optim` contains optimization methods on how to improve the parameters within `nn.Parameter` to better represent input data\n",
        "\n",
        "![a pytorch linear model with annotations](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-linear-model-annotated.png)\n",
        "*Basic building blocks of creating a PyTorch model by subclassing `nn.Module`. For objects that subclass `nn.Module`, the `forward()` method must be defined.*\n",
        "\n",
        "> **Resource:** See more of these essential modules and their use cases in the [PyTorch Cheat Sheet](https://pytorch.org/tutorials/beginner/ptcheat.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utX4IlOpbkS9"
      },
      "source": [
        "### Checking the contents of our PyTorch model\n",
        "\n",
        "Now that we've created a model, let's see what is inside\n",
        "\n",
        "We can check out our model parameters using `.parameters()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdFRQRr8bkS9",
        "outputId": "2fb22e39-8a77-4016-be35-8677d0906909"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Set a fixed seed for reproducibility (ensures the same random numbers are generated each time)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Instantiate the linear regression model (this creates an instance with random weight and bias)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Retrieve the list of parameters (weights and biases) of the model for inspection\n",
        "list(model_0.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6bTg84dbkS9"
      },
      "source": [
        "We can also get the state (what the model contains) of the model using [`.state_dict()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5XQOUKibkS9",
        "outputId": "2cdbf5fe-9b8f-4472-9d0a-0e22a086caa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# List named parameters and their corresponding values\n",
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycy9QHEzbkS9"
      },
      "source": [
        "\n",
        "Notice how the values for `weights` and `bias` from `model_0.state_dict()` come out as random float tensors?\n",
        "\n",
        "This is because we initialized them above using `torch.randn()`.\n",
        "\n",
        "Essentially we want to start from random parameters and get the model to update them towards parameters that fit our data best (the hardcoded `weight` and `bias` values we set when creating our straight line data). In this case, that would be 0.7 and 0.3 for weight and bias respectively.\n",
        "\n",
        "> **Exercise:** Try changing the `torch.manual_seed()` value two cells above, see what happens to the weights and bias values.\n",
        "\n",
        "Because our model starts with random values, right now it'll have poor predictive power.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2sIuY7BbkS9"
      },
      "source": [
        "### Making predictions with using `torch.inference_mode()`\n",
        "\n",
        "To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`.\n",
        "\n",
        "When we pass data to our model, it will go through the model's `forward()` method and produce a result using the computation we've defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7O6oddmbkS9",
        "outputId": "5be68090-fa93-4e4e-8762-07e2d4057761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8000],\n",
              "         [0.8200],\n",
              "         [0.8400],\n",
              "         [0.8600],\n",
              "         [0.8800],\n",
              "         [0.9000],\n",
              "         [0.9200],\n",
              "         [0.9400],\n",
              "         [0.9600],\n",
              "         [0.9800]]),\n",
              " tensor([[0.8600],\n",
              "         [0.8740],\n",
              "         [0.8880],\n",
              "         [0.9020],\n",
              "         [0.9160],\n",
              "         [0.9300],\n",
              "         [0.9440],\n",
              "         [0.9580],\n",
              "         [0.9720],\n",
              "         [0.9860]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_test, y_test\n",
        "# An ideal model will input X_test and output y_test values exactly, i.e., the model should have no error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvRLguRebkS9",
        "outputId": "6420e0f7-4fee-49d4-b489-3b8ad783dfa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3982],\n",
              "        [0.4049],\n",
              "        [0.4116],\n",
              "        [0.4184],\n",
              "        [0.4251],\n",
              "        [0.4318],\n",
              "        [0.4386],\n",
              "        [0.4453],\n",
              "        [0.4520],\n",
              "        [0.4588]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "    y_pred = model_0(X_test) # we pass the X_test data through our model\n",
        "\n",
        "# Note that inference mode temporarily disables autograd, which can speed up prediction computations\n",
        "\n",
        "# Inference mode is preferred over no_grad mode because it saves memory and speeds up computations, especially when dealing with large datasets.\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "uNIqUf0SbkS9",
        "outputId": "6150069a-267e-4b24-c33d-f30840d15ef0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_predictions(predictions=y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGMFjIZVbkS9"
      },
      "source": [
        "Currently, our model is making random predictions that are far from where our data actually lies. This is because we haven't trained our model yet.\n",
        "\n",
        "Right now, our model is making predictions using random parameters to make calculations (random guessing). It's not looking at the blue dots to predict the green dots at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2m7cTbmbkS9"
      },
      "source": [
        "## 3. Train Model\n",
        "\n",
        "Right now, our model is making prediction using random parameters to make calculations. It is basically guessing randomly.\n",
        "\n",
        "We could attempt to hard-code the ideal values, but most of the time we would not know what the ideal parameters are for a model.\n",
        "\n",
        "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters i.e. from a poor representation of the data to a better representation of the data.\n",
        "\n",
        "One way to measure how inaccurate or how wrong your model's predictions are is to use a loss function.\n",
        "\n",
        "### Creating a loss function and optimizer in PyTorch\n",
        "\n",
        "| Function | What does it do? | Where does it live in PyTorch? | Common values |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **Loss function** | Measures how wrong your model's predictions (e.g. `y_pred`) are compared to the truth labels (e.g. `y_test`). Lower the better. | PyTorch has plenty of built-in loss functions in [`torch.nn`](https://pytorch.org/docs/stable/nn.html#loss-functions). | Mean absolute error (MAE) for regression problems ([`torch.nn.L1Loss()`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html)). Binary cross entropy for binary classification problems ([`torch.nn.BCELoss()`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)).  |\n",
        "| **Optimizer** | Tells your model how to update its internal parameters to best lower the loss. | You can find various optimization function implementations in [`torch.optim`](https://pytorch.org/docs/stable/optim.html). | Stochastic gradient descent ([`torch.optim.SGD()`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)). Adam optimizer ([`torch.optim.Adam()`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)). |\n",
        "\n",
        "Let's create a loss function and an optimizer we can use to help improve our model.\n",
        "\n",
        "Depending on what kind of problem you're working on will depend on what loss function and what optimizer you use.\n",
        "\n",
        "However, there are some common values, that are known to work well such as the SGD (stochastic gradient descent) or Adam optimizer. And the MAE (mean absolute error) loss function for regression problems (predicting a number) or binary cross entropy loss function for classification problems (predicting one thing or another).\n",
        "\n",
        "For our problem, since we're predicting a number, let's use MAE (which is under `torch.nn.L1Loss()`) in PyTorch as our loss function.\n",
        "\n",
        "![what MAE loss looks like for our plot data](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-mae-loss-annotated.png)\n",
        "*Mean absolute error (MAE, in PyTorch: `torch.nn.L1Loss`) measures the absolute difference between two points (predictions and labels) and then takes the mean across all examples.*\n",
        "\n",
        "And we'll use SGD, `torch.optim.SGD(params, lr)` where:\n",
        "\n",
        "* `params` is the target model parameters you'd like to optimize (e.g. the `weights` and `bias` values we randomly set before).\n",
        "* `lr` is the **learning rate** you'd like the optimizer to update the parameters at, higher means the optimizer will try larger updates (these can sometimes be too large and the optimizer will fail to work), lower means the optimizer will try smaller updates (these can sometimes be too small and the optimizer will take too long to find the ideal values). The learning rate is considered a **hyperparameter** (because it's set by a machine learning engineer). Common starting values for the learning rate are `0.01`, `0.001`, `0.0001`, however, these can also be adjusted over time (this is called [learning rate scheduling](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)).\n",
        "\n",
        "\n",
        "### Code Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nTQW9p6WbkS-"
      },
      "outputs": [],
      "source": [
        "# Create a loss function using L1 Loss (MAE), which calculates the absolute differences between predicted and target values\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Create the optimizer using Stochastic Gradient Descent (SGD), with the model's parameters and a learning rate of 0.01\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of the target model to optimize\n",
        "                            lr=0.01) # learning rate: how much the optimizer should change parameters at each step.\n",
        "                                     # higher=more (less stable), lower=less (more stable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOy_5T3-bkS-"
      },
      "source": [
        "### Creating an optimization loop in PyTorch\n",
        "\n",
        "Now that we have a loss function and an optimizer, now we can create a **training loop** (and **testing loop**)\n",
        "\n",
        "The **training loop** involves the model going through the training data and learning the relationships between the `features` and `labels`.\n",
        "\n",
        "The **testing loop** involves evaluating how well the model has learned patterns from the training data by using the testing data, which the model has not seen during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkI4P1lgbkS-"
      },
      "source": [
        "### PyTorch training loop\n",
        "| Number | Step name | What does it do? | Code example |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| 1 | Forward pass | The model goes through all of the training data once, performing its `forward()` function calculations. | `model(x_train)` |\n",
        "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_train)` |\n",
        "| 3 | Zero gradients | The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step. | `optimizer.zero_grad()` |\n",
        "| 4 | Perform backpropagation on the loss | Computes the gradient of the loss with respect for every model parameter to be updated  (each parameter with `requires_grad=True`). This is known as **backpropagation**, hence \"backwards\".  | `loss.backward()` |\n",
        "| 5 | Update the optimizer (**gradient descent**) | Update the parameters with `requires_grad=True` with respect to the loss gradients in order to improve them. | `optimizer.step()` |\n",
        "\n",
        "![pytorch training loop annotated](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-training-loop-annotated.png)\n",
        "\n",
        "> **Note:** The above is just one example of how the steps could be ordered or described. With experience you'll find making PyTorch training loops can be quite flexible.\n",
        ">\n",
        "> And on the ordering of things, the above is a good default order but you may see slightly different orders. Some rules of thumb:\n",
        "> * Calculate the loss (`loss = ...`) *before* performing backpropagation on it (`loss.backward()`).\n",
        "> * Zero gradients (`optimizer.zero_grad()`) *before* computing the gradients of the loss with respect to every model parameter (`loss.backward()`).\n",
        "> * Step the optimizer (`optimizer.step()`) *after* performing backpropagation on the loss (`loss.backward()`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBjCrb8ZbkS-"
      },
      "source": [
        "### PyTorch testing loop\n",
        "\n",
        "As for the testing loop (evaluating our model), the typical steps include:\n",
        "\n",
        "| Number | Step name | What does it do? | Code example |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| 1 | Forward pass | The model goes through all of the testing data once, performing its `forward()` function calculations. | `model(x_test)` |\n",
        "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_test)` |\n",
        "| 3 | Calulate evaluation metrics (optional) | Alongside the loss value you may want to calculate other evaluation metrics such as accuracy on the test set. | Custom functions |\n",
        "\n",
        "Notice the testing loop doesn't contain performing backpropagation (`loss.backward()`) or stepping the optimizer (`optimizer.step()`), this is because no parameters in the model are being changed during testing, they've already been calculated. For testing, we're only interested in the output of the forward pass through the model.\n",
        "\n",
        "![pytorch annotated testing loop](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-testing-loop-annotated.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4pPvbIQbkS-"
      },
      "source": [
        "### What are Loss Values?\n",
        "\n",
        "Loss values are a way to measure how well a machine learning model's predictions match the actual target values. In simple terms, they tell you how far off your model's predictions are from the correct answers.\n",
        "\n",
        "#### Key Points:\n",
        "\n",
        "1. **Quantifying Error**:\n",
        "   The loss function calculates the difference (error) between the model’s predicted output and the actual target (true) output.\n",
        "   - For example, in regression tasks, if the model predicts a value like 20 but the actual value is 25, the loss function measures the size of this error.\n",
        "\n",
        "2. **Single Number**:\n",
        "   The result of this calculation is a single number that represents how poorly or well the model is performing. Lower loss means better performance (i.e., smaller error), and higher loss means worse performance.\n",
        "\n",
        "3. **Training Loss vs. Testing Loss**:\n",
        "   - **Training Loss**: The loss calculated on the training dataset, which the model learns from.\n",
        "   - **Testing Loss**: The loss calculated on the test (or validation) dataset, which is unseen by the model during training. This helps evaluate how well the model generalizes to new data.\n",
        "\n",
        "4. **Loss Function**:\n",
        "   The specific way in which the loss is calculated depends on the type of task. Common loss functions include:\n",
        "   - **Mean Squared Error (MSE)**: Used for regression tasks, it calculates the average squared difference between predicted and actual values.\n",
        "   - **Cross-Entropy Loss**: Used for classification tasks, it measures the difference between predicted probability distributions and actual class labels.\n",
        "\n",
        "In short, **loss values guide the model in learning**. During training, the model adjusts its parameters (weights and biases) to minimize the loss, which improves its predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGb5eI21bkS-",
        "outputId": "f548ce48-65dd-4e62-cfd0-a99440704abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.48106518387794495 \n",
            "Epoch: 10 | MAE Train Loss: 0.1976713240146637 | MAE Test Loss: 0.3463551998138428 \n",
            "Epoch: 20 | MAE Train Loss: 0.08908725529909134 | MAE Test Loss: 0.21729660034179688 \n",
            "Epoch: 30 | MAE Train Loss: 0.053148526698350906 | MAE Test Loss: 0.14464017748832703 \n",
            "Epoch: 40 | MAE Train Loss: 0.04543796554207802 | MAE Test Loss: 0.11360953003168106 \n",
            "Epoch: 50 | MAE Train Loss: 0.04167863354086876 | MAE Test Loss: 0.09919948130846024 \n",
            "Epoch: 60 | MAE Train Loss: 0.03818932920694351 | MAE Test Loss: 0.08886633068323135 \n",
            "Epoch: 70 | MAE Train Loss: 0.03476089984178543 | MAE Test Loss: 0.0805937647819519 \n",
            "Epoch: 80 | MAE Train Loss: 0.03132382780313492 | MAE Test Loss: 0.07232122868299484 \n",
            "Epoch: 90 | MAE Train Loss: 0.02788739837706089 | MAE Test Loss: 0.06473556160926819 \n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)  # Set random seed for reproducibility\n",
        "\n",
        "# Set the number of epochs (how many times the model will pass over the training data)\n",
        "epochs = 100\n",
        "\n",
        "# Create empty lists to track loss values for both training and testing data\n",
        "train_loss_values = []  # Stores the loss values for the training dataset\n",
        "test_loss_values = []   # Stores the loss values for the testing dataset\n",
        "epoch_count = []        # Tracks the epochs when losses are recorded\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "\n",
        "    # Set the model to training mode (enables gradient calculation, and if using layers like dropout, they behave correctly for training)\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass on training data to get predictions (model processes the input data X_train and generates output predictions y_pred)\n",
        "    y_pred = model_0(X_train)\n",
        "\n",
        "    # 2. Calculate training loss (loss_fn compares the predicted values (y_pred) to the actual target values (y_train) to quantify the error)\n",
        "    loss = loss_fn(y_pred, y_train) # loss_fn(prediction, target)\n",
        "\n",
        "    # 3. Zero the gradients (clears old gradients from previous iterations, preventing accumulation that would mess up the updates)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Backpropagate the loss (calculates how the loss changes with respect to each model parameter using the chain rule)\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Update model parameters based on calculated gradients (optimizer adjusts model weights in the direction that reduces the loss)\n",
        "    optimizer.step() # this should always go after backpropagation\n",
        "\n",
        "    ### Testing\n",
        "\n",
        "    # Set the model to evaluation mode (disables gradient calculation and sets dropout layers to inference mode)\n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():  # Disable gradient calculation for efficiency during evaluation\n",
        "        # 1. Forward pass on test data to get predictions (assess model performance on unseen data)\n",
        "        test_pred = model_0(X_test)\n",
        "\n",
        "        # 2. Calculate testing loss (quantifies how far off predictions are from actual values in test data)\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "        # Log and print progress every 10 epochs\n",
        "        if epoch % 10 == 0:\n",
        "            epoch_count.append(epoch)  # Track current epoch number\n",
        "            train_loss_values.append(loss.detach().numpy())  # Save training loss (detach to prevent storing gradients)\n",
        "            test_loss_values.append(test_loss.detach().numpy())  # Save testing loss\n",
        "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORTfjAAxbkS-"
      },
      "source": [
        "Continue on 6:24:38 (https://www.youtube.com/watch?v=Z_ikDlimN6A&list=PL4bBPBIa3Hi-fOOqMAX3pIigMfkv4Cbyk)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}