{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHL96/PyTorch-Course/blob/main/03_pytorch_computer_vision_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UmeFn4G8fT-"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1rujxvXtdzHOj_xrNlNz_7dNAMp6ZQYps\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "[View Source Code](https://github.com/JunHL96/PyTorch-Course/blob/main/03_pytorch_computer_vision_notes.ipynb) | [View Slides](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/03_pytorch_computer_vision.pdf) | [Watch Video Walkthrough](https://youtu.be/Z_ikDlimN6A?t=50417)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R59WdT5t8fT_"
      },
      "source": [
        "# 03. PyTorch Computer Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXbCyjMq8fT_"
      },
      "source": [
        "\n",
        "[Computer vision](https://en.wikipedia.org/wiki/Computer_vision) is the art of teaching a computer to see.\n",
        "\n",
        "For example, it could involve building a model to classify whether a photo is of a cat or a dog ([binary classification](https://developers.google.com/machine-learning/glossary#binary-classification)).\n",
        "\n",
        "Or whether a photo is of a cat, dog or chicken ([multi-class classification](https://developers.google.com/machine-learning/glossary#multi-class-classification)).\n",
        "\n",
        "Or identifying where a car appears in a video frame ([object detection](https://en.wikipedia.org/wiki/Object_detection)).\n",
        "\n",
        "Or figuring out where different objects in an image can be separated ([panoptic segmentation](https://arxiv.org/abs/1801.00868)).\n",
        "\n",
        "![example computer vision problems](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-computer-vision-problems.png)\n",
        "*Example computer vision problems for binary classification, multiclass classification, object detection and segmentation.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzncLl7_8fUA"
      },
      "source": [
        "## Where does computer vision get used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc7f7IT38fUA"
      },
      "source": [
        "\n",
        "If you use a smartphone, you've already used computer vision.\n",
        "\n",
        "Camera and photo apps use [computer vision to enhance](https://machinelearning.apple.com/research/panoptic-segmentation) and sort images.\n",
        "\n",
        "Modern cars use [computer vision](https://youtu.be/j0z4FweCy4M?t=2989) to avoid other cars and stay within lane lines.\n",
        "\n",
        "Manufacturers use computer vision to identify defects in various products.\n",
        "\n",
        "Security cameras use computer vision to detect potential intruders.\n",
        "\n",
        "In essence, anything that can be described in a visual sense can be a potential computer vision problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlBuZb3B8fUA"
      },
      "source": [
        "## What we're going to cover"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33byGVwC8fUA"
      },
      "source": [
        "\n",
        "\n",
        "We're going to apply the PyTorch Workflow we've been learning in the past couple of sections to computer vision.\n",
        "\n",
        "![a PyTorch workflow with a computer vision focus](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
        "\n",
        "\n",
        "Specifically, we're going to cover:\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **0. Computer vision libraries in PyTorch** | PyTorch has a bunch of built-in helpful computer vision libraries, let's check them out.  |\n",
        "| **1. Load data** | To practice computer vision, we'll start with some images of different pieces of clothing from [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). |\n",
        "| **2. Prepare data** | We've got some images, let's load them in with a [PyTorch `DataLoader`](https://pytorch.org/docs/stable/data.html) so we can use them with our training loop. |\n",
        "| **3. Model 0: Building a baseline model** | Here we'll create a multi-class classification model to learn patterns in the data, we'll also choose a **loss function**, **optimizer** and build a **training loop**. |\n",
        "| **4. Making predictions and evaluating model 0** | Let's make some predictions with our baseline model and evaluate them. |\n",
        "| **5. Setup device agnostic code for future models** | It's best practice to write device-agnostic code, so let's set it up. |\n",
        "| **6. Model 1: Adding non-linearity** | Experimenting is a large part of machine learning, let's try and improve upon our baseline model by adding non-linear layers. |\n",
        "| **7. Model 2: Convolutional Neural Network (CNN)** | Time to get computer vision specific and introduce the powerful convolutional neural network architecture. |\n",
        "| **8. Comparing our models** | We've built three different models, let's compare them. |\n",
        "| **9. Evaluating our best model** | Let's make some predictions on random images and evaluate our best model. |\n",
        "| **10. Making a confusion matrix** | A confusion matrix is a great way to evaluate a classification model, let's see how we can make one. |\n",
        "| **11. Saving and loading the best performing model** | Since we might want to use our model for later, let's save it and make sure it loads back in correctly. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeUq8PF48fUB"
      },
      "source": [
        "## 0. Computer vision libraries in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND35t8FG8fUB"
      },
      "source": [
        "\n",
        "\n",
        "Before we get started writing code, let's talk about some PyTorch computer vision libraries you should be aware of.\n",
        "\n",
        "| PyTorch module | What does it do? |\n",
        "| ----- | ----- |\n",
        "| [`torchvision`](https://pytorch.org/vision/stable/index.html) | Contains datasets, model architectures and image transformations often used for computer vision problems. |\n",
        "| [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) | Here you'll find many example computer vision datasets for a range of problems from image classification, object detection, image captioning, video classification and more. It also contains [a series of base classes for making custom datasets](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets). |\n",
        "| [`torchvision.models`](https://pytorch.org/vision/stable/models.html) | This module contains well-performing and commonly used computer vision model architectures implemented in PyTorch, you can use these with your own problems. |\n",
        "| [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) | Often images need to be transformed (turned into numbers/processed/augmented) before being used with a model, common image transformations are found here. |\n",
        "| [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) | Base dataset class for PyTorch.  |\n",
        "| [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#module-torch.utils.data) | Creates a Python iterable over a dataset (created with `torch.utils.data.Dataset`). |\n",
        "\n",
        "> **Note:** The `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` classes aren't only for computer vision in PyTorch, they are capable of dealing with many different types of data.\n",
        "\n",
        "Now we've covered some of the most important PyTorch computer vision libraries, let's import the relevant dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFxo6R2J8fUB",
        "outputId": "13e03fd2-f513-42a0-9e99-a09ef6c7995e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.5.1+cu121\n",
            "torchvision version: 0.20.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device-Agnostic Code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwcgz8a28fUC"
      },
      "source": [
        "## 1. Getting a dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaIw9TjA8fUC"
      },
      "source": [
        "\n",
        "To begin working on a computer vision problem, let's get a computer vision dataset.\n",
        "\n",
        "We're going to start with FashionMNIST.\n",
        "\n",
        "MNIST stands for Modified National Institute of Standards and Technology.\n",
        "\n",
        "The [original MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) contains thousands of examples of handwritten digits (from 0 to 9) and was used to build computer vision models to identify numbers for postal services.\n",
        "\n",
        "[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist), made by Zalando Research, is a similar setup.\n",
        "\n",
        "Except it contains grayscale images of 10 different kinds of clothing.\n",
        "\n",
        "![example image of FashionMNIST](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-fashion-mnist-slide.png)\n",
        "*`torchvision.datasets` contains a lot of example datasets you can use to practice writing computer vision code on. FashionMNIST is one of those datasets. And since it has 10 different image classes (different types of clothing), it's a multi-class classification problem.*\n",
        "\n",
        "Later, we'll be building a computer vision neural network to identify the different styles of clothing in these images.\n",
        "\n",
        "PyTorch has a bunch of common computer vision datasets stored in `torchvision.datasets`.\n",
        "\n",
        "Including FashionMNIST in [`torchvision.datasets.FashionMNIST()`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html).\n",
        "\n",
        "To download it, we provide the following parameters:\n",
        "* `root: str` - which folder do you want to download the data to?\n",
        "* `train: Bool` - do you want the training or test split?\n",
        "* `download: Bool` - should the data be downloaded?\n",
        "* `transform: torchvision.transforms` - what transformations would you like to do on the data?\n",
        "* `target_transform` - you can transform the targets (labels) if you like too.\n",
        "\n",
        "Many other datasets in `torchvision` have these parameter options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVhW_Dwx8fUC",
        "outputId": "a16aeac0-e676-4b48-d0eb-5d3d26d4bef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 9.87MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 210kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.91MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 21.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # specify the directory where the dataset will be downloaded\n",
        "    train=True, # indicates this is the training dataset\n",
        "    download=True, # automatically downloads the dataset if not already present in the specified directory\n",
        "    transform=ToTensor(), # converts images from PIL format to Torch tensors for model compatibility\n",
        "    target_transform=None # no additional transformation applied to labels (e.g., leave labels as integers)\n",
        ")\n",
        "\n",
        "# Setup testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # specify the directory where the dataset will be downloaded\n",
        "    train=False, # indicates this is the testing dataset\n",
        "    download=True, # automatically downloads the dataset if not already present in the specified directory\n",
        "    transform=ToTensor() # converts images from PIL format to Torch tensors for consistency with training data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L23pDv-J8fUC"
      },
      "source": [
        "Let's check out the first sample of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdxmjTQU8fUC",
        "outputId": "b5d9eddb-c621-4ffb-97bb-25f174403791"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# See first training sample\n",
        "image, label = train_data[0] # Access the first data sample (image, label pair) from the training dataset\n",
        "image, label # Display the image (as a tensor) and its corresponding label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0crFmV_a8fUC"
      },
      "source": [
        "#### Class Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x4qEc268fUC",
        "outputId": "3b4a8d15-b825-40f6-a0a5-b90eb2d5253f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "class_names = train_data.classes    # Get the list of class names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgW40vJN8fUC"
      },
      "source": [
        "#### Class-to-Index Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEqXNulK8fUC",
        "outputId": "3e76ec82-62a4-4be7-c2d4-8b7ce11b4b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'T-shirt/top': 0,\n",
              " 'Trouser': 1,\n",
              " 'Pullover': 2,\n",
              " 'Dress': 3,\n",
              " 'Coat': 4,\n",
              " 'Sandal': 5,\n",
              " 'Shirt': 6,\n",
              " 'Sneaker': 7,\n",
              " 'Bag': 8,\n",
              " 'Ankle boot': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "class_to_idx = train_data.class_to_idx  # Get the mapping of class names to indices\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FGhro_o8fUC"
      },
      "source": [
        "Above, we see the class names and their corresponding indices defined in the dataset for FashionMNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNmPvMcw8fUC"
      },
      "source": [
        "### 1.1 Input and output shapes of a computer vision model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amM7D-WM8fUC"
      },
      "source": [
        "\n",
        "We've got a big tensor of values (the image) leading to a single value for the target (the label).\n",
        "\n",
        "Let's see the image shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8zphR208fUC",
        "outputId": "7232a703-d4c8-4d45-ac18-4958578b8b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
            "Image label: Ankle boot\n"
          ]
        }
      ],
      "source": [
        "class_names = train_data.classes\n",
        "# What's the shape of the image?\n",
        "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image label: {class_names[label]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ3TkhZo8fUC"
      },
      "source": [
        "The shape of the image tensor is `[1, 28, 28]` or more specifically:\n",
        "\n",
        "```\n",
        "[color_channels=1, height=28, width=28]\n",
        "```\n",
        "\n",
        "Having `color_channels=1` means the image is grayscale.\n",
        "\n",
        "![example input and output shapes of the fashionMNIST problem](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-computer-vision-input-and-output-shapes.png)\n",
        "*Various problems will have various input and output shapes. But the premise remains: encode data into numbers, build a model to find patterns in those numbers, convert those patterns into something meaningful.*\n",
        "\n",
        "If `color_channels=3`, the image comes in pixel values for red, green and blue (this is also known as the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model)).\n",
        "\n",
        "The order of our current tensor is often referred to as `CHW` (Color Channels, Height, Width).\n",
        "\n",
        "There's debate on whether images should be represented as `CHW` (color channels first) or `HWC` (color channels last).\n",
        "\n",
        "> **Note:** You'll also see `NCHW` and `NHWC` formats where `N` stands for *number of images*. For example if you have a `batch_size=32`, your tensor shape may be `[32, 1, 28, 28]`. We'll cover batch sizes later.\n",
        "\n",
        "PyTorch generally accepts `NCHW` (channels first) as the default for many operators.\n",
        "\n",
        "However, PyTorch also explains that `NHWC` (channels last) performs better and is [considered best practice](https://pytorch.org/blog/tensor-memory-format-matters/#pytorch-best-practice).\n",
        "\n",
        "For now, since our dataset and models are relatively small, this won't make too much of a difference.\n",
        "\n",
        "But keep it in mind for when you're working on larger image datasets and using convolutional neural networks (we'll see these later).\n",
        "\n",
        "Let's check out more shapes of our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_6SiCt_8fUC",
        "outputId": "e1721f83-fbe1-4709-c407-bc5b3c8acaa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# How many samples are there?\n",
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOmoNcez8fUD"
      },
      "source": [
        "So we've got 60,000 training samples and 10,000 testing samples. The amount in the training and testing datasets are predefined in some cases like MNIST, FashionMNIST, etc.\n",
        "\n",
        "What classes are there?\n",
        "\n",
        "We can find these via the `.classes` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtsCGtPR8fUD",
        "outputId": "eeea2f68-583b-461f-bbe8-1db7509ee8ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# See classes\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDc9PHfO8fUD"
      },
      "source": [
        "Sweet! It looks like we're dealing with 10 different kinds of clothes.\n",
        "\n",
        "Because we're working with 10 different classes, it means our problem is **multi-class classification**.\n",
        "\n",
        "Let's get visual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSNWJAX88fUD"
      },
      "source": [
        "### 1.2 Visualizing our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "LtiEL0_q8fUD",
        "outputId": "28789f15-c1ed-48a0-e4dd-85bd30932e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt # Import Matplotlib for visualization\n",
        "\n",
        "image, label = train_data[0] # Retrieve the first training sample (image and label pair)\n",
        "print(f\"Image shape: {image.shape}\") # Print the shape of the image tensor (e.g., [1, 28, 28])\n",
        "\n",
        "plt.imshow(image.squeeze()) # Remove the extra dimension (e.g., [1, 28, 28] -> [28, 28]) because imshow expects a 2D array\n",
        "plt.title(label); # Set the title of the plot to the label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG2Dd5PW8fUD"
      },
      "source": [
        "We can turn the image into grayscale using the `cmap` parameter of `plt.imshow()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "wraY35hm8fUD",
        "outputId": "0cfa493e-dce3-41ec-cad1-360484caaea5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAomElEQVR4nO3de3RV5Z3G8eckJIdAksMl5FYCCTdh5KKDECNyj0C0DBSseFmzoINamdAW0LGLmVbqtGtSsWNZVCq20wXWiSLO4lJdSoeLhCogBWHQGWUIBgFDwqXmJCTkQvLOHyzPeLiFd5vkTcL3s9ZecvZ5f9kvLzt53Dn7/I7PGGMEAEALi3A9AQDAjYkAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAhoxZ84cxcbGNjpu3LhxGjduXJMdd9y4cRo8eHCTfT2gtSGA0C79+te/ls/nU2ZmpuuptEn/8i//og0bNrieBto5AgjtUn5+vtLT07Vnzx4VFha6nk6bQwChJRBAaHeKioq0c+dOPffcc+rRo4fy8/NdTwnAFRBAaHfy8/PVtWtX3XPPPbr33nuvGEBHjx6Vz+fTL37xC/3mN79R37595ff7NWLECP35z39u9BgHDhxQjx49NG7cOJ07d+6q42pqarRkyRL169dPfr9faWlpevLJJ1VTU3Pdf599+/bpjjvuUExMjDIyMrRy5crLxpw6dUpz585VUlKSOnbsqGHDhumll166bFxlZaUef/xxpaWlye/366abbtIvfvELfbUpvs/nU2VlpV566SX5fD75fD7NmTPnuucLXDcDtDMDBw40c+fONcYYs2PHDiPJ7NmzJ2xMUVGRkWRuvfVW069fP/PMM8+YpUuXmoSEBNOzZ09TW1sbGjt79mzTuXPn0OM9e/aYrl27mrvuustUVVWF9o8dO9aMHTs29Li+vt5MmjTJdOrUySxYsMC8+OKLZv78+aZDhw5m2rRpjf49xo4da1JTU01iYqKZP3++Wb58ubnzzjuNJPO73/0uNK6qqsoMGjTIREVFmYULF5rly5eb0aNHG0lm2bJloXENDQ1mwoQJxufzmYcfftg8//zzZurUqUaSWbBgQWjcyy+/bPx+vxk9erR5+eWXzcsvv2x27tzZ+MIDlgggtCt79+41kszmzZuNMRd/6Pbs2dP84Ac/CBv3ZQB1797d/OUvfwnt37hxo5Fk3njjjdC+rwbQu+++a+Lj480999xjqqurw77mpQH08ssvm4iICPOnP/0pbNzKlSuNJPPee+9d8+8yduxYI8n867/+a2hfTU2NueWWW0xiYmIoJJctW2YkmX//938PjautrTVZWVkmNjbWlJeXG2OM2bBhg5Fkfvazn4Ud59577zU+n88UFhaG9nXu3NnMnj37mvMDvi5+BYd2JT8/X0lJSRo/fryki79OmjVrltasWaP6+vrLxs+aNUtdu3YNPR49erQk6dNPP71s7DvvvKPJkydr4sSJWrdunfx+/zXn8vrrr2vQoEEaOHCgzpw5E9omTJgQ+nqN6dChg7773e+GHkdHR+u73/2uTp06pX379kmS3nrrLSUnJ+uBBx4IjYuKitL3v/99nTt3TgUFBaFxkZGR+v73vx92jMcff1zGGL399tuNzgdoSgQQ2o36+nqtWbNG48ePV1FRkQoLC1VYWKjMzEyVlpZq69atl9X06tUr7PGXYfTFF1+E7a+urtY999yjW2+9VWvXrlV0dHSj8zl8+LD++7//Wz169AjbBgwYIOni6zaNSU1NVefOncP2fVl/9OhRSdJnn32m/v37KyIi/Nt50KBBoee//G9qaqri4uKuOQ5oKR1cTwBoKtu2bdPJkye1Zs0arVmz5rLn8/PzNWnSpLB9kZGRV/xa5pJPqvf7/br77ru1ceNGbdq0Sd/85jcbnU9DQ4OGDBmi55577orPp6WlNfo1gPaMAEK7kZ+fr8TERK1YseKy59atW6f169dr5cqViomJsf7aPp9P+fn5mjZtmr797W/r7bffbrTrQd++ffVf//Vfmjhxonw+n/UxJam4uFiVlZVhV0H/+7//K0lKT0+XJPXu3VsHDx5UQ0ND2FXQJ598Enr+y/9u2bJFFRUVYVdBl4778u8LNDd+BYd24fz581q3bp2++c1v6t57771smz9/vioqKvSHP/zB8zGio6O1bt06jRgxQlOnTtWePXuuOf6+++7T559/rt/+9rdXnG9lZWWjx7xw4YJefPHF0OPa2lq9+OKL6tGjh4YPHy5Juvvuu1VSUqLXXnstrO5Xv/qVYmNjNXbs2NC4+vp6Pf/882HH+OUvfymfz6ecnJzQvs6dO6usrKzR+QFfB1dAaBf+8Ic/qKKiQn/zN39zxedvv/320JtSZ82a5fk4MTExevPNNzVhwgTl5OSooKDgqv3a/vZv/1Zr167VY489pnfeeUejRo1SfX29PvnkE61du1Z//OMfddttt13zeKmpqXrmmWd09OhRDRgwQK+99poOHDig3/zmN4qKipIkPfroo3rxxRc1Z84c7du3T+np6fqP//gPvffee1q2bFnoamfq1KkaP368/umf/klHjx7VsGHD9J//+Z/auHGjFixYoL59+4aOO3z4cG3ZskXPPfecUlNTlZGRQVsjND3Xt+EBTWHq1KmmY8eOprKy8qpj5syZY6KiosyZM2dCt2E/++yzl42TZJYsWRJ6fOn7gIwx5syZM+av/uqvTHJysjl8+LAx5vLbsI25eDv0M888Y26++Wbj9/tN165dzfDhw83TTz9tgsHgNf9OY8eONTfffLPZu3evycrKMh07djS9e/c2zz///GVjS0tLzXe+8x2TkJBgoqOjzZAhQ8yqVasuG1dRUWEWLlxoUlNTTVRUlOnfv7959tlnTUNDQ9i4Tz75xIwZM8bExMQYSdySjWbhM+aSV1sBAGgBvAYEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATre6NqA0NDSouLlZcXBztQACgDTLGqKKiQqmpqZc1yf2qVhdAxcXFNGkEgHbg+PHj6tmz51Wfb3W/gru0VTwAoG1q7Od5swXQihUrlJ6ero4dOyozM7PRxo1f4tduANA+NPbzvFkC6LXXXtOiRYu0ZMkSffDBBxo2bJgmT558XR/ABQC4QTRHg7mRI0ea3Nzc0OP6+nqTmppq8vLyGq0NBoNGEhsbGxtbG98aa7jb5FdAtbW12rdvn7Kzs0P7IiIilJ2drV27dl02vqamRuXl5WEbAKD9a/IAOnPmjOrr65WUlBS2PykpSSUlJZeNz8vLUyAQCG3cAQcANwbnd8EtXrxYwWAwtB0/ftz1lAAALaDJ3weUkJCgyMhIlZaWhu0vLS1VcnLyZeP9fr/8fn9TTwMA0Mo1+RVQdHS0hg8frq1bt4b2NTQ0aOvWrcrKymrqwwEA2qhm6YSwaNEizZ49W7fddptGjhypZcuWqbKyUt/5znea43AAgDaoWQJo1qxZOn36tJ566imVlJTolltu0aZNmy67MQEAcOPyGWOM60l8VXl5uQKBgOtpAAC+pmAwqPj4+Ks+7/wuOADAjYkAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA40cH1BIDWxOfzWdcYY5phJpeLi4uzrrnzzjs9Hevtt9/2VGfLy3pHRkZa11y4cMG6prXzsnZeNdc5zhUQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBM1LgKyIi7P+frL6+3rqmX79+1jUPP/ywdc358+etaySpsrLSuqa6utq6Zs+ePdY1LdlY1EvDTy/nkJfjtOQ62DaANcaooaGh0XFcAQEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEzQjBb7Ctumi5K0Z6YQJE6xrsrOzrWtOnDhhXSNJfr/fuqZTp07WNXfddZd1zb/9279Z15SWllrXSBebatrycj54ERsb66nuepqEXqqqqsrTsRrDFRAAwAkCCADgRJMH0E9+8hP5fL6wbeDAgU19GABAG9csrwHdfPPN2rJly/8fpAMvNQEAwjVLMnTo0EHJycnN8aUBAO1Es7wGdPjwYaWmpqpPnz566KGHdOzYsauOrampUXl5edgGAGj/mjyAMjMztXr1am3atEkvvPCCioqKNHr0aFVUVFxxfF5engKBQGhLS0tr6ikBAFqhJg+gnJwcffvb39bQoUM1efJkvfXWWyorK9PatWuvOH7x4sUKBoOh7fjx4009JQBAK9Tsdwd06dJFAwYMUGFh4RWf9/v9nt70BgBo25r9fUDnzp3TkSNHlJKS0tyHAgC0IU0eQE888YQKCgp09OhR7dy5U9/61rcUGRmpBx54oKkPBQBow5r8V3AnTpzQAw88oLNnz6pHjx668847tXv3bvXo0aOpDwUAaMOaPIDWrFnT1F8SaDG1tbUtcpwRI0ZY16Snp1vXeGmuKkkREfa/HPnjH/9oXXPrrbda1yxdutS6Zu/evdY1kvThhx9a13z88cfWNSNHjrSu8XIOSdLOnTuta3bt2mU13hhzXW+poRccAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADjR7B9IB7jg8/k81RljrGvuuusu65rbbrvNuuZqH2t/LZ07d7aukaQBAwa0SM2f//xn65qrfbjltcTGxlrXSFJWVpZ1zYwZM6xr6urqrGu8rJ0kPfzww9Y1NTU1VuMvXLigP/3pT42O4woIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAATviMl/a/zai8vFyBQMD1NNBMvHapbilevh12795tXZOenm5d44XX9b5w4YJ1TW1tradj2aqurrauaWho8HSsDz74wLrGS7duL+s9ZcoU6xpJ6tOnj3XNN77xDU/HCgaDio+Pv+rzXAEBAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMdXE8AN5ZW1vu2SXzxxRfWNSkpKdY158+ft67x+/3WNZLUoYP9j4bY2FjrGi+NRWNiYqxrvDYjHT16tHXNHXfcYV0TEWF/LZCYmGhdI0mbNm3yVNccuAICADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACdoRgp8TZ06dbKu8dJ80ktNVVWVdY0kBYNB65qzZ89a16Snp1vXeGlo6/P5rGskb2vu5Xyor6+3rvHaYDUtLc1TXXPgCggA4AQBBABwwjqAduzYoalTpyo1NVU+n08bNmwIe94Yo6eeekopKSmKiYlRdna2Dh8+3FTzBQC0E9YBVFlZqWHDhmnFihVXfH7p0qVavny5Vq5cqffff1+dO3fW5MmTPX3wFACg/bK+CSEnJ0c5OTlXfM4Yo2XLlulHP/qRpk2bJkn6/e9/r6SkJG3YsEH333//15stAKDdaNLXgIqKilRSUqLs7OzQvkAgoMzMTO3ateuKNTU1NSovLw/bAADtX5MGUElJiSQpKSkpbH9SUlLouUvl5eUpEAiEttZ0iyAAoPk4vwtu8eLFCgaDoe348eOupwQAaAFNGkDJycmSpNLS0rD9paWloecu5ff7FR8fH7YBANq/Jg2gjIwMJScna+vWraF95eXlev/995WVldWUhwIAtHHWd8GdO3dOhYWFocdFRUU6cOCAunXrpl69emnBggX62c9+pv79+ysjI0M//vGPlZqaqunTpzflvAEAbZx1AO3du1fjx48PPV60aJEkafbs2Vq9erWefPJJVVZW6tFHH1VZWZnuvPNObdq0SR07dmy6WQMA2jyf8dLZrxmVl5crEAi4ngaaiZemkF4aQnpp7ihJsbGx1jX79++3rvGyDufPn7eu8fv91jWSVFxcbF1z6Wu/1+OOO+6wrvHS9NRLg1BJio6Otq6pqKiwrvHyM8/rDVtezvG5c+daja+vr9f+/fsVDAav+bq+87vgAAA3JgIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJyw/jgG4Ovw0nw9MjLSusZrN+xZs2ZZ11zt036v5fTp09Y1MTEx1jUNDQ3WNZLUuXNn65q0tDTrmtraWusaLx2+6+rqrGskqUMH+x+RXv6dunfvbl2zYsUK6xpJuuWWW6xrvKzD9eAKCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcoBkpWpSXpoZeGlZ69dFHH1nX1NTUWNdERUVZ17RkU9bExETrmurqauuas2fPWtd4WbuOHTta10jemrJ+8cUX1jUnTpywrnnwwQetayTp2Wefta7ZvXu3p2M1hisgAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHDihm5G6vP5PNV5aQoZEWGf9V7mV1dXZ13T0NBgXePVhQsXWuxYXrz11lvWNZWVldY158+ft66Jjo62rjHGWNdI0unTp61rvHxfeGkS6uUc96qlvp+8rN3QoUOtayQpGAx6qmsOXAEBAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBPtphmpl2Z+9fX1no7V2htqtmZjxoyxrpk5c6Z1zahRo6xrJKmqqsq65uzZs9Y1XhqLduhg/+3q9Rz3sg5evgf9fr91jZcGpl6bsnpZBy+8nA/nzp3zdKwZM2ZY17zxxhuejtUYroAAAE4QQAAAJ6wDaMeOHZo6dapSU1Pl8/m0YcOGsOfnzJkjn88Xtk2ZMqWp5gsAaCesA6iyslLDhg3TihUrrjpmypQpOnnyZGh79dVXv9YkAQDtj/Wrmjk5OcrJybnmGL/fr+TkZM+TAgC0f83yGtD27duVmJiom266SfPmzbvmXUI1NTUqLy8P2wAA7V+TB9CUKVP0+9//Xlu3btUzzzyjgoIC5eTkXPV20Ly8PAUCgdCWlpbW1FMCALRCTf4+oPvvvz/05yFDhmjo0KHq27evtm/frokTJ142fvHixVq0aFHocXl5OSEEADeAZr8Nu0+fPkpISFBhYeEVn/f7/YqPjw/bAADtX7MH0IkTJ3T27FmlpKQ096EAAG2I9a/gzp07F3Y1U1RUpAMHDqhbt27q1q2bnn76ac2cOVPJyck6cuSInnzySfXr10+TJ09u0okDANo26wDau3evxo8fH3r85es3s2fP1gsvvKCDBw/qpZdeUllZmVJTUzVp0iT99Kc/9dTzCQDQfvmM1y59zaS8vFyBQMD1NJpct27drGtSU1Ota/r3798ix5G8NTUcMGCAdU1NTY11TUSEt98u19XVWdfExMRY1xQXF1vXREVFWdd4aXIpSd27d7euqa2tta7p1KmTdc3OnTuta2JjY61rJG/NcxsaGqxrgsGgdY2X80GSSktLrWsGDRrk6VjBYPCar+vTCw4A4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABONPlHcrty++23W9f89Kc/9XSsHj16WNd06dLFuqa+vt66JjIy0rqmrKzMukaSLly4YF1TUVFhXeOly7LP57OukaTz589b13jpznzfffdZ1+zdu9e6Ji4uzrpG8taBPD093dOxbA0ZMsS6xus6HD9+3LqmqqrKusZLR3WvHb579+7tqa45cAUEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE602makERERVg0lly9fbn2MlJQU6xrJW5NQLzVemhp6ER0d7anOy9/JS7NPLwKBgKc6L40af/7zn1vXeFmHefPmWdcUFxdb10hSdXW1dc3WrVutaz799FPrmv79+1vXdO/e3bpG8tYINyoqyromIsL+WqCurs66RpJOnz7tqa45cAUEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE74jDHG9SS+qry8XIFAQA899JBVk0wvDSGPHDliXSNJsbGxLVLj9/uta7zw0jxR8tbw8/jx49Y1Xhpq9ujRw7pG8tYUMjk52bpm+vTp1jUdO3a0rklPT7eukbydr8OHD2+RGi//Rl6aino9ltfmvrZsmjV/lZfv99tvv91qfENDgz7//HMFg0HFx8dfdRxXQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgRAfXE7ia06dPWzXN89LkMi4uzrpGkmpqaqxrvMzPS0NIL40Qr9Us8Fr+8pe/WNd89tln1jVe1uH8+fPWNZJUXV1tXXPhwgXrmvXr11vXfPjhh9Y1XpuRduvWzbrGS8PPsrIy65q6ujrrGi//RtLFppq2vDT79HIcr81IvfyMGDBggNX4Cxcu6PPPP290HFdAAAAnCCAAgBNWAZSXl6cRI0YoLi5OiYmJmj59ug4dOhQ2prq6Wrm5uerevbtiY2M1c+ZMlZaWNumkAQBtn1UAFRQUKDc3V7t379bmzZtVV1enSZMmqbKyMjRm4cKFeuONN/T666+roKBAxcXFmjFjRpNPHADQtlndhLBp06awx6tXr1ZiYqL27dunMWPGKBgM6ne/+51eeeUVTZgwQZK0atUqDRo0SLt377b+VD0AQPv1tV4DCgaDkv7/jpl9+/aprq5O2dnZoTEDBw5Ur169tGvXrit+jZqaGpWXl4dtAID2z3MANTQ0aMGCBRo1apQGDx4sSSopKVF0dLS6dOkSNjYpKUklJSVX/Dp5eXkKBAKhLS0tzeuUAABtiOcAys3N1UcffaQ1a9Z8rQksXrxYwWAwtHl5vwwAoO3x9EbU+fPn680339SOHTvUs2fP0P7k5GTV1taqrKws7CqotLRUycnJV/xafr9ffr/fyzQAAG2Y1RWQMUbz58/X+vXrtW3bNmVkZIQ9P3z4cEVFRWnr1q2hfYcOHdKxY8eUlZXVNDMGALQLVldAubm5euWVV7Rx40bFxcWFXtcJBAKKiYlRIBDQ3LlztWjRInXr1k3x8fH63ve+p6ysLO6AAwCEsQqgF154QZI0bty4sP2rVq3SnDlzJEm//OUvFRERoZkzZ6qmpkaTJ0/Wr3/96yaZLACg/fAZY4zrSXxVeXm5AoGAhgwZosjIyOuu++1vf2t9rDNnzljXSFLnzp2ta7p3725d46VR47lz56xrvDRPlKQOHexfQvTSdLFTp07WNV4amEre1iIiwv5eHi/fdpfeXXo9vvomcRtemrl+8cUX1jVeXv/18n3rpYGp5K2JqZdjxcTEWNdc7XX1xnhpYpqfn281vqamRs8//7yCweA1mx3TCw4A4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOePpE1Jbw4YcfWo1ft26d9TH+7u/+zrpGkoqLi61rPv30U+ua6upq6xovXaC9dsP20sE3OjrausamK/qXampqrGskqb6+3rrGS2frqqoq65qTJ09a13htdu9lHbx0R2+pc7y2tta6RvLWkd5LjZcO2l46dUu67INEr0dpaanV+Otdb66AAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJn/HarbCZlJeXKxAItMixcnJyPNU98cQT1jWJiYnWNWfOnLGu8dII0UvjSclbk1AvzUi9NLn0MjdJ8vl81jVevoW8NID1UuNlvb0ey8vaeeHlOLbNNL8OL2ve0NBgXZOcnGxdI0kHDx60rrnvvvs8HSsYDCo+Pv6qz3MFBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOtNpmpD6fz6rpoJdmfi1p/Pjx1jV5eXnWNV6annpt/hoRYf//L16ahHppRuq1waoXp06dsq7x8m33+eefW9d4/b44d+6cdY3XBrC2vKxdXV2dp2NVVVVZ13j5vti8ebN1zccff2xdI0k7d+70VOcFzUgBAK0SAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJxotc1I0XIGDhzoqS4hIcG6pqyszLqmZ8+e1jVHjx61rpG8Na08cuSIp2MB7R3NSAEArRIBBABwwiqA8vLyNGLECMXFxSkxMVHTp0/XoUOHwsaMGzcu9Fk+X26PPfZYk04aAND2WQVQQUGBcnNztXv3bm3evFl1dXWaNGmSKisrw8Y98sgjOnnyZGhbunRpk04aAND2WX3U5KZNm8Ier169WomJidq3b5/GjBkT2t+pUyclJyc3zQwBAO3S13oNKBgMSpK6desWtj8/P18JCQkaPHiwFi9efM2Pta2pqVF5eXnYBgBo/6yugL6qoaFBCxYs0KhRozR48ODQ/gcffFC9e/dWamqqDh48qB/+8Ic6dOiQ1q1bd8Wvk5eXp6efftrrNAAAbZTn9wHNmzdPb7/9tt59991rvk9j27ZtmjhxogoLC9W3b9/Lnq+pqVFNTU3ocXl5udLS0rxMCR7xPqD/x/uAgKbT2PuAPF0BzZ8/X2+++aZ27NjR6A+HzMxMSbpqAPn9fvn9fi/TAAC0YVYBZIzR9773Pa1fv17bt29XRkZGozUHDhyQJKWkpHiaIACgfbIKoNzcXL3yyivauHGj4uLiVFJSIkkKBAKKiYnRkSNH9Morr+juu+9W9+7ddfDgQS1cuFBjxozR0KFDm+UvAABom6wC6IUXXpB08c2mX7Vq1SrNmTNH0dHR2rJli5YtW6bKykqlpaVp5syZ+tGPftRkEwYAtA/Wv4K7lrS0NBUUFHytCQEAbgx0wwYANAu6YQMAWiUCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATrS6AjDGupwAAaAKN/TxvdQFUUVHhegoAgCbQ2M9zn2lllxwNDQ0qLi5WXFycfD5f2HPl5eVKS0vT8ePHFR8f72iG7rEOF7EOF7EOF7EOF7WGdTDGqKKiQqmpqYqIuPp1TocWnNN1iYiIUM+ePa85Jj4+/oY+wb7EOlzEOlzEOlzEOlzkeh0CgUCjY1rdr+AAADcGAggA4ESbCiC/368lS5bI7/e7nopTrMNFrMNFrMNFrMNFbWkdWt1NCACAG0ObugICALQfBBAAwAkCCADgBAEEAHCCAAIAONFmAmjFihVKT09Xx44dlZmZqT179rieUov7yU9+Ip/PF7YNHDjQ9bSa3Y4dOzR16lSlpqbK5/Npw4YNYc8bY/TUU08pJSVFMTExys7O1uHDh91Mthk1tg5z5sy57PyYMmWKm8k2k7y8PI0YMUJxcXFKTEzU9OnTdejQobAx1dXVys3NVffu3RUbG6uZM2eqtLTU0Yybx/Wsw7hx4y47Hx577DFHM76yNhFAr732mhYtWqQlS5bogw8+0LBhwzR58mSdOnXK9dRa3M0336yTJ0+Gtnfffdf1lJpdZWWlhg0bphUrVlzx+aVLl2r58uVauXKl3n//fXXu3FmTJ09WdXV1C8+0eTW2DpI0ZcqUsPPj1VdfbcEZNr+CggLl5uZq9+7d2rx5s+rq6jRp0iRVVlaGxixcuFBvvPGGXn/9dRUUFKi4uFgzZsxwOOumdz3rIEmPPPJI2PmwdOlSRzO+CtMGjBw50uTm5oYe19fXm9TUVJOXl+dwVi1vyZIlZtiwYa6n4ZQks379+tDjhoYGk5ycbJ599tnQvrKyMuP3+82rr77qYIYt49J1MMaY2bNnm2nTpjmZjyunTp0ykkxBQYEx5uK/fVRUlHn99ddDYz7++GMjyezatcvVNJvdpetgjDFjx441P/jBD9xN6jq0+iug2tpa7du3T9nZ2aF9ERERys7O1q5duxzOzI3Dhw8rNTVVffr00UMPPaRjx465npJTRUVFKikpCTs/AoGAMjMzb8jzY/v27UpMTNRNN92kefPm6ezZs66n1KyCwaAkqVu3bpKkffv2qa6uLux8GDhwoHr16tWuz4dL1+FL+fn5SkhI0ODBg7V48WJVVVW5mN5Vtbpu2Jc6c+aM6uvrlZSUFLY/KSlJn3zyiaNZuZGZmanVq1frpptu0smTJ/X0009r9OjR+uijjxQXF+d6ek6UlJRI0hXPjy+fu1FMmTJFM2bMUEZGho4cOaJ//Md/VE5Ojnbt2qXIyEjX02tyDQ0NWrBggUaNGqXBgwdLung+REdHq0uXLmFj2/P5cKV1kKQHH3xQvXv3Vmpqqg4ePKgf/vCHOnTokNatW+dwtuFafQDh/+Xk5IT+PHToUGVmZqp3795au3at5s6d63BmaA3uv//+0J+HDBmioUOHqm/fvtq+fbsmTpzocGbNIzc3Vx999NEN8TrotVxtHR599NHQn4cMGaKUlBRNnDhRR44cUd++fVt6mlfU6n8Fl5CQoMjIyMvuYiktLVVycrKjWbUOXbp00YABA1RYWOh6Ks58eQ5wflyuT58+SkhIaJfnx/z58/Xmm2/qnXfeCfv8sOTkZNXW1qqsrCxsfHs9H662DleSmZkpSa3qfGj1ARQdHa3hw4dr69atoX0NDQ3aunWrsrKyHM7MvXPnzunIkSNKSUlxPRVnMjIylJycHHZ+lJeX6/3337/hz48TJ07o7Nmz7er8MMZo/vz5Wr9+vbZt26aMjIyw54cPH66oqKiw8+HQoUM6duxYuzofGluHKzlw4IAkta7zwfVdENdjzZo1xu/3m9WrV5v/+Z//MY8++qjp0qWLKSkpcT21FvX444+b7du3m6KiIvPee++Z7Oxsk5CQYE6dOuV6as2qoqLC7N+/3+zfv99IMs8995zZv3+/+eyzz4wxxvz85z83Xbp0MRs3bjQHDx4006ZNMxkZGeb8+fOOZ960rrUOFRUV5oknnjC7du0yRUVFZsuWLeav//qvTf/+/U11dbXrqTeZefPmmUAgYLZv325OnjwZ2qqqqkJjHnvsMdOrVy+zbds2s3fvXpOVlWWysrIczrrpNbYOhYWF5p//+Z/N3r17TVFRkdm4caPp06ePGTNmjOOZh2sTAWSMMb/61a9Mr169THR0tBk5cqTZvXu36ym1uFmzZpmUlBQTHR1tvvGNb5hZs2aZwsJC19Nqdu+8846RdNk2e/ZsY8zFW7F//OMfm6SkJOP3+83EiRPNoUOH3E66GVxrHaqqqsykSZNMjx49TFRUlOndu7d55JFH2t3/pF3p7y/JrFq1KjTm/Pnz5u///u9N165dTadOncy3vvUtc/LkSXeTbgaNrcOxY8fMmDFjTLdu3Yzf7zf9+vUz//AP/2CCwaDbiV+CzwMCADjR6l8DAgC0TwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4MT/AcBjvi3QnOhnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2qmAtH78fUD"
      },
      "source": [
        "Beautiful, well as beautiful as a pixelated grayscale ankle boot can get.\n",
        "\n",
        "Let's view a few more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "48B2IV1G8fUD",
        "outputId": "87368777-6ace-4ad7-bdfd-fa088b3f5d46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42) # Set a random seed for reproducibility\n",
        "fig = plt.figure(figsize=(9, 9)) # Create a figure with specified size for plotting\n",
        "rows, cols = 4, 4 # Define the number of rows and columns for the grid (4x4 grid)\n",
        "for i in range(1, rows * cols + 1): # Loop through grid positions (16 total images)\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item() # Get a random index from the training dataset NOTE: see explanation below\n",
        "    img, label = train_data[random_idx] # Retrieve the image and its corresponding label using the random index\n",
        "    fig.add_subplot(rows, cols, i) # Add a subplot to the grid at the ith position\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\") # Display the image; squeeze removes extra dimensions, and cmap=\"gray\" ensures grayscale\n",
        "    plt.title(class_names[label]) # Set the title of the subplot to the class name corresponding to the label\n",
        "    plt.axis(False); # Remove axis ticks and labels for a cleaner visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqGCeZnM8fUE"
      },
      "source": [
        "### NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIO-wzrI8fUE"
      },
      "source": [
        "#### Why `.item()` is needed:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjuLWtYE8fUE"
      },
      "source": [
        "\n",
        "- `torch.randint()` returns a tensor (e.g., `tensor([42])`), even if it contains a single value.\n",
        "- `.item()` extracts the scalar value from the tensor, converting it into a standard Python integer (e.g., `42`), which is required for indexing `train_data`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WO8OAB88fUE"
      },
      "source": [
        "\n",
        "#### Why `size=[1]` is needed:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3nv10vO8fUE"
      },
      "source": [
        "\n",
        "- `size=[1]` tells `torch.randint()` to generate a single random number (1 element in the output tensor).\n",
        "- Without it, you would need to explicitly pass a scalar shape for randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9JaWeYC8fUE"
      },
      "source": [
        "Hmmm, this dataset doesn't look too aesthetic.\n",
        "\n",
        "But the principles we're going to learn on how to build a model for it will be similar across a wide range of computer vision problems.\n",
        "\n",
        "In essence, taking pixel values and building a model to find patterns in them to use on future pixel values.\n",
        "\n",
        "Plus, even for this small dataset (yes, even 60,000 images in deep learning is considered quite small), could you write a program to classify each one of them?\n",
        "\n",
        "You probably could.\n",
        "\n",
        "But I think coding a model in PyTorch would be faster.\n",
        "\n",
        "> **Question:** Do you think the above data can be modeled with only straight (linear) lines? Or do you think you'd also need non-straight (non-linear) lines?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BERFHduI8fUE"
      },
      "source": [
        "## 2. Prepare DataLoader\n",
        "\n",
        "Now that our dataset is ready, the next step is to organize it using a [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), commonly referred to as `DataLoader`.\n",
        "\n",
        "Right now, our data is in the form of PyTorch datasets. We can use a `DataLoader` to turn it into an iterable sequence of batches.\n",
        "\n",
        "### What is a DataLoader?\n",
        "\n",
        "A `DataLoader` serves as an efficient way to load data into your model for both training and inference. It transforms a large `Dataset` into an iterable sequence of smaller subsets called **batches** or **mini-batches**. The size of these batches is determined by the `batch_size` parameter.\n",
        "\n",
        "### Why Use Batches?\n",
        "\n",
        "- **Computational Efficiency:** Processing the entire dataset at once can be resource-intensive and impractical for large datasets. By dividing the data into smaller batches, you reduce memory usage and speed up computations.\n",
        "  \n",
        "- **Frequent Updates:** Using mini-batches allows your model to update its parameters more frequently. Instead of waiting to process the entire dataset before making an update (which happens once per epoch), updates occur after each mini-batch, leading to faster convergence. In other words, it gives our neural network more chances to update its gradients per epoch.\n",
        "\n",
        "### Choosing a Batch Size\n",
        "\n",
        "A good starting point for the `batch_size` is **32**. This value strikes a balance between training speed and model performance. However, since `batch_size` is a **hyperparameter**, you can experiment with different values to see what works best for your specific problem. Common batch sizes are powers of 2, such as 32, 64, 128, 256, and 512.\n",
        "\n",
        "![Batched Dataset Example](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-batching-fashionmnist.png)\n",
        "*Example of batching FashionMNIST with a batch size of 32 and shuffle enabled. The batching process is similar for other datasets, varying only with the chosen batch size.*\n",
        "\n",
        "### Implementing DataLoaders for Training and Testing\n",
        "\n",
        "Let's create `DataLoader` instances for both our training and test datasets. This will enable efficient data handling during the model training and evaluation phases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-9Uga3-8fUE",
        "outputId": "e2f8b64f-44f4-4154-9f86-a750d63a1d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7afe71009f30>, <torch.utils.data.dataloader.DataLoader object at 0x7afe7a281db0>)\n",
            "Length of train dataloader: 1875 batches of 32\n",
            "Length of test dataloader: 313 batches of 32\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32      # How many samples per batch?\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(train_data,            # dataset to turn into iterable\n",
        "                              batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "                              shuffle=True)          # shuffle data every epoch?\n",
        "\n",
        "test_dataloader = DataLoader(test_data,              # dataset to turn into iterable\n",
        "                            batch_size=BATCH_SIZE,   # how many samples per batch?\n",
        "                            shuffle=False)           # shuffle data every epoch?\n",
        "\n",
        "# Let's check out what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8qtbFj-8fUE"
      },
      "source": [
        "#### Why shuffle data every epoch for training, but not for testing?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPBhD96Q8fUE"
      },
      "source": [
        "\n",
        "- For training, shuffling the data every epoch ensures that the model is exposed to a wide variety of data patterns, which helps prevent overfitting.\n",
        "- For testing, we want to see the model's performance on the same data patterns it encountered during training, so we don't want to shuffle it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG1aWGGH8fUE"
      },
      "source": [
        "#### Check out what's inside the training dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PH62hbG8fUE",
        "outputId": "54e4dc4c-309e-4be0-dd42-d0fc3282928d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))  # Retrieve one batch of features (inputs) and labels (targets) from the dataloader\n",
        "train_features_batch.shape, train_labels_batch.shape  # Output the shapes of the features and labels in the batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMZ8xyTJ8fUE"
      },
      "source": [
        "#### Purpose and Importance of `train_features_batch` and `train_labels_batch`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCIG88dk8fUE"
      },
      "source": [
        "\n",
        "1. **Understanding Data Structure:**\n",
        "   - **Purpose:** By fetching a single batch and inspecting its shape, you gain insight into how your data is organized.\n",
        "   - **Why It Matters:** Knowing the dimensions helps ensure that your data aligns with the expected input requirements of your neural network. For instance, if your model expects inputs of shape `[batch_size, channels, height, width]`, verifying this helps prevent shape mismatches.\n",
        "      * **Note**: In PyTorch, data is often represented as tensors with dimensions in the format `[batch_size, channels, height, width]` (NCHW format).\n",
        "\n",
        "2. **Verifying DataLoader Configuration:**\n",
        "   - **Purpose:** This step acts as a sanity check to confirm that the `DataLoader` is correctly batching and loading your data.\n",
        "   - **Why It Matters:** Misconfigurations like incorrect `batch_size` or improper shuffling can lead to issues during training. Ensuring that the loader behaves as expected helps avoid runtime errors and improves training efficiency.\n",
        "\n",
        "3. **Debugging and Troubleshooting:**\n",
        "   - **Purpose:** If you encounter unexpected behaviors or errors later in your training process, knowing the exact shape and structure of your data can help pinpoint issues.\n",
        "   - **Why It Matters:** For example, if your model throws an error about mismatched dimensions, you can refer back to these shape checks to identify the discrepancy.\n",
        "\n",
        "4. **Performance Optimization:**\n",
        "   - **Purpose:** Understanding the batch size and data dimensions can aid in optimizing training performance, especially when leveraging hardware accelerators like GPUs.\n",
        "   - **Why It Matters:** Larger batch sizes can speed up training but may require more memory. Balancing these factors based on your data shapes ensures efficient utilization of resources.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjLtIzsb8fUE"
      },
      "source": [
        "#### Show a Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "HBDQEwnt8fUE",
        "outputId": "8ea28af4-6942-4644-ec02-f5b6834929b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: torch.Size([1, 28, 28])\n",
            "Label: 6, label size: torch.Size([])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False);\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW2QYXEJ8fUE"
      },
      "source": [
        "## 3. Model 0: Building a Baseline Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eTYIk6d8fUE"
      },
      "source": [
        "\n",
        "Data has been successfully loaded and prepared!\n",
        "\n",
        "Now, let's construct a **baseline model** by subclassing `nn.Module` from PyTorch.\n",
        "\n",
        "When starting to build a series of ML modelling experiments, it's best practice to start with a **baseline model** that provides a starting point to improve upon.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq_X-DxW8fUE"
      },
      "source": [
        "\n",
        "### What is a Baseline Model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSTLKJM08fUE"
      },
      "source": [
        "\n",
        "A **baseline model** serves as the simplest possible model to establish a performance benchmark. It provides a starting point from which more complex models can be developed and improvements can be measured.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szSSTri28fUE"
      },
      "source": [
        "\n",
        "### Building the Baseline Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldlD5Amg8fUF"
      },
      "source": [
        "\n",
        "Our baseline model will consist of two [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layers. These layers are fully connected layers that apply a linear transformation to the input data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuh7hS3u8fUF"
      },
      "source": [
        "\n",
        "#### A Slight Variation for Image Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ve6jiBu8fUF"
      },
      "source": [
        "\n",
        "Since we are working with image data, we'll introduce a slight modification by incorporating the [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) layer at the beginning of our model.\n",
        "\n",
        "- **`nn.Flatten()`**: This layer transforms multi-dimensional input tensors into a single-dimensional vector. For image data, which typically has dimensions corresponding to color channels, height, and width, flattening simplifies the data structure, making it easier to process with linear layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd90b1cf8fUF"
      },
      "source": [
        "\n",
        "### Why Use `nn.Flatten()`?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXEf-KnH8fUF"
      },
      "source": [
        "\n",
        "Flattening the tensor reduces its complexity by collapsing all dimensions except the batch size into one. This is particularly useful when transitioning from convolutional layers, which handle multi-dimensional data, to linear layers, which expect one-dimensional input.\n",
        "\n",
        "By starting with `nn.Flatten()`, we ensure that our image data is appropriately formatted for the linear layers that follow, enabling effective training of our baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iggIkz2n8fUF"
      },
      "source": [
        "### Coding the Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUDL1qcM8fUF",
        "outputId": "e76e3ce2-e15d-463b-fafc-232a5e068ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
            "Shape after flattening: torch.Size([1, 784]) -> [color_channels, height*width]\n"
          ]
        }
      ],
      "source": [
        "# Create a flatten layer\n",
        "flatten_model = nn.Flatten()  # Initialize the Flatten layer to convert multi-dimensional tensors to 1D\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]  # Select the first image from the training features batch\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_model(x)  # Apply the Flatten layer to transform the image tensor into a 1D vector\n",
        "\n",
        "# Print output shape\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")  # Display original tensor shape\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")  # Display flattened tensor shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ2e40Z_8fUF"
      },
      "source": [
        "\n",
        "\n",
        "### Benefits for `nn.Linear` Layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3tEY0b_8fUF"
      },
      "source": [
        "\n",
        "`nn.Linear()` layers are designed to work with feature vectors. They expect inputs to be in a flat, one-dimensional format where each element of the vector represents a distinct feature. By providing the data as a feature vector, `nn.Linear()` can effectively apply linear transformations to learn the relationships between features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STdjFqca8fUF"
      },
      "source": [
        "\n",
        "### Building Our First Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LccRGiP8fUF"
      },
      "source": [
        "\n",
        "Let's create our initial model by using `nn.Flatten()` as the first layer. This setup ensures that our image data is properly formatted for the subsequent linear layers, allowing the model to process and learn from the pixel data efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vSRXNL9P8fUF"
      },
      "outputs": [],
      "source": [
        "from torch import nn  # Import PyTorch's neural network module\n",
        "\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape: int,     # Number of input features (e.g., 784 for 28x28 images)\n",
        "                 hidden_units: int,    # Number of neurons in the hidden layer\n",
        "                 output_shape: int):   # Number of output classes (e.g., 10 for classification)\n",
        "        super().__init__()  # Initialize the parent nn.Module class\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(),  # Flatten multi-dimensional input into a 1D vector\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units),  # First linear layer: input to hidden\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape)   # Second linear layer: hidden to output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)  # Pass input through the sequential layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF41cP338fUF"
      },
      "source": [
        "Wonderful!\n",
        "\n",
        "We've got a baseline model class we can use, now let's instantiate a model.\n",
        "\n",
        "We'll need to set the following parameters:\n",
        "* `input_shape=784` - this is how many features you've got going in the model, in our case, it's one for every pixel in the target image (28 pixels high by 28 pixels wide = 784 features).\n",
        "* `hidden_units=10` - number of units/neurons in the hidden layer(s), this number could be whatever you want but to keep the model small we'll start with `10`.\n",
        "* `output_shape=len(class_names)` - since we're working with a multi-class classification problem, we need an output neuron per class in our dataset.\n",
        "\n",
        "Let's create an instance of our model and send to the CPU for now (we'll run a small test for running `model_0` on CPU vs. a similar model on GPU soon)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDYxIL5r8fUF",
        "outputId": "3e9f7c98-d1b4-46aa-e434-d1d12141e595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV0(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Setup model with input parameters\n",
        "model_0 = FashionMNISTModelV0(input_shape=784,               # 784 for 28x28 images\n",
        "                              hidden_units=10,               # units in hidden layer\n",
        "                              output_shape=len(class_names)  # one for each class\n",
        "                             )#to.(device)\n",
        "\n",
        "model_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYLq4R_F8fUF"
      },
      "source": [
        "#### Running a Small Test to test shapes and inputs of `model_0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdSX4iir8fUF",
        "outputId": "75b82c2d-c143-4f79-e2fa-c3ca2d6a9d21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
              "          -0.1004,  0.0157]], grad_fn=<AddmmBackward0>),\n",
              " torch.Size([1, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "dummy_x = torch.rand([1, 1, 28, 28])#.to(device)\n",
        "model_0(dummy_x), model_0(dummy_x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCSmeu4-8fUF"
      },
      "source": [
        "### 3.1 Setup loss, optimizer and evaluation metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch-sjeSy8fUF"
      },
      "source": [
        "\n",
        "Since we're working on a classification problem, let's bring in our [`helper_functions.py` script](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/helper_functions.py) and subsequently the `accuracy_fn()` we defined in [notebook 02](https://www.learnpytorch.io/02_pytorch_classification/).\n",
        "\n",
        "> **Note:** Rather than importing and using our own accuracy function or evaluation metric(s), you could import various evaluation metrics from the [TorchMetrics package](https://torchmetrics.readthedocs.io/en/latest/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6192qXaq8fUF",
        "outputId": "7580dadf-9f10-4cd2-ae53-f474a6e6d068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ],
      "source": [
        "import requests  # Import the requests module to handle HTTP requests\n",
        "from pathlib import Path  # Import Path from pathlib to work with file paths\n",
        "\n",
        "# Check if the helper_functions.py file already exists in the current directory\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "    print(\"helper_functions.py already exists, skipping download\")  # Notify that the file exists\n",
        "else:\n",
        "    print(\"Downloading helper_functions.py\")  # Notify that the file is being downloaded\n",
        "    # Send a GET request to download the raw helper_functions.py script from the specified GitHub URL\n",
        "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "    # Open a file named \"helper_functions.py\" in write-binary mode and save the downloaded content\n",
        "    with open(\"helper_functions.py\", \"wb\") as f:\n",
        "        f.write(request.content)  # Write the content of the request to the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AOPNzEEc8fUF"
      },
      "outputs": [],
      "source": [
        "# Import accuracy metric from the helper_functions.py script\n",
        "from helper_functions import accuracy_fn  # Custom accuracy function for evaluation\n",
        "# Note: Alternatively, you could use the TorchMetrics package for prebuilt metrics like Accuracy.\n",
        "# Example: torchmetrics.Accuracy(task='multiclass', num_classes=len(class_names)).to(device)\n",
        "\n",
        "# Setup loss function\n",
        "loss_fn = nn.CrossEntropyLoss()  # Define the loss function for classification tasks (e.g., categorical cross-entropy)\n",
        "\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),    # Use Stochastic Gradient Descent (SGD) optimizer\n",
        "                            lr=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrEa9xcn8fUF"
      },
      "source": [
        "### 3.2 Creating a Function to Time Our Experiments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQUUT8zS8fUF"
      },
      "source": [
        "\n",
        "With the loss function and optimizer set up, we're ready to begin training our model. However, before diving into training, it's beneficial to conduct an experiment to measure and compare the training times on different hardware—specifically, between a **CPU** and a **GPU**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx7bDQM_8fUG"
      },
      "source": [
        "\n",
        "#### Why Measure Training Time?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XjmaCh78fUG"
      },
      "source": [
        "\n",
        "Understanding how long your model takes to train on different hardware can help you make informed decisions about resource allocation, optimize your workflow, and identify potential bottlenecks in your training process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzm4z3RH8fUG"
      },
      "source": [
        "\n",
        "#### Setting Up the Timing Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61koDoXw8fUG"
      },
      "source": [
        "\n",
        "To accurately measure the training time, we'll create a **timing function**. This function will utilize the [`timeit.default_timer()`](https://docs.python.org/3/library/timeit.html#timeit.default_timer) from Python's [`timeit` module](https://docs.python.org/3/library/timeit.html). The `timeit` module provides a simple way to time small bits of Python code, and `default_timer()` offers the most accurate clock available on your platform.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVGlmGwJ8fUG"
      },
      "source": [
        "\n",
        "#### Steps to Create the Timing Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6snWcMKJ8fUG"
      },
      "source": [
        "\n",
        "1. **Import the Required Function:**\n",
        "   - We'll import `default_timer` from the `timeit` module to track the start and end times of our training process.\n",
        "\n",
        "2. **Define the Timing Function:**\n",
        "   - The function will accept the model, data loaders, loss function, optimizer, number of epochs, and the device (CPU or GPU) as parameters.\n",
        "   - It will record the time before and after the training loop to calculate the total training duration.\n",
        "\n",
        "3. **Run the Experiment:**\n",
        "   - We'll train the same model twice: once on the CPU and once on the GPU.\n",
        "   - By comparing the recorded times, we can observe the performance difference between the two hardware setups.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4VNRFyrM8fUG"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer  # Import the default_timer function for high-resolution timing\n",
        "\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"\n",
        "    Prints the difference between start and end times, indicating the training duration on a specific device.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferably obtained using timeit.default_timer()).\n",
        "        end (float): End time of computation.\n",
        "        device (torch.device, optional): The device on which the computation was performed (e.g., CPU or GPU). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: The total time taken for training in seconds.\n",
        "    \"\"\"\n",
        "    total_time = end - start  # Calculate the total training time by subtracting start time from end time\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")  # Print the training time with device information\n",
        "    return total_time  # Return the total training time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGvFdrvt8fUG"
      },
      "source": [
        "### 3.3 Creating a Training Loop and Training a Model on Batches of Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR9RHdtK8fUG"
      },
      "source": [
        "\n",
        "Great! We have all the necessary components: a timer, loss function, optimizer, model, and data.\n",
        "\n",
        "Next, we'll create training and testing loops to train and evaluate our model.\n",
        "\n",
        "Since our data is now batched, we'll introduce an additional loop to handle these batches. Our batches are managed by the `DataLoader`s: `train_dataloader` for training data and `test_dataloader` for testing data.\n",
        "\n",
        "Each batch contains `BATCH_SIZE` samples of features (`X`) and labels (`y`). With `BATCH_SIZE=32`, each batch includes 32 images and their corresponding targets.\n",
        "\n",
        "Because we're processing data in batches, we'll calculate loss and evaluation metrics **per batch** instead of across the entire dataset. This requires dividing the accumulated loss and accuracy by the number of batches in each dataloader.\n",
        "\n",
        "Here’s the process:\n",
        "1. Iterate over epochs.\n",
        "2. For each epoch, loop through training batches to perform training steps and compute training loss per batch.\n",
        "3. Loop through testing batches to perform testing steps and compute testing loss per batch.\n",
        "4. Display progress and results.\n",
        "5. Track the total training time.\n",
        "\n",
        "It involves several steps, but as always, if you’re unsure, just start coding!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "87f9c23c5cc0462097fae4365de26ed2",
            "f08f1421d4b84a44b86ee429fc1259a0",
            "a6d1862ff3d242aaad2819ddc3e4a6b9",
            "94db0d40b8294b7e9513dd65ca1d29f1",
            "549a3d3188364ee98d57faf6585a7389",
            "afe33f448a004b12807976a181980d3d",
            "d6b40b425b824b97bc90e7c8a19ddb7a",
            "aa7b72b547614745bb206721e7728617",
            "34415457a256458a819486efa8accbed",
            "b0b6ae6ab9074b1782d5e2eaac0984b2",
            "43cf24a0b3334a6c8a8001ae2de37b09"
          ]
        },
        "id": "xh3RahSm8fUG",
        "outputId": "536c13b0-db4a-4e55-e97b-ea1a621420f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87f9c23c5cc0462097fae4365de26ed2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Processed 0/60000 images during training\n",
            "Processed 12800/60000 images during training\n",
            "Processed 25600/60000 images during training\n",
            "Processed 38400/60000 images during training\n",
            "Processed 51200/60000 images during training\n",
            "Train Loss: 0.59039 | Test Loss: 0.50954 | Test Accuracy: 82.04%\n",
            "Epoch: 1\n",
            "-------\n",
            "Processed 0/60000 images during training\n",
            "Processed 12800/60000 images during training\n",
            "Processed 25600/60000 images during training\n",
            "Processed 38400/60000 images during training\n",
            "Processed 51200/60000 images during training\n",
            "Train Loss: 0.47633 | Test Loss: 0.47989 | Test Accuracy: 83.20%\n",
            "Epoch: 2\n",
            "-------\n",
            "Processed 0/60000 images during training\n",
            "Processed 12800/60000 images during training\n",
            "Processed 25600/60000 images during training\n",
            "Processed 38400/60000 images during training\n",
            "Processed 51200/60000 images during training\n",
            "Train Loss: 0.45503 | Test Loss: 0.47664 | Test Accuracy: 83.43%\n",
            "Train time on cpu: 27.630 seconds\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm  # Import tqdm for displaying progress bars\n",
        "import torch\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Start the training timer to measure how long the training process takes\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Define the number of training epochs (full passes through the dataset)\n",
        "epochs = 3\n",
        "\n",
        "# Training and testing loop iterates over the number of epochs\n",
        "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "\n",
        "    ### Training Phase\n",
        "    train_loss = 0  # Initialize cumulative training loss for the epoch\n",
        "\n",
        "    # Enumerate(train_dataloader) provides the batch index, input data X, and corresponding labels y for each training batch\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        model_0.train()  # Set model to training mode to enable behaviors like dropout and batch normalization\n",
        "\n",
        "        # 1. Forward pass: compute model predictions for the input batch\n",
        "        y_pred = model_0(X)\n",
        "\n",
        "        # 2. Compute loss between predictions and true labels\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()  # Accumulate loss to compute average later\n",
        "\n",
        "        # 3. Zero out gradients from the previous optimization step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Backward pass: compute gradients of the loss w.r.t. model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Update model parameters based on computed gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Optional: Print progress every 400 batches to monitor training\n",
        "        if batch % 400 == 0:\n",
        "            processed = batch * len(X)  # Number of images processed so far\n",
        "            total = len(train_dataloader.dataset)  # Total number of images in the dataset\n",
        "            print(f\"Processed {processed}/{total} images during training\")\n",
        "\n",
        "    # Calculate average training loss for the epoch by dividing total loss by number of batches\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    ### Testing Phase\n",
        "    test_loss, test_acc = 0, 0  # Initialize cumulative test loss and accuracy\n",
        "    model_0.eval()  # Set model to evaluation mode to disable dropout and batch normalization\n",
        "\n",
        "    with torch.inference_mode():  # Disable gradient calculations for faster computations during evaluation\n",
        "        for X_test, y_test in test_dataloader:\n",
        "            # 1. Forward pass: compute model predictions on the test data\n",
        "            test_pred = model_0(X_test)\n",
        "\n",
        "            # 2. Compute loss between predictions and true labels, accumulate the loss\n",
        "            test_loss += loss_fn(test_pred, y_test).item()\n",
        "\n",
        "            # 3. Calculate accuracy by comparing predicted labels to true labels\n",
        "            #    `argmax(dim=1)` selects the class with the highest predicted score\n",
        "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate average test loss by dividing total test loss by number of test batches\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Calculate average test accuracy by dividing total correct predictions by number of test batches\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "    # Display training and testing metrics for the current epoch\n",
        "    print(f\"Train Loss: {train_loss:.5f} | Test Loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "# End the training timer to measure total training duration\n",
        "train_time_end_on_cpu = timer()\n",
        "\n",
        "# Calculate and print the total training time using a custom function `print_train_time`\n",
        "# This function likely formats and displays the elapsed time along with the device used\n",
        "total_train_time_model_0 = print_train_time(\n",
        "    start=train_time_start_on_cpu,\n",
        "    end=train_time_end_on_cpu,\n",
        "    device=str(next(model_0.parameters()).device)  # Retrieves the device (CPU/GPU) the model is on\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz7fsNGa8fUG"
      },
      "source": [
        "Nice! Looks like our baseline model did fairly well.\n",
        "\n",
        "It didn't take too long to train either, even just on the CPU, I wonder if it'll speed up on the GPU?\n",
        "\n",
        "Let's write some code to evaluate our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1KhTgwS8fUG"
      },
      "source": [
        "## 4. Make predictions and get Model 0 results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma-bsud8fUG"
      },
      "source": [
        "\n",
        "Since we're going to be building a few models, it's a good idea to write some code to evaluate them all in similar ways.\n",
        "\n",
        "Namely, let's create a function that takes in a trained model, a `DataLoader`, a loss function and an accuracy function.\n",
        "\n",
        "The function will use the model to make predictions on the data in the `DataLoader` and then we can evaluate those predictions using the loss function and accuracy function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlRd8uqk8fUG",
        "outputId": "d42caf06-b78b-42ad-e771-0608a8a5dbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'FashionMNISTModelV0', 'model_loss': 0.47663894295692444, 'model_acc': 83.42651757188499}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model: torch.nn.Module,                # PyTorch model to evaluate\n",
        "              data_loader: torch.utils.data.DataLoader,  # DataLoader containing evaluation data\n",
        "              loss_fn: torch.nn.Module,              # Loss function to compute loss\n",
        "              accuracy_fn: callable):                # Function to compute accuracy\n",
        "    \"\"\"\n",
        "    Evaluates the given model on the provided dataset and returns performance metrics.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
        "        data_loader (torch.utils.data.DataLoader): A PyTorch DataLoader containing the data to predict on.\n",
        "        loss_fn (torch.nn.Module): A PyTorch loss function.\n",
        "        accuracy_fn (callable): A function for computing accuracy.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the model's name, average loss, and average accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    loss, acc = 0, 0  # Initialize cumulative loss and accuracy\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batchnorm, etc.)\n",
        "\n",
        "    with torch.inference_mode():  # Disable gradient calculations for faster computation and reduced memory usage\n",
        "        for X, y in data_loader:\n",
        "            # Move data to the same device as the model (e.g., CPU or GPU)\n",
        "            X, y = X.to(next(model.parameters()).device), y.to(next(model.parameters()).device)\n",
        "\n",
        "            # Forward pass: compute the model's predictions\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Compute the loss for the current batch and accumulate it\n",
        "            loss += loss_fn(y_pred, y)\n",
        "\n",
        "            # Compute the number of correct predictions and accumulate it\n",
        "            # y_pred.argmax(dim=1) selects the class with the highest score as the predicted label\n",
        "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        # Calculate average loss over all batches\n",
        "        loss /= len(data_loader)\n",
        "\n",
        "        # Calculate average accuracy over all batches\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    # Prepare the results dictionary with model name, average loss, and average accuracy\n",
        "    return {\n",
        "        \"model_name\": model.__class__.__name__,  # Retrieves the class name of the model\n",
        "        \"model_loss\": loss.item(),               # Converts the loss tensor to a Python float\n",
        "        \"model_acc\": acc                         # Average accuracy as a float\n",
        "    }\n",
        "\n",
        "# Example Usage:\n",
        "\n",
        "# Assuming you have a trained model `model_0`, a test DataLoader `test_dataloader`,\n",
        "# a loss function `loss_fn`, and an accuracy function `accuracy_fn` defined elsewhere.\n",
        "\n",
        "# Evaluate model_0 on the test dataset\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                            data_loader=test_dataloader,\n",
        "                            loss_fn=loss_fn,\n",
        "                            accuracy_fn=accuracy_fn)\n",
        "\n",
        "# Display the evaluation results\n",
        "print(model_0_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_csVDJZ8fUG"
      },
      "source": [
        "### Clarification of the use of `enumerate` in the training loop and its omission in the evaluation loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS716DbY8fUG"
      },
      "source": [
        "\n",
        "#### 1. Did We Absolutely Have to Use `enumerate` when training our model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7FH2Wvu8fUG"
      },
      "source": [
        "\n",
        "**Short Answer:**  \n",
        "No, using `enumerate` is not mandatory. It is optional and should be used based on whether you need access to the batch index within your loop.\n",
        "\n",
        "**Detailed Explanation:**\n",
        "\n",
        "- **Purpose of `enumerate`:**  \n",
        "  The `enumerate` function adds a counter to an iterable and returns it as an `enumerate` object. This allows you to access both the **index** (or count) and the **value** from the iterable in a single loop.\n",
        "\n",
        "- **When to Use `enumerate`:**\n",
        "  - **Logging & Monitoring:** If you want to log progress, print batch numbers, or perform actions at specific intervals (e.g., every 100 batches), `enumerate` provides the batch index essential for these tasks.\n",
        "  - **Conditional Operations:** Perform certain operations only on specific batches based on their index.\n",
        "\n",
        "- **When Not to Use `enumerate`:**\n",
        "  - **No Need for Index:** If your loop logic doesn't require knowing the current batch number, you can iterate directly over the DataLoader without using `enumerate`.\n",
        "\n",
        "**Conclusion:**  \n",
        "Use `enumerate` **only** when you need the batch index for tasks like logging, conditional processing, or tracking progress. Otherwise, it's perfectly fine to iterate directly over the DataLoader.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqj0Yaon8fUG"
      },
      "source": [
        "\n",
        "#### 2. Why Use `for batch, (X, y) in enumerate(train_dataloader):` in Training but `for X, y in data_loader:` in Evaluation?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHb6Q_9D8fUG"
      },
      "source": [
        "\n",
        "**Short Answer:**  \n",
        "In the training loop, `enumerate` is used to access the batch index for logging progress, while in the evaluation loop, the batch index isn't needed, so `enumerate` is omitted.\n",
        "\n",
        "**Detailed Explanation:**\n",
        "\n",
        "| **Scenario** | **Loop Structure** | **Reason** |\n",
        "|--------------|---------------------|------------|\n",
        "| **Training** | `for batch, (X, y) in enumerate(train_dataloader):` | Need batch index for logging and conditional operations. |\n",
        "| **Evaluation** | `for X, y in test_dataloader:` | No need for batch index; focus on aggregating metrics. |\n",
        "\n",
        "- **Training Loop with `enumerate`:**\n",
        "  - **Progress Logging:** The batch index (`batch`) is used to print progress messages at regular intervals, helping monitor how much of the training data has been processed.\n",
        "  - **Conditional Operations:** Allows performing specific actions based on the batch number, such as adjusting learning rates or saving checkpoints dynamically.\n",
        "\n",
        "- **Evaluation Loop without `enumerate`:**\n",
        "  - **No Need for Batch Index:** During evaluation, the primary goal is to aggregate metrics like loss and accuracy over the entire dataset. The batch index doesn't provide additional value.\n",
        "  - **Simplicity:** Omitting `enumerate` makes the loop cleaner and more focused on processing data rather than tracking its position.\n",
        "\n",
        "**Conclusion:**  \n",
        "In the **training loop**, `enumerate` is valuable for tracking progress, logging, and performing batch-specific operations. In the **evaluation loop**, since these needs are absent, you can iterate directly over the DataLoader without using `enumerate` for a more streamlined and efficient process.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t20ynK038fUG"
      },
      "source": [
        "\n",
        "#### 3. Practical Implications & Best Practices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt8ncD1u8fUH"
      },
      "source": [
        "\n",
        "- **Consistency:**  \n",
        "  While it's not mandatory to use `enumerate` in both training and evaluation loops, maintaining consistency can improve code readability. If you foresee the need for batch indices in the future (e.g., more detailed logging during evaluation), you might opt to include `enumerate` even in the evaluation loop.\n",
        "\n",
        "- **Performance:**  \n",
        "  Using `enumerate` has negligible performance implications. The choice to use it should be driven by the necessity of accessing the batch index rather than performance concerns.\n",
        "\n",
        "- **Code Readability:**  \n",
        "  Including `enumerate` when the index is not used can introduce unnecessary complexity. Aim for simplicity by omitting it when it's not needed.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f-e1zb88fUH"
      },
      "source": [
        "\n",
        "#### 4. Additional Recommendations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXDv60xi8fUH"
      },
      "source": [
        "\n",
        "- **Device Management:**  \n",
        "  Ensure that both your model and data are on the same device (CPU or GPU) to prevent runtime errors and optimize performance.\n",
        "\n",
        "- **Gradient Clipping:**  \n",
        "  To prevent exploding gradients, especially in deep networks, consider clipping gradients before the optimizer step.\n",
        "\n",
        "- **Learning Rate Scheduling:**  \n",
        "  Adjust the learning rate during training for potentially better convergence.\n",
        "\n",
        "- **Saving Checkpoints:**  \n",
        "  Periodically save model checkpoints during training to prevent loss of progress in case of interruptions.\n",
        "\n",
        "**Example Recommendations (Conceptual):**\n",
        "\n",
        "- **Device Handling:**  \n",
        "  Move both model and data to GPU if available to leverage faster computations.\n",
        "\n",
        "- **Progress Monitoring:**  \n",
        "  Use `enumerate` in training loops for periodic logging to monitor training progress effectively.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blQ9zyJ78fUH"
      },
      "source": [
        "\n",
        "#### 5. Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxqQ6yoy8fUH"
      },
      "source": [
        "\n",
        "- **`X` and `y`:**  \n",
        "  Represent the input data and corresponding labels for each batch, respectively.\n",
        "\n",
        "- **`enumerate`:**  \n",
        "  A Python function that adds a counter to an iterable, allowing access to both the index (`batch`) and the value (`(X, y)`) in each iteration.\n",
        "\n",
        "- **Loop Structure Differences:**  \n",
        "  - **Training Loop:** Uses `enumerate` to track batch indices for logging and conditional operations.\n",
        "  - **Evaluation Loop:** Omits `enumerate` as batch indices are unnecessary for aggregating metrics.\n",
        "\n",
        "**Understanding these components is crucial for effectively managing data flow and monitoring progress in your PyTorch models. Implement best practices to enhance code readability, maintainability, and performance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COZXz_Lt8fUH"
      },
      "source": [
        "## 5. Setup device agnostic-code (for using a GPU if there is one)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9-Oy1o18fUH"
      },
      "source": [
        "\n",
        "We've seen how long it takes to train ma PyTorch model on 60,000 samples on CPU.\n",
        "\n",
        "> **Note:** Model training time is dependent on hardware used. Generally, more processors means faster training and smaller models on smaller datasets will often train faster than large models and large datasets.\n",
        "\n",
        "Now let's setup some [device-agnostic code](https://pytorch.org/docs/stable/notes/cuda.html#best-practices) for our models and data to run on GPU if it's available.\n",
        "\n",
        "If you're running this notebook on Google Colab, and you don't have a GPU turned on yet, it's now time to turn one on via `Runtime -> Change runtime type -> Hardware accelerator -> GPU`. If you do this, your runtime will likely reset and you'll have to run all of the cells above by going `Runtime -> Run before`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEA2rLw88fUH",
        "outputId": "8713ee62-9ccd-4437-e508-72c41e8b48c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Device-Agnostic Code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVrl9JeY8fUH"
      },
      "source": [
        "## 6. Model 1: Building a better model with non-linearity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pgDtlDX8fUH"
      },
      "source": [
        "\n",
        "We learned about [the power of non-linearity in notebook 02](https://www.learnpytorch.io/02_pytorch_classification/#6-the-missing-piece-non-linearity).\n",
        "\n",
        "Seeing the data we've been working with, do you think it needs non-linear functions?\n",
        "\n",
        "And remember, linear means straight and non-linear means non-straight.\n",
        "\n",
        "Let's find out.\n",
        "\n",
        "We'll do so by recreating a similar model to before, except this time we'll put non-linear functions (`nn.ReLU()`) in between each linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rtLG1SDX8fUH"
      },
      "outputs": [],
      "source": [
        "class FashionMNISTModelV1(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape: int,\n",
        "                 hidden_units: int,\n",
        "                 output_shapes: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(nn.Flatten(),  # Flatten multi-dimensional input into a 1D vector\n",
        "                                         nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "                                         nn.ReLU(),     # Apply ReLU activation function\n",
        "                                         nn.Linear(in_features=hidden_units, out_features=output_shapes),\n",
        "                                         nn.ReLU())\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layer_stack(x)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oyhg0ZO8fUH"
      },
      "source": [
        "That looks good.\n",
        "\n",
        "Now let's instantiate it with the same settings we used before.\n",
        "\n",
        "We'll need `input_shape=784` (equal to the number of features of our image data), `hidden_units=10` (starting small and the same as our baseline model) and `output_shape=len(class_names)` (one output unit per class).\n",
        "\n",
        "> **Note:** Notice how we kept most of the settings of our model the same except for one change: adding non-linear layers. This is a standard practice for running a series of machine learning experiments, change one thing and see what happens, then do it again, again, again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekhjw5Vv8fUH",
        "outputId": "a0ef1b30-a688-4aa1-ae8d-db69bda235df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "model_1 = FashionMNISTModelV1(input_shape=784,  # 784 because of 28x28 images\n",
        "                              hidden_units=10,  # 10 hidden units because we have 10 classes\n",
        "                              output_shapes=len(class_names)    #  Sets the number of output neurons to match the number of classes for classification\n",
        ").to(device)\n",
        "\n",
        "next(model_1.parameters()).device   # Checks the device that model_1 is on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOIDPLes8fUH"
      },
      "source": [
        "### 6.1 Setup loss, optimizer and evaluation metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaFDpEQh8fUH"
      },
      "source": [
        "\n",
        "As usual, we'll setup a loss function, an optimizer and an evaluation metric (we could do multiple evaluation metrics but we'll stick with accuracy for now)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KYp_hQL88fUH"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrjKoE9C8fUH"
      },
      "source": [
        "### 6.2 Functionizing training and test loops\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1UIGt4q8fUH"
      },
      "source": [
        "\n",
        "So far we've been writing train and test loops over and over.\n",
        "\n",
        "Let's write them again but this time we'll put them in functions so they can be called again and again.\n",
        "\n",
        "And because we're using device-agnostic code now, we'll be sure to call `.to(device)` on our feature (`X`) and target (`y`) tensors.\n",
        "\n",
        "For the training loop we'll create a function called `train_step()` which takes in a model, a `DataLoader` a loss function and an optimizer.\n",
        "\n",
        "The testing loop will be similar but it'll be called `test_step()` and it'll take in a model, a `DataLoader`, a loss function and an evaluation function.\n",
        "\n",
        "> **Note:** Since these are functions, you can customize them in any way you like. What we're making here can be considered barebones training and testing functions for our specific classification use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TOC9BIK78fUH"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    \"\"\"\n",
        "    Executes one full pass through the training dataset, updating model parameters.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model to train.\n",
        "        data_loader (torch.utils.data.DataLoader): DataLoader providing training data batches.\n",
        "        loss_fn (torch.nn.Module): Loss function to compute the error between predictions and targets.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer to update model parameters based on gradients.\n",
        "        accuracy_fn (callable): Function to calculate accuracy given true and predicted labels.\n",
        "        device (torch.device): Device to perform computations on (CPU or GPU). Defaults to `device`.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    train_loss, train_acc = 0, 0  # Initialize cumulative loss and accuracy for the epoch\n",
        "    model.to(device)  # Move the model to the specified device (CPU or GPU)\n",
        "\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Send input data and labels to the designated device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass: compute model predictions for the input batch\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss between predictions and true labels\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss  # Accumulate loss for averaging later\n",
        "\n",
        "        # Calculate accuracy by comparing predicted labels to true labels\n",
        "        train_acc += accuracy_fn(\n",
        "            y_true=y,\n",
        "            y_pred=y_pred.argmax(dim=1)  # Convert logits to predicted class labels\n",
        "        )\n",
        "\n",
        "        # 3. Zero out gradients from the previous optimization step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Backward pass: compute gradients of the loss w.r.t. model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Update model parameters based on computed gradients\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate average loss and accuracy over all batches in the epoch\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "\n",
        "    # Print the training metrics for the epoch\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    \"\"\"\n",
        "    Evaluates the model's performance on the test dataset without updating parameters.\n",
        "\n",
        "    Args:\n",
        "        data_loader (torch.utils.data.DataLoader): DataLoader providing test data batches.\n",
        "        model (torch.nn.Module): The neural network model to evaluate.\n",
        "        loss_fn (torch.nn.Module): Loss function to compute the error between predictions and targets.\n",
        "        accuracy_fn (callable): Function to calculate accuracy given true and predicted labels.\n",
        "        device (torch.device): Device to perform computations on (CPU or GPU). Defaults to `device`.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    test_loss, test_acc = 0, 0  # Initialize cumulative loss and accuracy for evaluation\n",
        "    model.to(device)  # Move the model to the specified device (CPU or GPU)\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batchnorm, etc.)\n",
        "\n",
        "    # Disable gradient calculations for efficiency during evaluation\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Send input data and labels to the designated device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass: compute model predictions for the input batch\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss between predictions and true labels\n",
        "            test_loss += loss_fn(test_pred, y)  # Accumulate loss for averaging later\n",
        "\n",
        "            # Calculate accuracy by comparing predicted labels to true labels\n",
        "            test_acc += accuracy_fn(\n",
        "                y_true=y,\n",
        "                y_pred=test_pred.argmax(dim=1)  # Convert logits to predicted class labels\n",
        "            )\n",
        "\n",
        "        # Calculate average loss and accuracy over all batches in the test dataset\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "\n",
        "        # Print the evaluation metrics\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alTDvbaS8fUH"
      },
      "source": [
        "Woohoo!\n",
        "\n",
        "Now we've got some functions for training and testing our model, let's run them.\n",
        "\n",
        "We'll do so inside another loop for each epoch.\n",
        "\n",
        "That way, for each epoch, we're going through a training step and a testing step.\n",
        "\n",
        "> **Note:** You can customize how often you do a testing step. Sometimes people do them every five epochs or 10 epochs or in our case, every epoch.\n",
        "\n",
        "Let's also time things to see how long our code takes to run on the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdZ38nPx8fUH"
      },
      "source": [
        "#### Testing out our functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "1ffaa66bc057400486d70bc842ca88a0",
            "07f2e53ff753409d933310405fabe541",
            "27bdc6862d92470fa95355ba78ed203a",
            "5bf2ebae378f4f9594bf7627d3511caf",
            "8cc1bde438bd4831a7afb163eec20db7",
            "ab7381dcb147491791787f3f795c974f",
            "d7f199600dcf45aa901e73340f1edd91",
            "ddaa91cfc62a4a62bab8c292bd68a490",
            "49ce3ce1cf094a1bacfedad4e62c4d97",
            "588397756cf846c0acbe716171ad5b61",
            "98fe13f15b434c819f14e8542260cb3d"
          ]
        },
        "id": "ght7qr9A8fUH",
        "outputId": "81d587c6-51c1-4e83-b66b-a50984606753"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ffaa66bc057400486d70bc842ca88a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 1.09199 | Train accuracy: 61.34%\n",
            "Test loss: 0.95636 | Test accuracy: 65.00%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.78101 | Train accuracy: 71.93%\n",
            "Test loss: 0.72227 | Test accuracy: 73.91%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.67027 | Train accuracy: 75.94%\n",
            "Test loss: 0.68500 | Test accuracy: 75.02%\n",
            "\n",
            "Train time on cuda: 33.642 seconds\n"
          ]
        }
      ],
      "source": [
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure the start time of the training process\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "# Define the number of training epochs\n",
        "epochs = 3\n",
        "\n",
        "# Loop over each epoch\n",
        "for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):   # tqdm provides a progress bar, range(epochs) iterates over epochs\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "\n",
        "    # Perform a training step: forward pass, loss computation, backward pass, and optimization\n",
        "    train_step(\n",
        "        data_loader=train_dataloader,   # DataLoader providing training data batches\n",
        "        model=model_1,                  # The neural network model to train\n",
        "        loss_fn=loss_fn,                # Loss function to compute error between predictions and targets\n",
        "        optimizer=optimizer,            # Optimizer to update model parameters based on gradients\n",
        "        accuracy_fn=accuracy_fn         # Function to calculate accuracy of predictions\n",
        "    )\n",
        "\n",
        "    # Perform a testing step: evaluate model performance on the test dataset\n",
        "    test_step(\n",
        "        data_loader=test_dataloader,     # DataLoader providing test data batches\n",
        "        model=model_1,                   # The neural network model to evaluate\n",
        "        loss_fn=loss_fn,                 # Loss function to compute error between predictions and targets\n",
        "        accuracy_fn=accuracy_fn          # Function to calculate accuracy of predictions\n",
        "    )\n",
        "\n",
        "# Measure the end time of the training process\n",
        "train_time_end_on_gpu = timer()\n",
        "\n",
        "# Calculate and print the total training time\n",
        "total_train_time_model_1 = print_train_time(\n",
        "    start=train_time_start_on_gpu,     # Start time of training\n",
        "    end=train_time_end_on_gpu,         # End time of training\n",
        "    device=device                      # Device used for training (CPU or GPU)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbok1gJu8fUH"
      },
      "source": [
        "Excellent!\n",
        "\n",
        "Our model trained but the training time took longer?\n",
        "\n",
        "> **Note:** The training time on CUDA vs CPU will depend largely on the quality of the CPU/GPU you're using. Read on for a more explained answer.\n",
        "\n",
        "> **Question:** \"I used a GPU but my model didn't train faster, why might that be?\"\n",
        ">\n",
        "> **Answer:** Well, one reason could be because your dataset and model are both so small (like the dataset and model we're working with) the benefits of using a GPU are outweighed by the time it actually takes to transfer the data there.\n",
        ">\n",
        "> There's a small bottleneck between copying data from the CPU memory (default) to the GPU memory.\n",
        ">\n",
        "> So for smaller models and datasets, the CPU might actually be the optimal place to compute on.\n",
        ">\n",
        "> But for larger datasets and models, the speed of computing the GPU can offer usually far outweighs the cost of getting the data there.\n",
        ">\n",
        "> However, this is largely dependent on the hardware you're using. With practice, you will get used to where the best place to train your models is.\n",
        "\n",
        "Let's evaluate our trained `model_1` using our `eval_model()` function and see how it went."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uCwSKb-h8fUI",
        "outputId": "af80409c-abd6-4071-947e-3f277e3cc9bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel_1_results = eval_model(model=model_1, \\n    data_loader=test_dataloader,\\n    loss_fn=loss_fn, \\n    accuracy_fn=accuracy_fn) \\nmodel_1_results \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Note: This will error due to `eval_model()` not using device agnostic code\n",
        "'''\n",
        "model_1_results = eval_model(model=model_1,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn)\n",
        "model_1_results\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk3ckdZo8fUI"
      },
      "source": [
        "Oh no!\n",
        "\n",
        "It looks like our `eval_model()` function errors out with:\n",
        "\n",
        "> `RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)`\n",
        "\n",
        "It's because we've setup our data and model to use device-agnostic code but not our evaluation function, which we wrote earlier.\n",
        "\n",
        "How about we fix that by passing a target `device` parameter to our `eval_model()` function?\n",
        "\n",
        "Then we'll try calculating the results again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILkXkUpj8fUI"
      },
      "source": [
        "### `eval_model` Function Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftVWjl8M8fUI"
      },
      "source": [
        "\n",
        "The `eval_model()` function is designed to evaluate the performance of a PyTorch model on a given dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTybC9sx8fUI"
      },
      "source": [
        "\n",
        "#### Functionality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGIvcZNy8fUI"
      },
      "source": [
        "\n",
        "- **Purpose:** Computes the model's loss and accuracy on the evaluation dataset.\n",
        "- **Arguments:**\n",
        "  - `model` (`torch.nn.Module`): The PyTorch model to evaluate.\n",
        "  - `data_loader` (`torch.utils.data.DataLoader`): Provides batches of evaluation data.\n",
        "  - `loss_fn` (`torch.nn.Module`): Loss function to measure error between predictions and true labels.\n",
        "  - `accuracy_fn` (callable): Function to compute accuracy from true and predicted labels.\n",
        "  - `device` (`torch.device`): Specifies the computation device (CPU or GPU).\n",
        "- **Returns:** A dictionary with:\n",
        "  - `\"model_name\"`: The class name of the model.\n",
        "  - `\"model_loss\"`: The average loss across all evaluation batches.\n",
        "  - `\"model_acc\"`: The average accuracy across all evaluation batches.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcqLNYiC8fUI"
      },
      "source": [
        "\n",
        "#### Key Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i7glajH8fUI"
      },
      "source": [
        "\n",
        "- Uses device-agnostic code to move data and computations to the specified device.\n",
        "- Disables gradient calculations to improve evaluation efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjAVq6Ma8fUI"
      },
      "source": [
        "#### Pass a target `device` parameter to `eval_model()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxDVpVPL8fUI",
        "outputId": "cfce6fee-d2d4-42a5-e780-ec059429fcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'FashionMNISTModelV1', 'model_loss': 0.6850008964538574, 'model_acc': 75.01996805111821}\n"
          ]
        }
      ],
      "source": [
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    \"\"\"\n",
        "    Evaluates a given model on a specified dataset.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The PyTorch model to evaluate.\n",
        "        data_loader (torch.utils.data.DataLoader): DataLoader providing the dataset for evaluation.\n",
        "        loss_fn (torch.nn.Module): Loss function to compute the error between predictions and true labels.\n",
        "        accuracy_fn (callable): Function to calculate accuracy given true and predicted labels.\n",
        "        device (torch.device, optional): Device to perform computations on (CPU or GPU). Defaults to `device`.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing the model's name, average loss, and average accuracy.\n",
        "    \"\"\"\n",
        "    loss, acc = 0, 0  # Initialize cumulative loss and accuracy\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batchnorm, etc.)\n",
        "\n",
        "    # Disable gradient calculations for efficiency during evaluation\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Send input data and labels to the specified device (CPU or GPU)\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass: compute model predictions for the input batch\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Compute loss between predictions and true labels and accumulate it\n",
        "            loss += loss_fn(y_pred, y)\n",
        "\n",
        "            # Compute accuracy by comparing predicted labels to true labels and accumulate it\n",
        "            acc += accuracy_fn(\n",
        "                y_true=y,\n",
        "                y_pred=y_pred.argmax(dim=1)  # Convert logits to predicted class labels\n",
        "            )\n",
        "\n",
        "        # Calculate average loss and accuracy over all batches\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    # Return a dictionary with the model's name, average loss, and average accuracy\n",
        "    return {\"model_name\": model.__class__.__name__,  # Retrieves the class name of the model\n",
        "            \"model_loss\": loss.item(),               # Converts the loss tensor to a Python float\n",
        "             \"model_acc\": acc}                       # Average accuracy as a float\n",
        "\n",
        "\n",
        "# Evaluate model_1 on the test dataset using device-agnostic code\n",
        "model_1_results = eval_model(model=model_1,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             device=device)\n",
        "\n",
        "# Display the evaluation results\n",
        "print(model_1_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG1hKOTW8fUI"
      },
      "source": [
        "#### Unexpected Performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4csUXAC8fUI"
      },
      "source": [
        "\n",
        "Adding non-linearities made our model perform worse than the baseline. In machine learning, sometimes expected improvements don't materialize, and unexpected results can occur. It's part science, part art.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvP2JiX38fUI"
      },
      "source": [
        "\n",
        "#### Overfitting Observed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjEe7JE8fUI"
      },
      "source": [
        "Our model is **overfitting** the training data, meaning it learns the training patterns well but fails to generalize to the testing data. This lack of generalization means that while the model performs excellently on the training data, it struggles to make accurate predictions on new, unseen data because it hasn't learned the underlying patterns that apply broadly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luShleTt8fUI"
      },
      "source": [
        "\n",
        "#### Solutions to Overfitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uCNGs1T8fUI"
      },
      "source": [
        "\n",
        "Two main ways to address overfitting include:\n",
        "1. **Use a Smaller or Different Model:** Some models are better suited to certain types of data.\n",
        "2. **Use a Larger Dataset:** More data helps the model learn generalizable patterns.\n",
        "\n",
        "There are additional methods to explore. I encourage you to search online for \"ways to prevent overfitting in machine learning\" to discover more strategies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z524vNrU8fUI"
      },
      "source": [
        "\n",
        "#### Next Steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1PExIQH8fUI"
      },
      "source": [
        "\n",
        "Let's focus on the first solution: using a different model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEP1jksI8fUI"
      },
      "source": [
        "## 7. Model 2: Building a Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2AYwXTc8fUI"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Alright, time to step things up a notch.\n",
        "\n",
        "It's time to create a [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN or ConvNet).\n",
        "\n",
        "CNN's are known for their capabilities to find patterns in visual data.\n",
        "\n",
        "And since we're dealing with visual data, let's see if using a CNN model can improve upon our baseline.\n",
        "\n",
        "The CNN model we're going to be using is known as TinyVGG from the [CNN Explainer](https://poloclub.github.io/cnn-explainer/) website.\n",
        "\n",
        "It follows the typical structure of a convolutional neural network:\n",
        "\n",
        "`Input layer -> [Convolutional layer -> activation layer -> pooling layer] -> Output layer`\n",
        "\n",
        "Where the contents of `[Convolutional layer -> activation layer -> pooling layer]` can be upscaled and repeated multiple times, depending on requirements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qabBjqa58fUI"
      },
      "source": [
        "\n",
        "### Architecture of a CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtMv10-j8fUI"
      },
      "source": [
        "\n",
        "| **Hyperparameter/Layer type**       | **What does it do?**                                                        | **Typical values**                                                                                                     |\n",
        "|-------------------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n",
        "| **Input image(s)**                  | Target images you'd like to discover patterns in                            | Whatever you can take a photo (or video) of                                                                           |\n",
        "| **Input layer**                     | Takes in target images and processes them for further layers                | `input_shape = [batch_size, image_height, image_width, color_channels]` or `input_shape = [batch_size, channels, height, width]` |\n",
        "| **Convolution layer**               | Extracts/learns the most important features from target images               | Multiple, can create with `torch.nn.ConvXd()`                                                                         |\n",
        "| **Hidden activation/non-linear activation** | Adds non-linearity to learned features                                     | Usually ReLU (`torch.nn.ReLU()`), though there can be many more                                                       |\n",
        "| **Pooling layer**                   | Reduces the dimensionality of learned image features                        | Max (`torch.nn.MaxPool2d()`) or Average (`torch.nn.AvgPool2d()`)                                                      |\n",
        "| **Output layer/linear layer**       | Takes learned features and outputs them in shape of target labels           | `torch.nn.Linear(out_features=[number_of_classes])`                                                                   |\n",
        "| **Output activation**               | Converts output logits to prediction probabilities                          | `torch.sigmoid()` (binary classification) or `torch.softmax()` (multi-class classification)                           |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXbYhtWU8fUI"
      },
      "source": [
        "\n",
        "### Breakdown of `torch.nn.Conv2d` Layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83nkfGx68fUI"
      },
      "source": [
        "\n",
        "| **Hyperparameter name** | **What does it do?**                                                                                           | **Typical values**                                        |\n",
        "|--------------------------|--------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|\n",
        "| **`in_channels`**        | Defines the number of input channels of the input data                                                      | 1 (grayscale), 3 (RGB color images)                      |\n",
        "| **`out_channels`**       | Defines the number of output channels of the layer (could also be called hidden units)                      | 10, 128, 256, 512                                        |\n",
        "| **`kernel_size`**        | Determines the shape of the kernel (sliding windows) over the input                                         | 3, 5, 7 (lower values learn smaller features; higher values learn larger features) |\n",
        "| **`stride`**             | The number of steps a filter takes across an image at a time (e.g., `stride=1` moves across 1 pixel at a time) | 1 (default), 2                                           |\n",
        "| **`padding`**            | Pads the target tensor with zeroes (if \"same\") to preserve input shape, or leaves it as is (if \"valid\")       | 0, 1, \"same\", \"valid\"                                    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeY2tM838fUI"
      },
      "source": [
        "### What model should I use?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqQeVX48fUI"
      },
      "source": [
        "\n",
        "> **Question:** Wait, you say CNN's are good for images, are there any other model types I should be aware of?\n",
        "\n",
        "Good question.\n",
        "\n",
        "This table is a good general guide for which model to use (though there are exceptions).\n",
        "\n",
        "| **Problem type** | **Model to use (generally)** | **Code example** |\n",
        "| ----- | ----- | ----- |\n",
        "| Structured data (Excel spreadsheets, row and column data) | Gradient boosted models, Random Forests, XGBoost | [`sklearn.ensemble`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble), [XGBoost library](https://xgboost.readthedocs.io/en/stable/) |\n",
        "| Unstructured data (images, audio, language) | Convolutional Neural Networks, Transformers | [`torchvision.models`](https://pytorch.org/vision/stable/models.html), [HuggingFace Transformers](https://huggingface.co/docs/transformers/index) |\n",
        "\n",
        "> **Note:** The table above is only for reference, the model you end up using will be highly dependent on the problem you're working on and the constraints you have (amount of data, latency requirements).\n",
        "\n",
        "Enough talking about models, let's now build a CNN that replicates the model on the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "![TinyVGG architecture, as setup by CNN explainer website](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-cnn-explainer-model.png)\n",
        "\n",
        "To do so, we'll leverage the [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) layers from `torch.nn`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEvEQtsW8fUI",
        "outputId": "1be36d9a-b832-49c9-b189-30a2892332c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV2(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Create a convolutional neural network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "    TinyVGG is a small convolutional neural network designed for learning how CNNs work.\n",
        "    It consists of two convolutional blocks (Conv -> ReLU -> MaxPool) followed by a classifier.\n",
        "\n",
        "    Key Features:\n",
        "    - **Convolutional Layers**: Learn spatial patterns in images using sliding filters.\n",
        "    - **ReLU Activation**: Introduces non-linearity to the network.\n",
        "    - **Pooling Layers**: Reduce the spatial dimensions, which decreases computational requirements and helps prevent overfitting.\n",
        "    - **Fully Connected Layer**: Maps the extracted features to the final class predictions.\n",
        "\n",
        "    This implementation is adapted for the FashionMNIST dataset (28x28 grayscale images) but can be generalized to similar tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):     # def__init__ will be called when creating an instance of the class\n",
        "        super().__init__()          # Call the parent class constructor, which is nn.Module\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,  # Size of the filter; a 3x3 kernel captures small patterns like edges\n",
        "                      stride=1,       # Number of pixels the filter moves at a time (default is 1)\n",
        "                      padding=1),     # Adds 1-pixel padding around the image to preserve input dimensions\n",
        "            nn.ReLU(),                # Applies ReLU activation: sets negative values to 0, keeps positive values the same\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,  # Another 3x3 filter for extracting more complex patterns\n",
        "                      stride=1,       # Filter moves 1 pixel at a time\n",
        "                      padding=1),     # Preserves spatial dimensions with 1-pixel padding\n",
        "            nn.ReLU(),                # Adds non-linearity to the second convolutional layer\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)    # Reduces the spatial dimensions by half (28x28 -> 14x14)\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),  # First Conv layer of block 2 (14x14 -> 14x14)\n",
        "            nn.ReLU(),                                            # Non-linear activation\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),  # Second Conv layer of block 2 (14x14 -> 14x14)\n",
        "            nn.ReLU(),                                            # Non-linear activation\n",
        "            nn.MaxPool2d(2)                                       # Reduces spatial dimensions again (14x14 -> 7x7)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(                          # Classifier (fully connected layers)\n",
        "            nn.Flatten(),                                         # Converts the 7x7x(hidden_units) feature map into a 1D vector\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*7*7,              # 7x7 is the result of the two MaxPool2d operations\n",
        "                      out_features=output_shape)                 # Output shape matches the number of classes (e.g., 10 for FashionMNIST)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)      # Pass the input through the first convolutional block\n",
        "        # print(x.shape)         # Debugging tip: uncomment to check shape after block_1\n",
        "        x = self.block_2(x)      # Pass the result through the second convolutional block\n",
        "        # print(x.shape)         # Debugging tip: uncomment to check shape after block_2\n",
        "        x = self.classifier(x)   # Flatten and classify the features\n",
        "        # print(x.shape)         # Debugging tip: uncomment to check shape after classifier\n",
        "        return x\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the FashionMNISTModelV2 class\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,                              # 1 channel for grayscale images, 3 for RGB\n",
        "                              hidden_units=10,                            # Number of filters in the convolutional layers\n",
        "                              output_shape=len(class_names)).to(device)   # Output size matches the number of classes\n",
        "model_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ddU1lO8fUJ"
      },
      "source": [
        "Nice!\n",
        "\n",
        "Our biggest model yet!\n",
        "\n",
        "What we've done is a common practice in machine learning.\n",
        "\n",
        "Find a model architecture somewhere and replicate it with code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiVCXKTP8fUJ"
      },
      "source": [
        "\n",
        "#### Explanation for `self.classifier`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FgMvUZ8fUJ"
      },
      "source": [
        "\n",
        "\n",
        "- The `classifier` is the final stage of the CNN. It converts the features extracted by the convolutional and pooling layers into predictions for the output classes.\n",
        "\n",
        "- **Why flatten the data?**  \n",
        "\n",
        "    * After the convolutional and pooling layers, the output is a multi-dimensional tensor (e.g., `[batch_size, hidden_units, 7, 7]`). To use this as input for a fully connected layer, it must be reshaped (flattened) into a 1D vector for each sample.\n",
        "- **Why use a linear layer?**  \n",
        "\n",
        "    * The `nn.Linear` layer acts as a fully connected layer, which learns how to map the flattened features to the desired number of output classes (e.g., 10 for FashionMNIST). It ensures the network can make final predictions based on the learned patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIizUBOs8fUJ"
      },
      "source": [
        "#### Convolution Operation (`conv2d`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeRTFNVC8fUJ"
      },
      "source": [
        "\n",
        "\n",
        "##### a. **Kernel Size (`kernel_size`)**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyo6KXgV8fUJ"
      },
      "source": [
        "\n",
        "- **Definition**: The kernel (or filter) is a small matrix used to perform convolution operations on the input data. The `kernel_size` determines the dimensions of this matrix, typically represented as `(height, width)`.\n",
        "- **Purpose**: It helps in capturing local patterns and features from the input data. Smaller kernels can detect finer details, while larger kernels can capture broader structures.\n",
        "- **Effect of Increasing/Decreasing**:\n",
        "  - **Increasing `kernel_size`**: This increases the receptive field, allowing the network to consider more context around each pixel but reduces the number of parameters. It can lead to capturing more global information but might also result in losing finer details.\n",
        "  - **Decreasing `kernel_size`**: This narrows the focus, making the network more sensitive to local patterns and details. However, it may miss broader structures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS9RUT5U8fUJ"
      },
      "source": [
        "\n",
        "##### b. **Stride (`stride`)**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE0khHmm8fUJ"
      },
      "source": [
        "\n",
        "- **Definition**: The stride is the number of pixels by which the kernel moves across the input data during convolution.\n",
        "- **Purpose**: It controls the amount of overlap between adjacent convolutions. A larger stride can reduce spatial dimensions but increases information loss, while a smaller stride preserves more detail but results in higher computational cost.\n",
        "- **Effect of Increasing/Decreasing**:\n",
        "  - **Increasing `stride`**: This reduces the output size, leading to faster processing and less memory usage but potentially losing important details.\n",
        "  - **Decreasing `stride`**: This increases the output size, preserving more spatial information at the expense of higher computational demand.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6EyeMXd8fUJ"
      },
      "source": [
        "\n",
        "##### c. **Padding (`padding`)**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emvap0Zt8fUJ"
      },
      "source": [
        "\n",
        "- **Definition**: Padding is additional pixels added to the borders of the input data before applying convolution.\n",
        "- **Purpose**: It allows control over the spatial dimensions of the output feature maps. Proper padding can help in maintaining the same spatial dimensions after convolution, which is often desirable for certain architectures.\n",
        "- **Effect of Increasing/Decreasing**:\n",
        "  - **Increasing `padding`**: This increases the output size, preserving more spatial information and allowing the network to focus on broader areas without losing detail.\n",
        "  - **Decreasing `padding`**: This decreases the output size, potentially leading to loss of important edge or boundary information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zINaJDyv8fUJ"
      },
      "source": [
        "\n",
        "##### d. **What is `conv2d`?**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC_ERL-X8fUJ"
      },
      "source": [
        "\n",
        "- **Definition**: `conv2d` (2-dimensional convolution) is an operation that applies a set of learnable filters (kernels) to the input data, typically images, to extract features.\n",
        "- **Purpose**: It enables the network to detect patterns and structures in the input data by sliding these learned kernels across the entire image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxuZWXvW8fUJ"
      },
      "source": [
        "\n",
        "##### e. **How it Works**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZb5E2wg8fUJ"
      },
      "source": [
        "\n",
        "1. The kernel slides over the input matrix (image).\n",
        "2. At each position, it multiplies the overlapping elements of the input and kernel.\n",
        "3. These products are summed up to produce a single output value for that position in the output feature map.\n",
        "4. This process is repeated across the entire input, with adjustments for stride and padding as specified.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0SF_Mll8fUJ"
      },
      "source": [
        "#### Max Pooling (`maxpool2d`):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tKJT3vx8fUJ"
      },
      "source": [
        "\n",
        "##### f. **What is `maxpool2d`?**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSsrZwvL8fUJ"
      },
      "source": [
        "\n",
        "- **Definition**: `maxpool2d` (2-dimensional max pooling) is a downsampling technique that reduces the spatial dimensions of the feature maps while retaining the most important features.\n",
        "- **Purpose**: It helps in making the network more robust to variations in the input data and reduces computational load by decreasing the number of parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcwBeq2P8fUJ"
      },
      "source": [
        "\n",
        "##### g. **How it Works**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s7t5z378fUJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T5GsaZX8fUJ"
      },
      "source": [
        "\n",
        "1. The input data is divided into non-overlapping regions (or windows) based on a specified pool size (`pool_size`) and stride.\n",
        "2. For each window, the maximum value is selected and placed in the output feature map.\n",
        "3. This process effectively reduces the spatial dimensions of the feature maps, making the network faster to compute.\n",
        "\n",
        "#### Summary:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rOf7ngp8fUJ"
      },
      "source": [
        "\n",
        "- **Kernel Size**: Determines the receptive field size; larger sizes capture broader structures but lose finer details.\n",
        "- **Stride**: Controls the step size of the kernel across the input; larger strides reduce output size but may lose information.\n",
        "- **Padding**: Adjusts the spatial dimensions of the output; proper padding helps in maintaining useful spatial information.\n",
        "\n",
        "These concepts are foundational to understanding how convolutional neural networks process and extract meaningful features from data, particularly images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljCHUWDp8fUJ"
      },
      "source": [
        "### 7.1 Stepping through `nn.Conv2d()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQJqO_uf8fUJ"
      },
      "source": [
        "\n",
        "We could start using our model above and see what happens but let's first step through the two new layers we've added:\n",
        "* [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), also known as a convolutional layer.\n",
        "* [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html), also known as a max pooling layer.\n",
        "\n",
        "> **Question:** What does the \"2d\" in `nn.Conv2d()` stand for?\n",
        ">\n",
        "> The 2d is for 2-dimensional data. As in, our images have two dimensions: height and width. Yes, there's color channel dimension but each of the color channel dimensions have two dimensions too: height and width.\n",
        ">\n",
        "> For other dimensional data (such as 1D for text or 3D for 3D objects) there's also `nn.Conv1d()` and `nn.Conv3d()`.\n",
        "\n",
        "To test the layers out, let's create some toy data just like the data used on CNN Explainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--BzThHb8fUJ",
        "outputId": "e7c8377f-a4e6-4961-bb40-2444ac83b095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape: torch.Size([32, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
            "Single image shape: torch.Size([3, 64, 64]) -> [color_channels, height, width]\n",
            "Single image pixel values:\n",
            "tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
            "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
            "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
            "         ...,\n",
            "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
            "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
            "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
            "\n",
            "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
            "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
            "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
            "         ...,\n",
            "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
            "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
            "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
            "\n",
            "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
            "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
            "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
            "         ...,\n",
            "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
            "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
            "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
          ]
        }
      ],
      "source": [
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a sample batch of random numbers with the same size as an image batch\n",
        "# Dimensions: [batch_size, color_channels, height, width]\n",
        "images = torch.randn(size=(32, 3, 64, 64))  # Generates a batch of 32 random images with 3 color channels (e.g., RGB) and 64x64 pixels\n",
        "\n",
        "# Extract a single image from the batch for testing\n",
        "test_image = images[0]  # Selects the first image in the batch for inspection\n",
        "\n",
        "# Print the shape of the entire image batch\n",
        "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
        "# Expected output: torch.Size([32, 3, 64, 64])\n",
        "\n",
        "# Print the shape of the single test image\n",
        "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\")\n",
        "# Expected output: torch.Size([3, 64, 64])\n",
        "\n",
        "# Print the pixel values of the single test image\n",
        "print(f\"Single image pixel values:\\n{test_image}\")\n",
        "# Displays the tensor containing pixel values of the first image in the batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0-hnDLY8fUK"
      },
      "source": [
        "These aren't actual images but tensors with the same shape as images. We can use them to test the layers we've added to our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSm7w_DP8fUK"
      },
      "source": [
        "Let's create an example `nn.Conv2d()` with various parameters:\n",
        "* `in_channels` (int) - Number of channels in the input image.\n",
        "* `out_channels` (int) - Number of channels produced by the convolution.\n",
        "* `kernel_size` (int or tuple) - Size of the convolving kernel/filter.\n",
        "* `stride` (int or tuple, optional) - How big of a step the convolving kernel takes at a time. Default: 1.\n",
        "* `padding` (int, tuple, str) - Padding added to all four sides of input. Default: 0.\n",
        "\n",
        "![example of going through the different parameters of a Conv2d layer](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-conv2d-layer.gif)\n",
        "\n",
        "*Example of what happens when you change the hyperparameters of a `nn.Conv2d()` layer.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZFBObzn8fUK",
        "outputId": "3e65e5ff-3907-4b6e-d3ca-e05c935d9a08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.5396,  0.0516,  0.6454,  ..., -0.3673,  0.8711,  0.4256],\n",
              "         [ 0.3662,  1.0114, -0.5997,  ...,  0.8983,  0.2809, -0.2741],\n",
              "         [ 1.2664, -1.4054,  0.3727,  ..., -0.3409,  1.2191, -0.0463],\n",
              "         ...,\n",
              "         [-0.1541,  0.5132, -0.3624,  ..., -0.2360, -0.4609, -0.0035],\n",
              "         [ 0.2981, -0.2432,  1.5012,  ..., -0.6289, -0.7283, -0.5767],\n",
              "         [-0.0386, -0.0781, -0.0388,  ...,  0.2842,  0.4228, -0.1802]],\n",
              "\n",
              "        [[-0.2840, -0.0319, -0.4455,  ..., -0.7956,  1.5599, -1.2449],\n",
              "         [ 0.2753, -0.1262, -0.6541,  ..., -0.2211,  0.1999, -0.8856],\n",
              "         [-0.5404, -1.5489,  0.0249,  ..., -0.5932, -1.0913, -0.3849],\n",
              "         ...,\n",
              "         [ 0.3870, -0.4064, -0.8236,  ...,  0.1734, -0.4330, -0.4951],\n",
              "         [-0.1984, -0.6386,  1.0263,  ..., -0.9401, -0.0585, -0.7833],\n",
              "         [-0.6306, -0.2052, -0.3694,  ..., -1.3248,  0.2456, -0.7134]],\n",
              "\n",
              "        [[ 0.4414,  0.5100,  0.4846,  ..., -0.8484,  0.2638,  1.1258],\n",
              "         [ 0.8117,  0.3191, -0.0157,  ...,  1.2686,  0.2319,  0.5003],\n",
              "         [ 0.3212,  0.0485, -0.2581,  ...,  0.2258,  0.2587, -0.8804],\n",
              "         ...,\n",
              "         [-0.1144, -0.1869,  0.0160,  ..., -0.8346,  0.0974,  0.8421],\n",
              "         [ 0.2941,  0.4417,  0.5866,  ..., -0.1224,  0.4814, -0.4799],\n",
              "         [ 0.6059, -0.0415, -0.2028,  ...,  0.1170,  0.2521, -0.4372]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.2560, -0.0477,  0.6380,  ...,  0.6436,  0.7553, -0.7055],\n",
              "         [ 1.5595, -0.2209, -0.9486,  ..., -0.4876,  0.7754,  0.0750],\n",
              "         [-0.0797,  0.2471,  1.1300,  ...,  0.1505,  0.2354,  0.9576],\n",
              "         ...,\n",
              "         [ 1.1065,  0.6839,  1.2183,  ...,  0.3015, -0.1910, -0.1902],\n",
              "         [-0.3486, -0.7173, -0.3582,  ...,  0.4917,  0.7219,  0.1513],\n",
              "         [ 0.0119,  0.1017,  0.7839,  ..., -0.3752, -0.8127, -0.1257]],\n",
              "\n",
              "        [[ 0.3841,  1.1322,  0.1620,  ...,  0.7010,  0.0109,  0.6058],\n",
              "         [ 0.1664,  0.1873,  1.5924,  ...,  0.3733,  0.9096, -0.5399],\n",
              "         [ 0.4094, -0.0861, -0.7935,  ..., -0.1285, -0.9932, -0.3013],\n",
              "         ...,\n",
              "         [ 0.2688, -0.5630, -1.1902,  ...,  0.4493,  0.5404, -0.0103],\n",
              "         [ 0.0535,  0.4411,  0.5313,  ...,  0.0148, -1.0056,  0.3759],\n",
              "         [ 0.3031, -0.1590, -0.1316,  ..., -0.5384, -0.4271, -0.4876]],\n",
              "\n",
              "        [[-1.1865, -0.7280, -1.2331,  ..., -0.9013, -0.0542, -1.5949],\n",
              "         [-0.6345, -0.5920,  0.5326,  ..., -1.0395, -0.7963, -0.0647],\n",
              "         [-0.1132,  0.5166,  0.2569,  ...,  0.5595, -1.6881,  0.9485],\n",
              "         ...,\n",
              "         [-0.0254, -0.2669,  0.1927,  ..., -0.2917,  0.1088, -0.4807],\n",
              "         [-0.2609, -0.2328,  0.1404,  ..., -0.1325, -0.8436, -0.7524],\n",
              "         [-1.1399, -0.1751, -0.8705,  ...,  0.1589,  0.3377,  0.3493]]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a convolutional layer with the same dimensions as TinyVGG\n",
        "# (try changing any of the parameters and see what happens)\n",
        "conv_layer = nn.Conv2d(\n",
        "    in_channels=3,        # Number of input channels (e.g., 3 for RGB images)\n",
        "    out_channels=10,      # Number of output channels (filters) the convolution will produce\n",
        "    kernel_size=3,        # Size of the convolutional kernel/filter (3x3 in this case)\n",
        "    stride=1,             # Stride determines how the filter moves across the input image (1 pixel at a time)\n",
        "    padding=0             # Padding adds zero-padding around the input.\n",
        "                          # \"valid\" convolution means no padding (padding=0)\n",
        "                          # \"same\" convolution preserves the input dimensions (requires padding=1 for kernel_size=3)\n",
        ")  # also try using \"valid\" or \"same\" here\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_layer(test_image) # Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D20qQD98fUK"
      },
      "source": [
        "If we try to pass a single image in, we get a shape mismatch error:\n",
        "\n",
        "> `RuntimeError: Expected 4-dimensional input for 4-dimensional weight [10, 3, 3, 3], but got 3-dimensional input of size [3, 64, 64] instead`\n",
        ">\n",
        "> **Note:** If you're running PyTorch 1.11.0+, this error won't occur.\n",
        "\n",
        "This is because our `nn.Conv2d()` layer expects a 4-dimensional tensor as input with size `(N, C, H, W)` or `[batch_size, color_channels, height, width]`.\n",
        "\n",
        "Right now our single image `test_image` only has a shape of `[color_channels, height, width]` or `[3, 64, 64]`.\n",
        "\n",
        "We can fix this for a single image using `test_image.unsqueeze(dim=0)` to add an extra dimension for `N`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvp_l1858fUK",
        "outputId": "1c268add-500b-46f2-dd39-31352b1962dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Add extra dimension to test image\n",
        "test_image.unsqueeze(dim=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tg2VHJe8fUK",
        "outputId": "7e001c9b-fecc-46ce-b388-495909b53252"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 62, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Pass test image with extra dimension through conv_layer\n",
        "conv_layer(test_image.unsqueeze(dim=0)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r85ILt358fUK"
      },
      "source": [
        "Hmm, notice what happens to our shape (the same shape as the first layer of TinyVGG on [CNN Explainer](https://poloclub.github.io/cnn-explainer/)), we get different channel sizes as well as different pixel sizes.\n",
        "\n",
        "What if we changed the values of `conv_layer`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm81pu7f8fUK",
        "outputId": "901b0070-b772-49fd-c53e-ee184b18049f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 30, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a new conv_layer with different values (try setting these to whatever you like)\n",
        "conv_layer_2 = nn.Conv2d(in_channels=3, # same number of color channels as our input image\n",
        "                         out_channels=10,\n",
        "                         kernel_size=(5, 5), # kernel is usually a square so a tuple also works\n",
        "                         stride=2,\n",
        "                         padding=0)\n",
        "\n",
        "# Pass single image through new conv_layer_2 (this calls nn.Conv2d()'s forward() method on the input)\n",
        "conv_layer_2(test_image.unsqueeze(dim=0)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SeH1a898fUK"
      },
      "source": [
        "Woah, we get another shape change.\n",
        "\n",
        "Now our image is of shape `[1, 10, 30, 30]` (it will be different if you use different values) or `[batch_size=1, color_channels=10, height=30, width=30]`.\n",
        "\n",
        "What's going on here?\n",
        "\n",
        "Behind the scenes, our `nn.Conv2d()` is compressing the information stored in the image.\n",
        "\n",
        "It does this by performing operations on the input (our test image) against its internal parameters.\n",
        "\n",
        "The goal of this is similar to all of the other neural networks we've been building.\n",
        "\n",
        "Data goes in and the layers try to update their internal parameters (patterns) to lower the loss function thanks to some help of the optimizer.\n",
        "\n",
        "The only difference is *how* the different layers calculate their parameter updates or in PyTorch terms, the operation present in the layer `forward()` method.\n",
        "\n",
        "If we check out our `conv_layer_2.state_dict()` we'll find a similar weight and bias setup as we've seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk7ffRzL8fUK",
        "outputId": "c5f1c576-42bb-47ae-8a81-f9ce74907030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[[[ 0.0883,  0.0958, -0.0271,  0.1061, -0.0253],\n",
            "          [ 0.0233, -0.0562,  0.0678,  0.1018, -0.0847],\n",
            "          [ 0.1004,  0.0216,  0.0853,  0.0156,  0.0557],\n",
            "          [-0.0163,  0.0890,  0.0171, -0.0539,  0.0294],\n",
            "          [-0.0532, -0.0135, -0.0469,  0.0766, -0.0911]],\n",
            "\n",
            "         [[-0.0532, -0.0326, -0.0694,  0.0109, -0.1140],\n",
            "          [ 0.1043, -0.0981,  0.0891,  0.0192, -0.0375],\n",
            "          [ 0.0714,  0.0180,  0.0933,  0.0126, -0.0364],\n",
            "          [ 0.0310, -0.0313,  0.0486,  0.1031,  0.0667],\n",
            "          [-0.0505,  0.0667,  0.0207,  0.0586, -0.0704]],\n",
            "\n",
            "         [[-0.1143, -0.0446, -0.0886,  0.0947,  0.0333],\n",
            "          [ 0.0478,  0.0365, -0.0020,  0.0904, -0.0820],\n",
            "          [ 0.0073, -0.0788,  0.0356, -0.0398,  0.0354],\n",
            "          [-0.0241,  0.0958, -0.0684, -0.0689, -0.0689],\n",
            "          [ 0.1039,  0.0385,  0.1111, -0.0953, -0.1145]]],\n",
            "\n",
            "\n",
            "        [[[-0.0903, -0.0777,  0.0468,  0.0413,  0.0959],\n",
            "          [-0.0596, -0.0787,  0.0613, -0.0467,  0.0701],\n",
            "          [-0.0274,  0.0661, -0.0897, -0.0583,  0.0352],\n",
            "          [ 0.0244, -0.0294,  0.0688,  0.0785, -0.0837],\n",
            "          [-0.0616,  0.1057, -0.0390, -0.0409, -0.1117]],\n",
            "\n",
            "         [[-0.0661,  0.0288, -0.0152, -0.0838,  0.0027],\n",
            "          [-0.0789, -0.0980, -0.0636, -0.1011, -0.0735],\n",
            "          [ 0.1154,  0.0218,  0.0356, -0.1077, -0.0758],\n",
            "          [-0.0384,  0.0181, -0.1016, -0.0498, -0.0691],\n",
            "          [ 0.0003, -0.0430, -0.0080, -0.0782, -0.0793]],\n",
            "\n",
            "         [[-0.0674, -0.0395, -0.0911,  0.0968, -0.0229],\n",
            "          [ 0.0994,  0.0360, -0.0978,  0.0799, -0.0318],\n",
            "          [-0.0443, -0.0958, -0.1148,  0.0330, -0.0252],\n",
            "          [ 0.0450, -0.0948,  0.0857, -0.0848, -0.0199],\n",
            "          [ 0.0241,  0.0596,  0.0932,  0.1052, -0.0916]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0291, -0.0497, -0.0127, -0.0864,  0.1052],\n",
            "          [-0.0847,  0.0617,  0.0406,  0.0375, -0.0624],\n",
            "          [ 0.1050,  0.0254,  0.0149, -0.1018,  0.0485],\n",
            "          [-0.0173, -0.0529,  0.0992,  0.0257, -0.0639],\n",
            "          [-0.0584, -0.0055,  0.0645, -0.0295, -0.0659]],\n",
            "\n",
            "         [[-0.0395, -0.0863,  0.0412,  0.0894, -0.1087],\n",
            "          [ 0.0268,  0.0597,  0.0209, -0.0411,  0.0603],\n",
            "          [ 0.0607,  0.0432, -0.0203, -0.0306,  0.0124],\n",
            "          [-0.0204, -0.0344,  0.0738,  0.0992, -0.0114],\n",
            "          [-0.0259,  0.0017, -0.0069,  0.0278,  0.0324]],\n",
            "\n",
            "         [[-0.1049, -0.0426,  0.0972,  0.0450, -0.0057],\n",
            "          [-0.0696, -0.0706, -0.1034, -0.0376,  0.0390],\n",
            "          [ 0.0736,  0.0533, -0.1021, -0.0694, -0.0182],\n",
            "          [ 0.1117,  0.0167, -0.0299,  0.0478, -0.0440],\n",
            "          [-0.0747,  0.0843, -0.0525, -0.0231, -0.1149]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0773,  0.0875,  0.0421, -0.0805, -0.1140],\n",
            "          [-0.0938,  0.0861,  0.0554,  0.0972,  0.0605],\n",
            "          [ 0.0292, -0.0011, -0.0878, -0.0989, -0.1080],\n",
            "          [ 0.0473, -0.0567, -0.0232, -0.0665, -0.0210],\n",
            "          [-0.0813, -0.0754,  0.0383, -0.0343,  0.0713]],\n",
            "\n",
            "         [[-0.0370, -0.0847, -0.0204, -0.0560, -0.0353],\n",
            "          [-0.1099,  0.0646, -0.0804,  0.0580,  0.0524],\n",
            "          [ 0.0825, -0.0886,  0.0830, -0.0546,  0.0428],\n",
            "          [ 0.1084, -0.0163, -0.0009, -0.0266, -0.0964],\n",
            "          [ 0.0554, -0.1146,  0.0717,  0.0864,  0.1092]],\n",
            "\n",
            "         [[-0.0272, -0.0949,  0.0260,  0.0638, -0.1149],\n",
            "          [-0.0262, -0.0692, -0.0101, -0.0568, -0.0472],\n",
            "          [-0.0367, -0.1097,  0.0947,  0.0968, -0.0181],\n",
            "          [-0.0131, -0.0471, -0.1043, -0.1124,  0.0429],\n",
            "          [-0.0634, -0.0742, -0.0090, -0.0385, -0.0374]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0037, -0.0245, -0.0398, -0.0553, -0.0940],\n",
            "          [ 0.0968, -0.0462,  0.0306, -0.0401,  0.0094],\n",
            "          [ 0.1077,  0.0532, -0.1001,  0.0458,  0.1096],\n",
            "          [ 0.0304,  0.0774,  0.1138, -0.0177,  0.0240],\n",
            "          [-0.0803, -0.0238,  0.0855,  0.0592, -0.0731]],\n",
            "\n",
            "         [[-0.0926, -0.0789, -0.1140, -0.0891, -0.0286],\n",
            "          [ 0.0779,  0.0193, -0.0878, -0.0926,  0.0574],\n",
            "          [-0.0859, -0.0142,  0.0554, -0.0534, -0.0126],\n",
            "          [-0.0101, -0.0273, -0.0585, -0.1029, -0.0933],\n",
            "          [-0.0618,  0.1115, -0.0558, -0.0775,  0.0280]],\n",
            "\n",
            "         [[ 0.0318,  0.0633,  0.0878,  0.0643, -0.1145],\n",
            "          [ 0.0102,  0.0699, -0.0107, -0.0680,  0.1101],\n",
            "          [-0.0432, -0.0657, -0.1041,  0.0052,  0.0512],\n",
            "          [ 0.0256,  0.0228, -0.0876, -0.1078,  0.0020],\n",
            "          [ 0.1053,  0.0666, -0.0672, -0.0150, -0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0557,  0.0209,  0.0629,  0.0957, -0.1060],\n",
            "          [ 0.0772, -0.0814,  0.0432,  0.0977,  0.0016],\n",
            "          [ 0.1051, -0.0984, -0.0441,  0.0673, -0.0252],\n",
            "          [-0.0236, -0.0481,  0.0796,  0.0566,  0.0370],\n",
            "          [-0.0649, -0.0937,  0.0125,  0.0342, -0.0533]],\n",
            "\n",
            "         [[-0.0323,  0.0780,  0.0092,  0.0052, -0.0284],\n",
            "          [-0.1046, -0.1086, -0.0552, -0.0587,  0.0360],\n",
            "          [-0.0336, -0.0452,  0.1101,  0.0402,  0.0823],\n",
            "          [-0.0559, -0.0472,  0.0424, -0.0769, -0.0755],\n",
            "          [-0.0056, -0.0422, -0.0866,  0.0685,  0.0929]],\n",
            "\n",
            "         [[ 0.0187, -0.0201, -0.1070, -0.0421,  0.0294],\n",
            "          [ 0.0544, -0.0146, -0.0457,  0.0643, -0.0920],\n",
            "          [ 0.0730, -0.0448,  0.0018, -0.0228,  0.0140],\n",
            "          [-0.0349,  0.0840, -0.0030,  0.0901,  0.1110],\n",
            "          [-0.0563, -0.0842,  0.0926,  0.0905, -0.0882]]],\n",
            "\n",
            "\n",
            "        [[[-0.0089, -0.1139, -0.0945,  0.0223,  0.0307],\n",
            "          [ 0.0245, -0.0314,  0.1065,  0.0165, -0.0681],\n",
            "          [-0.0065,  0.0277,  0.0404, -0.0816,  0.0433],\n",
            "          [-0.0590, -0.0959, -0.0631,  0.1114,  0.0987],\n",
            "          [ 0.1034,  0.0678,  0.0872, -0.0155, -0.0635]],\n",
            "\n",
            "         [[ 0.0577, -0.0598, -0.0779, -0.0369,  0.0242],\n",
            "          [ 0.0594, -0.0448, -0.0680,  0.0156, -0.0681],\n",
            "          [-0.0752,  0.0602, -0.0194,  0.1055,  0.1123],\n",
            "          [ 0.0345,  0.0397,  0.0266,  0.0018, -0.0084],\n",
            "          [ 0.0016,  0.0431,  0.1074, -0.0299, -0.0488]],\n",
            "\n",
            "         [[-0.0280, -0.0558,  0.0196,  0.0862,  0.0903],\n",
            "          [ 0.0530, -0.0850, -0.0620, -0.0254, -0.0213],\n",
            "          [ 0.0095, -0.1060,  0.0359, -0.0881, -0.0731],\n",
            "          [-0.0960,  0.1006, -0.1093,  0.0871, -0.0039],\n",
            "          [-0.0134,  0.0722, -0.0107,  0.0724,  0.0835]]],\n",
            "\n",
            "\n",
            "        [[[-0.1003,  0.0444,  0.0218,  0.0248,  0.0169],\n",
            "          [ 0.0316, -0.0555, -0.0148,  0.1097,  0.0776],\n",
            "          [-0.0043, -0.1086,  0.0051, -0.0786,  0.0939],\n",
            "          [-0.0701, -0.0083, -0.0256,  0.0205,  0.1087],\n",
            "          [ 0.0110,  0.0669,  0.0896,  0.0932, -0.0399]],\n",
            "\n",
            "         [[-0.0258,  0.0556, -0.0315,  0.0541, -0.0252],\n",
            "          [-0.0783,  0.0470,  0.0177,  0.0515,  0.1147],\n",
            "          [ 0.0788,  0.1095,  0.0062, -0.0993, -0.0810],\n",
            "          [-0.0717, -0.1018, -0.0579, -0.1063, -0.1065],\n",
            "          [-0.0690, -0.1138, -0.0709,  0.0440,  0.0963]],\n",
            "\n",
            "         [[-0.0343, -0.0336,  0.0617, -0.0570, -0.0546],\n",
            "          [ 0.0711, -0.1006,  0.0141,  0.1020,  0.0198],\n",
            "          [ 0.0314, -0.0672, -0.0016,  0.0063,  0.0283],\n",
            "          [ 0.0449,  0.1003, -0.0881,  0.0035, -0.0577],\n",
            "          [-0.0913, -0.0092, -0.1016,  0.0806,  0.0134]]],\n",
            "\n",
            "\n",
            "        [[[-0.0622,  0.0603, -0.1093, -0.0447, -0.0225],\n",
            "          [-0.0981, -0.0734, -0.0188,  0.0876,  0.1115],\n",
            "          [ 0.0735, -0.0689, -0.0755,  0.1008,  0.0408],\n",
            "          [ 0.0031,  0.0156, -0.0928, -0.0386,  0.1112],\n",
            "          [-0.0285, -0.0058, -0.0959, -0.0646, -0.0024]],\n",
            "\n",
            "         [[-0.0717, -0.0143,  0.0470, -0.1130,  0.0343],\n",
            "          [-0.0763, -0.0564,  0.0443,  0.0918, -0.0316],\n",
            "          [-0.0474, -0.1044, -0.0595, -0.1011, -0.0264],\n",
            "          [ 0.0236, -0.1082,  0.1008,  0.0724, -0.1130],\n",
            "          [-0.0552,  0.0377, -0.0237, -0.0126, -0.0521]],\n",
            "\n",
            "         [[ 0.0927, -0.0645,  0.0958,  0.0075,  0.0232],\n",
            "          [ 0.0901, -0.0190, -0.0657, -0.0187,  0.0937],\n",
            "          [-0.0857,  0.0262, -0.1135,  0.0605,  0.0427],\n",
            "          [ 0.0049,  0.0496,  0.0001,  0.0639, -0.0914],\n",
            "          [-0.0170,  0.0512,  0.1150,  0.0588, -0.0840]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0257, -0.0247, -0.1050, -0.0182],\n",
            "          [ 0.0817,  0.0161, -0.0673,  0.0355, -0.0370],\n",
            "          [ 0.1054, -0.1002, -0.0365, -0.1115, -0.0455],\n",
            "          [ 0.0364,  0.1112,  0.0194,  0.1132,  0.0226],\n",
            "          [ 0.0667,  0.0926,  0.0965, -0.0646,  0.1062]],\n",
            "\n",
            "         [[ 0.0699, -0.0540, -0.0551, -0.0969,  0.0290],\n",
            "          [-0.0936,  0.0488,  0.0365, -0.1003,  0.0315],\n",
            "          [-0.0094,  0.0527,  0.0663, -0.1148,  0.1059],\n",
            "          [ 0.0968,  0.0459, -0.1055, -0.0412, -0.0335],\n",
            "          [-0.0297,  0.0651,  0.0420,  0.0915, -0.0432]],\n",
            "\n",
            "         [[ 0.0389,  0.0411, -0.0961, -0.1120, -0.0599],\n",
            "          [ 0.0790, -0.1087, -0.1005,  0.0647,  0.0623],\n",
            "          [ 0.0950, -0.0872, -0.0845,  0.0592,  0.1004],\n",
            "          [ 0.0691,  0.0181,  0.0381,  0.1096, -0.0745],\n",
            "          [-0.0524,  0.0808, -0.0790, -0.0637,  0.0843]]]])), ('bias', tensor([ 0.0364,  0.0373, -0.0489, -0.0016,  0.1057, -0.0693,  0.0009,  0.0549,\n",
            "        -0.0797,  0.1121]))])\n"
          ]
        }
      ],
      "source": [
        "# Check out the conv_layer_2 internal parameters\n",
        "print(conv_layer_2.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZERzfQb98fUK"
      },
      "source": [
        "Look at that! A bunch of random numbers for a weight and bias tensor.\n",
        "\n",
        "The shapes of these are manipulated by the inputs we passed to `nn.Conv2d()` when we set it up.\n",
        "\n",
        "Let's check them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJY8xoLy8fUK",
        "outputId": "f9b20304-b70c-4be9-f25a-d25007c09745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_layer_2 weight shape: \n",
            "torch.Size([10, 3, 5, 5]) -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\n",
            "\n",
            "conv_layer_2 bias shape: \n",
            "torch.Size([10]) -> [out_channels=10]\n"
          ]
        }
      ],
      "source": [
        "# Get shapes of weight and bias tensors within conv_layer_2\n",
        "print(f\"conv_layer_2 weight shape: \\n{conv_layer_2.weight.shape} -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\")\n",
        "print(f\"\\nconv_layer_2 bias shape: \\n{conv_layer_2.bias.shape} -> [out_channels=10]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI3zVk9b8fUK"
      },
      "source": [
        "> **Question:** What should we set the parameters of our `nn.Conv2d()` layers?\n",
        ">\n",
        "> That's a good one. But similar to many other things in machine learning, the values of these aren't set in stone (and recall, because these values are ones we can set ourselves, they're referred to as \"**hyperparameters**\").\n",
        ">\n",
        "> The best way to find out is to try out different values and see how they effect your model's performance.\n",
        ">\n",
        "> Or even better, find a working example on a problem similar to yours (like we've done with TinyVGG) and copy it.\n",
        "\n",
        "We're working with a different of layer here to what we've seen before.\n",
        "\n",
        "But the premise remains the same: start with random numbers and update them to better represent the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irEdu6Ye8fUK"
      },
      "source": [
        "### 7.2 Stepping through `nn.MaxPool2d()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeA6WxBI8fUK"
      },
      "source": [
        "\n",
        "Now let's check out what happens when we move data through `nn.MaxPool2d()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zouxPBU18fUK",
        "outputId": "e2fb33c0-9996-41e7-d6ac-aa596929fc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test image original shape: torch.Size([3, 64, 64])\n",
            "Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n",
            "Shape after going through conv_layer(): torch.Size([1, 10, 62, 62])\n",
            "Shape after going through conv_layer() and max_pool_layer(): torch.Size([1, 10, 31, 31])\n"
          ]
        }
      ],
      "source": [
        "# Print out original image shape without and with unsqueezed dimension\n",
        "print(f\"Test image original shape: {test_image.shape}\")  # Displays the shape of the test_image tensor: [color_channels, height, width]\n",
        "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")  # dim=0 adds a batch dimension and displays the new shape: [1, color_channels, height, width]\n",
        "\n",
        "# Create a sample nn.MaxPool2d() layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)  # Initializes a max pooling layer with a 2x2 window to downsample the input\n",
        "\n",
        "# Pass data through just the conv_layer\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))  # Applies the convolutional layer to the test_image with added batch dimension\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")  # Prints the shape of the output after convolution: [1, out_channels, new_height, new_width]\n",
        "\n",
        "# Pass data through the max pool layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)  # Applies the max pooling layer to the convolutional output to reduce spatial dimensions\n",
        "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")  # Prints the shape after pooling: [1, out_channels, pooled_height, pooled_width]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs9wsQPN8fUK"
      },
      "source": [
        "Notice the change in the shapes of what's happening in and out of a `nn.MaxPool2d()` layer.\n",
        "\n",
        "The `kernel_size` of the `nn.MaxPool2d()` layer will affect the size of the output shape.\n",
        "\n",
        "In our case, the shape halves from a `62x62` image to `31x31` image.\n",
        "\n",
        "Let's see this work with a smaller tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to1s5vGe8fUK",
        "outputId": "560870fc-861e-46ee-e260-da25f4de6c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor:\n",
            "tensor([[[[0.3367, 0.1288],\n",
            "          [0.2345, 0.2303]]]])\n",
            "Random tensor shape: torch.Size([1, 1, 2, 2])\n",
            "\n",
            "Max pool tensor:\n",
            "tensor([[[[0.3367]]]]) <- this is the maximum value from random_tensor\n",
            "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a random tensor with a similar number of dimensions to our images\n",
        "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
        "print(f\"Random tensor:\\n{random_tensor}\")\n",
        "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
        "\n",
        "# Create a max pool layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2) # see what happens when you change the kernel_size value\n",
        "\n",
        "# Pass the random tensor through the max pool layer\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor:\\n{max_pool_tensor} <- this is the maximum value from random_tensor\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt40ptSF8fUK"
      },
      "source": [
        "Notice the final two dimensions between `random_tensor` and `max_pool_tensor`, they go from `[2, 2]` to `[1, 1]`.\n",
        "\n",
        "In essence, they get halved.\n",
        "\n",
        "And the change would be different for different values of `kernel_size` for `nn.MaxPool2d()`.\n",
        "\n",
        "Also notice the value leftover in `max_pool_tensor` is the **maximum** value from `random_tensor`.\n",
        "\n",
        "What's happening here?\n",
        "\n",
        "This is another important piece of the puzzle of neural networks.\n",
        "\n",
        "Essentially, **every layer in a neural network is trying to compress data from higher dimensional space to lower dimensional space**.\n",
        "\n",
        "In other words, take a lot of numbers (raw data) and learn patterns in those numbers, patterns that are predictive whilst also being *smaller* in size than the original values.\n",
        "\n",
        "From an artificial intelligence perspective, you could consider the whole goal of a neural network to *compress* information.\n",
        "\n",
        "![each layer of a neural network compresses the original input data into a smaller representation that is (hopefully) capable of making predictions on future input data](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-conv-net-as-compression.png)\n",
        "\n",
        "This means, that from the point of view of a neural network, intelligence is compression.\n",
        "\n",
        "This is the idea of the use of a `nn.MaxPool2d()` layer: take the maximum value from a portion of a tensor and disregard the rest.\n",
        "\n",
        "In essence, lowering the dimensionality of a tensor whilst still retaining a (hopefully) significant portion of the information.\n",
        "\n",
        "It is the same story for a `nn.Conv2d()` layer.\n",
        "\n",
        "Except instead of just taking the maximum, the `nn.Conv2d()` performs a convolutional operation on the data (see this in action on the [CNN Explainer webpage](https://poloclub.github.io/cnn-explainer/)).\n",
        "\n",
        "> **Exercise:** What do you think the [`nn.AvgPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) layer does? Try making a random tensor like we did above and passing it through. Check the input and output shapes as well as the input and output values.\n",
        "\n",
        "> **Extra-curriculum:** Lookup \"most common convolutional neural networks\", what architectures do you find? Are any of them contained within the [`torchvision.models`](https://pytorch.org/vision/stable/models.html) library? What do you think you could do with these?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkxyKXfn8fUL"
      },
      "source": [
        "### 7.3 Setup a loss function and optimizer for `model_2`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR8p_yBf8fUL"
      },
      "source": [
        "\n",
        "We've stepped through the layers in our first CNN enough.\n",
        "\n",
        "But remember, if something still isn't clear, try starting small.\n",
        "\n",
        "Pick a single layer of a model, pass some data through it and see what happens.\n",
        "\n",
        "Now it's time to move forward and get to training!\n",
        "\n",
        "Let's setup a loss function and an optimizer.\n",
        "\n",
        "We'll use the functions as before, `nn.CrossEntropyLoss()` as the loss function (since we're working with multi-class classification data).\n",
        "\n",
        "And `torch.optim.SGD()` as the optimizer to optimize `model_2.parameters()` with a learning rate of `0.1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "A_0GK72l8fUL"
      },
      "outputs": [],
      "source": [
        "# Setup a loss function and optimizer\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc1quxl18fUL"
      },
      "source": [
        "### 7.4 Training and testing `model_2` using our training and test functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wuvKO9V8fUL"
      },
      "source": [
        "\n",
        "Loss and optimizer ready!\n",
        "\n",
        "Time to train and test.\n",
        "\n",
        "We'll use our `train_step()` and `test_step()` functions we created before.\n",
        "\n",
        "We'll also measure the time to compare it to our other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "dc4f55a9fd4a4dfa849d905855608d8b",
            "f741bdfd8d79480a83860b6264e76deb",
            "be23dd80ee8240ea871f4956960b9461",
            "9ad8e6897f3c4cf285fdc0637e715b36",
            "6daacc8d48334140a4bd5944f828a515",
            "d34482e6598e433fa04779c8b69920e3",
            "6893d1c839e34fff9c471e5b82260d4b",
            "80e80c739b4c4875a00bc5845026b960",
            "04f624f7b381429eae976160008d28e3",
            "2827a62ca4e848168d4b91c79f2f00aa",
            "3a99c2822bba457b94da64fe9c633c53"
          ]
        },
        "id": "0RPbJDY48fUL",
        "outputId": "f582474c-a1e9-4b7c-cffe-ef8b5ec1f930"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc4f55a9fd4a4dfa849d905855608d8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 0.59355 | Train accuracy: 78.39%\n",
            "Test loss: 0.39711 | Test accuracy: 86.03%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.35529 | Train accuracy: 87.27%\n",
            "Test loss: 0.34269 | Test accuracy: 87.69%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.31593 | Train accuracy: 88.56%\n",
            "Test loss: 0.31293 | Test accuracy: 88.64%\n",
            "\n",
            "Train time on cuda: 37.508 seconds\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "# Train and test model\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step(model=model_2,\n",
        "               data_loader=train_dataloader,\n",
        "               loss_fn=loss_fn,\n",
        "               optimizer=optimizer,\n",
        "               accuracy_fn=accuracy_fn,\n",
        "               device=device\n",
        "    )\n",
        "\n",
        "    test_step(model=model_2,\n",
        "              data_loader=test_dataloader,\n",
        "              accuracy_fn=accuracy_fn,\n",
        "              loss_fn=loss_fn,\n",
        "              device=device\n",
        "    )\n",
        "\n",
        "train_time_end_model_2 = timer()\n",
        "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
        "                                            end=train_time_end_model_2,\n",
        "                                            device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA7wn7gr8fUL"
      },
      "source": [
        "Woah! Looks like the convolutional and max pooling layers helped improve performance a little.\n",
        "\n",
        "Let's evaluate `model_2`'s results with our `eval_model()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzZAs75H8fUL",
        "outputId": "2d273615-6d60-4597-f106-35ff11d72a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'FashionMNISTModelV2', 'model_loss': 0.31292983889579773, 'model_acc': 88.63817891373802}\n"
          ]
        }
      ],
      "source": [
        "# Get model_2's results\n",
        "model_2_results = eval_model(model=model_2,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             device=device)\n",
        "print(model_2_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffd-twNl8fUL"
      },
      "source": [
        "## 8. Compare model results and training time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxC0c_9J8fUL"
      },
      "source": [
        "\n",
        "We've trained three different models.\n",
        "\n",
        "1. `model_0` - our baseline model with two `nn.Linear()` layers.\n",
        "2. `model_1` - the same setup as our baseline model except with `nn.ReLU()` layers in between the `nn.Linear()` layers.\n",
        "3. `model_2` - our first CNN model that mimics the TinyVGG architecture on the CNN Explainer website.\n",
        "\n",
        "This is a regular practice in machine learning.\n",
        "\n",
        "Building multiple models and performing multiple training experiments to see which performs best.\n",
        "\n",
        "Let's combine our model results dictionaries into a DataFrame and find out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "XfiNBc9R8fUL",
        "outputId": "c9d2f907-c0c7-4c51-9c2d-b06d1d79df74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            model_name  model_loss  model_acc\n",
              "0  FashionMNISTModelV0    0.476639  83.426518\n",
              "1  FashionMNISTModelV1    0.685001  75.019968\n",
              "2  FashionMNISTModelV2    0.312930  88.638179"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9eb1110a-5bae-4ada-8e12-cb9af28c70e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_loss</th>\n",
              "      <th>model_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FashionMNISTModelV0</td>\n",
              "      <td>0.476639</td>\n",
              "      <td>83.426518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FashionMNISTModelV1</td>\n",
              "      <td>0.685001</td>\n",
              "      <td>75.019968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FashionMNISTModelV2</td>\n",
              "      <td>0.312930</td>\n",
              "      <td>88.638179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eb1110a-5bae-4ada-8e12-cb9af28c70e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9eb1110a-5bae-4ada-8e12-cb9af28c70e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9eb1110a-5bae-4ada-8e12-cb9af28c70e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76d08673-d2fd-436b-b83c-5edc0f466d4c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76d08673-d2fd-436b-b83c-5edc0f466d4c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76d08673-d2fd-436b-b83c-5edc0f466d4c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_54e08a7a-6f11-4388-a5ae-a36fbed73e19\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('compare_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_54e08a7a-6f11-4388-a5ae-a36fbed73e19 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('compare_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "compare_results",
              "summary": "{\n  \"name\": \"compare_results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FashionMNISTModelV0\",\n          \"FashionMNISTModelV1\",\n          \"FashionMNISTModelV2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18648156579580363,\n        \"min\": 0.31292983889579773,\n        \"max\": 0.6850008964538574,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.47663894295692444,\n          0.6850008964538574,\n          0.31292983889579773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.871282702742449,\n        \"min\": 75.01996805111821,\n        \"max\": 88.63817891373802,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          83.42651757188499,\n          75.01996805111821,\n          88.63817891373802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yql8Tvf8fUL"
      },
      "source": [
        "Nice!\n",
        "\n",
        "We can add the training time values too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ytO1O8zB8fUL",
        "outputId": "9b3f365f-6dda-4499-812e-bbe9ca46a7da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            model_name  model_loss  model_acc  training_time\n",
              "0  FashionMNISTModelV0    0.476639  83.426518      27.630151\n",
              "1  FashionMNISTModelV1    0.685001  75.019968      33.641891\n",
              "2  FashionMNISTModelV2    0.312930  88.638179      37.508124"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90972cf6-2413-4839-b19e-7204f7728188\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_loss</th>\n",
              "      <th>model_acc</th>\n",
              "      <th>training_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FashionMNISTModelV0</td>\n",
              "      <td>0.476639</td>\n",
              "      <td>83.426518</td>\n",
              "      <td>27.630151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FashionMNISTModelV1</td>\n",
              "      <td>0.685001</td>\n",
              "      <td>75.019968</td>\n",
              "      <td>33.641891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FashionMNISTModelV2</td>\n",
              "      <td>0.312930</td>\n",
              "      <td>88.638179</td>\n",
              "      <td>37.508124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90972cf6-2413-4839-b19e-7204f7728188')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90972cf6-2413-4839-b19e-7204f7728188 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90972cf6-2413-4839-b19e-7204f7728188');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7f586fa1-9fd5-4cb0-ae8f-7636d31ae574\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f586fa1-9fd5-4cb0-ae8f-7636d31ae574')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7f586fa1-9fd5-4cb0-ae8f-7636d31ae574 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5ea63f7d-8d62-4a1f-a9fe-a6b955e304c0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('compare_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5ea63f7d-8d62-4a1f-a9fe-a6b955e304c0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('compare_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "compare_results",
              "summary": "{\n  \"name\": \"compare_results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FashionMNISTModelV0\",\n          \"FashionMNISTModelV1\",\n          \"FashionMNISTModelV2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18648156579580363,\n        \"min\": 0.31292983889579773,\n        \"max\": 0.6850008964538574,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.47663894295692444,\n          0.6850008964538574,\n          0.31292983889579773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.871282702742449,\n        \"min\": 75.01996805111821,\n        \"max\": 88.63817891373802,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          83.42651757188499,\n          75.01996805111821,\n          88.63817891373802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"training_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.977669243041854,\n        \"min\": 27.63015072600001,\n        \"max\": 37.50812444000002,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          27.63015072600001,\n          33.64189093700003,\n          37.50812444000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Add training times to results comparison\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                    total_train_time_model_1,\n",
        "                                    total_train_time_model_2]\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrPb5pS8fUL"
      },
      "source": [
        "It looks like our CNN (`FashionMNISTModelV2`) model performed the best (lowest loss, highest accuracy) but had the longest training time.\n",
        "\n",
        "And our baseline model (`FashionMNISTModelV0`) performed better than `model_1` (`FashionMNISTModelV1`).\n",
        "\n",
        "### Performance-speed tradeoff\n",
        "\n",
        "Something to be aware of in machine learning is the **performance-speed** tradeoff.\n",
        "\n",
        "Generally, you get better performance out of a larger, more complex model (like we did with `model_2`).\n",
        "\n",
        "However, this performance increase often comes at a sacrifice of training speed and inference speed.\n",
        "\n",
        "> **Note:** The training times you get will be very dependent on the hardware you use.\n",
        ">\n",
        "> Generally, the more CPU cores you have, the faster your models will train on CPU. And similar for GPUs.\n",
        ">\n",
        "> Newer hardware (in terms of age) will also often train models faster due to incorporating technological advances.\n",
        "\n",
        "How about we get visual?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "cw0sIMRW8fUL",
        "outputId": "c4eff5d6-7752-4da6-a573-d8138522428e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize our model results\n",
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")  # Set 'model_name' as the index and plot 'model_acc' as a horizontal bar chart\n",
        "plt.xlabel(\"accuracy (%)\")  # Set the label for the x-axis to display accuracy in percentage\n",
        "plt.ylabel(\"model\")  # Set the label for the y-axis to display model names\n",
        "plt.title(\"Model Accuracy Comparison\")  # (Optional) Add a title to the plot for better context\n",
        "plt.tight_layout()  # (Optional) Adjust the layout to prevent clipping of labels\n",
        "plt.show()  # Display the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0ocwL0N8fUL"
      },
      "source": [
        "## 9. Make and evaluate random predictions with best model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK1wLjqh8fUL"
      },
      "source": [
        "\n",
        "Alright, we've compared our models to each other, let's further evaluate our best performing model, `model_2`.\n",
        "\n",
        "To do so, let's create a function `make_predictions()` where we can pass the model and some data for it to predict on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "GKUnseYU8fUL"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
        "    \"\"\"\n",
        "    Generates prediction probabilities for a given model and dataset.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Trained PyTorch model.\n",
        "        data (list): List of input data samples.\n",
        "        device (torch.device): Device to run the model on (e.g., 'cpu' or 'cuda').\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Tensor containing prediction probabilities for each input sample.\n",
        "    \"\"\"\n",
        "    pred_probs = []  # List to store prediction probabilities\n",
        "    model.eval()  # Set model to evaluation mode to disable dropout, batchnorm, etc.\n",
        "    with torch.inference_mode():  # Disable gradient calculation to save memory and computation\n",
        "        for sample in data:  # Iterate through each sample in the input data\n",
        "            # Prepare sample: add an extra batch dimension (unsqueeze) and move it to the specified device\n",
        "            sample = torch.unsqueeze(sample, dim=0).to(device)  # Unsqueeze is necessary because model expects a batch dimension\n",
        "\n",
        "            # Perform a forward pass through the model to get raw output logits\n",
        "            pred_logit = model(sample)\n",
        "\n",
        "            # Convert logits to probabilities using the softmax function\n",
        "            # Softmax is applied across the \"logits\" dimension (dim=0) since batch size is 1\n",
        "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "            # Move probabilities back to the CPU for further processing b/c libraries like numpy don't support GPU tensors\n",
        "            pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "    # Stack the list of prediction probabilities into a single tensor\n",
        "    return torch.stack(pred_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWPFsF3r8fUL",
        "outputId": "68cede76-764d-447d-8901-8ba674dc9019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sample image shape: torch.Size([1, 28, 28])\n",
            "Test sample label: 5 (Sandal)\n"
          ]
        }
      ],
      "source": [
        "import random  # Import the random module for random sampling\n",
        "\n",
        "random.seed(42)  # Set the random seed to ensure reproducibility of results\n",
        "\n",
        "test_samples = []  # Initialize an empty list to store selected test samples\n",
        "test_labels = []   # Initialize an empty list to store corresponding labels\n",
        "\n",
        "# Randomly select 9 (k=9) unique samples from the test_data\n",
        "for sample, label in random.sample(list(test_data), k=9):   # k=9 is a randomly selected number of samples from test dataset\n",
        "    test_samples.append(sample)  # Add the selected sample to the test_samples list\n",
        "    test_labels.append(label)    # Add the corresponding label to the test_labels list\n",
        "\n",
        "# Display the shape of the first test sample and its label with the class name\n",
        "print(\n",
        "    f\"Test sample image shape: {test_samples[0].shape}\\n\"\n",
        "    f\"Test sample label: {test_labels[0]} ({class_names[test_labels[0]]})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp6cFgiN8fUL"
      },
      "source": [
        "And now we can use our `make_predictions()` function to predict on `test_samples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLoiZ6yd8fUM",
        "outputId": "697e6ed0-b287-4001-cb51-27d7a1fe1a31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8.1303e-07, 7.9265e-08, 4.1449e-08, 3.3541e-08, 9.6054e-09, 9.9989e-01,\n",
              "         1.1818e-06, 2.2627e-06, 3.1423e-05, 7.1863e-05],\n",
              "        [1.4934e-01, 6.0926e-01, 3.2524e-03, 1.8190e-01, 3.8729e-02, 3.0554e-05,\n",
              "         1.6591e-02, 3.2708e-04, 4.2868e-05, 5.3429e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Make predictions on test samples with model 2\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                             data=test_samples)  # Invoke the make_predictions function using model_2 and the prepared test_samples\n",
        "\n",
        "# View first two prediction probabilities list\n",
        "pred_probs[:2]  # Retrieve and display the prediction probabilities for the first two test samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE_Fu5Af8fUM"
      },
      "source": [
        "Excellent!\n",
        "\n",
        "And now we can go from prediction probabilities to prediction labels by taking the `torch.argmax()` of the output of the `torch.softmax()` activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4GVcz-y8fUM",
        "outputId": "858f94b9-e08d-4c38-def7-c9e96d6a8b48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 1, 7, 4, 3, 0, 4, 7, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtkOsrPL8fUM",
        "outputId": "3e7d1517-8eb7-4420-a1fd-220b2b12831a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([5, 1, 7, 4, 3, 0, 4, 7, 1], tensor([5, 1, 7, 4, 3, 0, 4, 7, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Are our predictions in the same form as our test labels?\n",
        "test_labels, pred_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdRCkT_k8fUM"
      },
      "source": [
        "Now our predicted classes are in the same format as our test labels, we can compare.\n",
        "\n",
        "Since we're dealing with image data, let's stay true to the data explorer's motto.\n",
        "\n",
        "\"Visualize, visualize, visualize!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "YNFVVbiq8fUM",
        "outputId": "6b66a660-4e0e-42e6-e495-5e77d3060b3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9, 9))  # Initialize a new figure with a specified size of 9x9 inches\n",
        "nrows = 3  # Define the number of rows in the subplot grid\n",
        "ncols = 3  # Define the number of columns in the subplot grid\n",
        "\n",
        "for i, sample in enumerate(test_samples):  # Iterate over each test sample with its index. i starts from 0\n",
        "    # Create a subplot in the grid at position i+1\n",
        "    plt.subplot(nrows, ncols, i + 1)    # i+1 because indexing starts from 0\n",
        "\n",
        "    # Plot the target image\n",
        "    plt.imshow(sample.squeeze(), cmap=\"gray\")  # Display the image after removing any singleton dimensions and use a grayscale colormap\n",
        "\n",
        "    # Find the prediction label (in text form, e.g., \"Sandal\")\n",
        "    pred_label = class_names[pred_classes[i]]  # Map the predicted class index to its corresponding class name\n",
        "\n",
        "    # Get the truth label (in text form, e.g., \"T-shirt\")\n",
        "    truth_label = class_names[test_labels[i]]  # Map the true class index to its corresponding class name\n",
        "\n",
        "    # Create the title text of the plot\n",
        "    title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"  # Format the title to show both predicted and true labels\n",
        "\n",
        "    # Check for equality and change title color accordingly\n",
        "    if pred_label == truth_label:\n",
        "        plt.title(title_text, fontsize=10, c=\"g\")  # Set title with green color if prediction is correct\n",
        "    else:\n",
        "        plt.title(title_text, fontsize=10, c=\"r\")  # Set title with red color if prediction is incorrect\n",
        "\n",
        "    plt.axis(False)  # Hide the axis ticks and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT0Exj6L8fUM"
      },
      "source": [
        "Well, well, well, doesn't that look good!\n",
        "\n",
        "Not bad for a couple dozen lines of PyTorch code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qvW06Nx8fUM"
      },
      "source": [
        "## 10. Making a confusion matrix for further prediction evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2UE4il-8fUM"
      },
      "source": [
        "\n",
        "There are many [different evaluation metrics](https://www.learnpytorch.io/02_pytorch_classification/#9-more-classification-evaluation-metrics) we can use for classification problems.\n",
        "\n",
        "One of the most visual is a [confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/).\n",
        "\n",
        "A confusion matrix shows you where your classification model got confused between predictions and true labels.\n",
        "\n",
        "To make a confusion matrix, we'll go through three steps:\n",
        "1. Make predictions with our trained model, `model_2` (a confusion matrix compares predictions to true labels).\n",
        "2. Make a confusion matrix using [`torchmetrics.ConfusionMatrix`](https://torchmetrics.readthedocs.io/en/latest/references/modules.html?highlight=confusion#confusionmatrix).\n",
        "3. Plot the confusion matrix using [`mlxtend.plotting.plot_confusion_matrix()`](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/).\n",
        "\n",
        "Let's start by making predictions with our trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng6BRCsQ8fUM"
      },
      "source": [
        "### 10.1 Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "32db1b84061e4e218634ba021bc81481",
            "73e63981596b4babbebd7e18759f57cb",
            "7f50a6150d1d49c2b657e0d91dced714",
            "a63770aefd0547c7a717546140bde484",
            "2327683466df4f16b277cae05c74b618",
            "789f27bf9746414898c1370936895de2",
            "e8f72070a6454b25b5f91c90d3cbff81",
            "18bdc9633a9e453fb83ec588128cc2ca",
            "aa7c0f5e9ddb4efdb12a95045bcdbac4",
            "e677df5a5eca4e708a1f68447335eead",
            "9a8103b05c824003bd1243df2a8b77fd"
          ]
        },
        "id": "z-OAdXKE8fUM",
        "outputId": "90203c40-1045-409d-8262-6ab055bd1980"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Making predictions:   0%|          | 0/313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32db1b84061e4e218634ba021bc81481"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm  # tqdm.auto automatically selects the best progress bar format based on the environment\n",
        "\n",
        "# 1. Make predictions with trained model\n",
        "y_preds = []  # Initialize an empty list to store prediction results\n",
        "model_2.eval()  # Set the model to evaluation mode to disable dropout and other training-specific layers\n",
        "\n",
        "with torch.inference_mode():  # Disable gradient calculations for faster and memory-efficient inference\n",
        "    for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):  # Iterate over the test dataloader with a progress bar\n",
        "        # Send data and targets to target device\n",
        "        X, y = X.to(device), y.to(device)  # Move input features X and labels y to the specified device (CPU or GPU)\n",
        "\n",
        "        # Do the forward pass\n",
        "        y_logit = model_2(X)  # Perform a forward pass through model_2 to obtain raw output logits\n",
        "\n",
        "        # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
        "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
        "        # Apply softmax to convert logits to probabilities across the class dimension (dim=1)\n",
        "        # Then, use argmax to get the predicted class labels by selecting the index with the highest probability\n",
        "\n",
        "        # Put predictions on CPU for evaluation\n",
        "        y_preds.append(y_pred.cpu())  # Move the predicted labels to CPU and append them to the y_preds list\n",
        "\n",
        "# Concatenate list of predictions into a tensor\n",
        "y_pred_tensor = torch.cat(y_preds)  # Combine all prediction tensors in y_preds into a single tensor for further evaluation\n",
        "y_pred_tensor[:10]                  # Print the first 10 predicted labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_DLDGhN8fUM"
      },
      "source": [
        "### 10.2 torchmetrics and mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnsi69MN8fUM",
        "outputId": "e985e47c-951c-4cb8-b659-8cca183fb033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/926.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m727.0/926.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hmlxtend version: 0.23.3\n"
          ]
        }
      ],
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend  # Attempt to import the torchmetrics and mlxtend libraries\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")  # Print the currently installed version of mlxtend\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend version should be 0.19.0 or higher\"\n",
        "    # Ensure that the minor version of mlxtend is at least 19 (i.e., version 0.19.0 or higher)\n",
        "except:\n",
        "    %pip install -q torchmetrics -U mlxtend  # Install or upgrade torchmetrics and mlxtend quietly\n",
        "    # Note: If you're using Google Colab, installing packages may require restarting the runtime\n",
        "    import torchmetrics, mlxtend  # Re-import torchmetrics and mlxtend after installation\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")  # Print the updated version of mlxtend to confirm installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ughpA1DD8fUM"
      },
      "source": [
        "To plot the confusion matrix, we need to make sure we've got and [`mlxtend`](http://rasbt.github.io/mlxtend/) version of 0.19.0 or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYuQnxe78fUM",
        "outputId": "22b02c25-5cbf-4179-b2de-9c487676d37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23.3\n"
          ]
        }
      ],
      "source": [
        "# Import mlxtend upgraded version. This code makes sure mlxtend is at least version 0.19.0\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlaqjvvx8fUM"
      },
      "source": [
        "### 10.3 Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vjwAcfm8fUM"
      },
      "source": [
        "\n",
        "\n",
        "#### 1. How Does the `ConfusionMatrix` Instance Work?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRKlQI-F8fUM"
      },
      "source": [
        "\n",
        "- **Instance Behavior**:\n",
        "  - The `ConfusionMatrix` class from `torchmetrics` allows its instances to be callable because it implements a special method called `__call__`.\n",
        "  - When you write `confmat(preds=y_pred_tensor, target=test_data.targets)`, this internally invokes the `__call__` method of the `ConfusionMatrix` instance.\n",
        "\n",
        "- **Inputs to `__call__`**:\n",
        "  - `preds`: Predicted labels from your model.\n",
        "  - `target`: True labels from your dataset.\n",
        "  - The method processes these inputs to compute the confusion matrix.\n",
        "\n",
        "- **Documentation**:\n",
        "  - For more details, refer to the official [TorchMetrics ConfusionMatrix Documentation](https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html), which explains the input arguments and functionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc6fICic8fUM"
      },
      "source": [
        "\n",
        "#### 2. Setting Up and Plotting the Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypwyNnqJ8fUM"
      },
      "source": [
        "\n",
        "- **Imports**:\n",
        "  - `ConfusionMatrix` computes the confusion matrix for evaluating classification models.\n",
        "  - `plot_confusion_matrix` visualizes the confusion matrix.\n",
        "\n",
        "- **Steps**:\n",
        "  - A `ConfusionMatrix` instance is initialized with the number of classes (`num_classes`) and task type (`task='multiclass'`).\n",
        "  - The instance is called with `preds` and `target` to compute the confusion matrix tensor.\n",
        "  - The tensor is converted to a NumPy array and passed to `plot_confusion_matrix` for visualization.\n",
        "\n",
        "- **Documentation**:\n",
        "  - For more details, refer to the official [mlxtend `plot_confusion_matrix` Documentation](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oUIXl818fUM"
      },
      "source": [
        "\n",
        "#### 3. Importing and Verifying `mlxtend` Version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjH9ZVBC8fUM"
      },
      "source": [
        "\n",
        "- **Purpose**:\n",
        "  - Ensures compatibility with plotting features provided by `mlxtend`.\n",
        "  - The version is checked to ensure it is at least 0.19.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKudEG7z8fUM"
      },
      "source": [
        "#### Code Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "nZUFaalo8fUM",
        "outputId": "68c884b8-602d-402b-cf74-429030549cc6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torchmetrics import ConfusionMatrix  # Import the ConfusionMatrix class from torchmetrics\n",
        "from mlxtend.plotting import plot_confusion_matrix  # Import the plot_confusion_matrix function from mlxtend.plotting\n",
        "\n",
        "# Setup confusion matrix instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names),  # Specify the number of classes\n",
        "                          task='multiclass')  # Indicate that this is a multiclass classification problem\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,  # Compute the confusion matrix using predicted labels\n",
        "                         target=test_data.targets)  # Compare against true target labels\n",
        "\n",
        "# Plot the confusion matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(),  # Convert the confusion matrix tensor to a NumPy array for compatibility\n",
        "                                class_names=class_names,          # Provide class names for labeling axes of the confusion matrix\n",
        "                                figsize=(10, 7))                  # Set the figure size to 10 inches by 7 inches for better visualization\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dU29OYG8fUN"
      },
      "source": [
        "Woah! Doesn't that look good?\n",
        "\n",
        "We can see our model does fairly well since most of the dark squares are down the diagonal from top left to bottom right (and ideal model will have only values in these squares and 0 everywhere else).\n",
        "\n",
        "The model gets most \"confused\" on classes that are similar, for example predicting \"Pullover\" for images that are actually labelled \"Shirt\".\n",
        "\n",
        "And the same for predicting \"Shirt\" for classes that are actually labelled \"T-shirt/top\".\n",
        "\n",
        "This kind of information is often more helpful than a single accuracy metric because it tells use *where* a model is getting things wrong.\n",
        "\n",
        "It also hints at *why* the model may be getting certain things wrong.\n",
        "\n",
        "It's understandable the model sometimes predicts \"Shirt\" for images labelled \"T-shirt/top\".\n",
        "\n",
        "We can use this kind of information to further inspect our models and data to see how it could be improved.\n",
        "\n",
        "> **Exercise:** Use the trained `model_2` to make predictions on the test FashionMNIST dataset. Then plot some predictions where the model was wrong alongside what the label of the image should've been. After visualizing these predictions do you think it's more of a modelling error or a data error? As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcEIukSU8fUN"
      },
      "source": [
        "## 11. Save and load best performing model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxBe9x9V8fUN"
      },
      "source": [
        "\n",
        "Let's finish this section off by saving and loading in our best performing model.\n",
        "\n",
        "Recall from [notebook 01](https://www.learnpytorch.io/01_pytorch_workflow/#5-saving-and-loading-a-pytorch-model) we can save and load a PyTorch model using a combination of:\n",
        "* `torch.save` - a function to save a whole PyTorch model or a model's `state_dict()`.\n",
        "* `torch.load` - a function to load in a saved PyTorch object.\n",
        "* `torch.nn.Module.load_state_dict()` - a function to load a saved `state_dict()` into an existing model instance.\n",
        "\n",
        "You can see more of these three in the [PyTorch saving and loading models documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "\n",
        "For now, let's save our `model_2`'s `state_dict()` then load it back in and evaluate it to make sure the save and load went correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQZFc59L8fUN",
        "outputId": "a890a151-6740-4725-faf3-720232a8b6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/03_pytorch_computer_vision_model_2.pth\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path  # Import Path class from pathlib for handling filesystem paths\n",
        "\n",
        "# Create models directory (if it doesn't already exist)\n",
        "# Reference: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\n",
        "MODEL_PATH = Path(\"models\")  # Define the path for the models directory\n",
        "MODEL_PATH.mkdir(\n",
        "    parents=True,  # Create any necessary parent directories\n",
        "    exist_ok=True   # Do not raise an error if the directory already exists\n",
        ")\n",
        "\n",
        "# Define the name and full path for saving the model\n",
        "MODEL_NAME = \"03_pytorch_computer_vision_model_2.pth\"  # Name of the model file\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME  # Combine directory and filename to get full save path\n",
        "\n",
        "# Save the model's state dictionary to the specified path\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")  # Inform the user where the model is being saved\n",
        "torch.save(\n",
        "    obj=model_2.state_dict(),  # Extract the state dictionary (learned parameters) from model_2\n",
        "    f=MODEL_SAVE_PATH           # Specify the file path where the state dictionary will be saved\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya-bU_Gy8fUN"
      },
      "source": [
        "Now we've got a saved model `state_dict()` we can load it back in using a combination of `load_state_dict()` and `torch.load()`.\n",
        "\n",
        "Since we're using `load_state_dict()`, we'll need to create a new instance of `FashionMNISTModelV2()` with the same input parameters as our saved model `state_dict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLZWYmCE8fUN",
        "outputId": "26985543-0d73-4d5a-c5cf-b6b7b8ec02fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-01e1a5266d0e>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n"
          ]
        }
      ],
      "source": [
        "# Create a new instance of FashionMNISTModelV2 (the same class as our saved state_dict())\n",
        "# Note: loading model will error if the shapes here aren't the same as the saved version\n",
        "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                                    hidden_units=10, # try changing this to 128 and seeing what happens\n",
        "                                    output_shape=10)\n",
        "\n",
        "# Load in the saved state_dict()\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Send model to GPU\n",
        "loaded_model_2 = loaded_model_2.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-YVUUSh8fUN"
      },
      "source": [
        "And now we've got a loaded model we can evaluate it with `eval_model()` to make sure its parameters work similarly to `model_2` prior to saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YTSnrd18fUN",
        "outputId": "481faea4-176f-4e42-c476-26a219d9039a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.31292983889579773,\n",
              " 'model_acc': 88.63817891373802}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Evaluate loaded model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(\n",
        "    model=loaded_model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "loaded_model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "803pziRE8fUN"
      },
      "source": [
        "Do these results look the same as `model_2_results`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CsS-fXg8fUN",
        "outputId": "c11d9cb3-cacd-472d-9f54-c0d3e09bafb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.31292983889579773,\n",
              " 'model_acc': 88.63817891373802}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri6ulqVn8fUN"
      },
      "source": [
        "We can find out if two tensors are close to each other using `torch.isclose()` and passing in a tolerance level of closeness via the parameters `atol` (absolute tolerance) and `rtol` (relative tolerance).\n",
        "\n",
        "If our model's results are close, the output of `torch.isclose()` should be true."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q65s6qC_8fUN",
        "outputId": "3831d5b2-d931-4e69-9f7d-61643f4842c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Check to see if results are close to each other (if they are very far away, there may be an error)\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "              torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
        "              atol=1e-08, # absolute tolerance\n",
        "              rtol=0.0001) # relative tolerance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk7xg1Xa8fUN"
      },
      "source": [
        "## Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79SoXM58fUN"
      },
      "source": [
        "\n",
        "All of the exercises are focused on practicing the code in the sections above.\n",
        "\n",
        "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
        "\n",
        "All exercises should be completed using [device-agnostic code](https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code).\n",
        "\n",
        "**Resources:**\n",
        "* [Exercise template notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb)\n",
        "* [Example solutions notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/03_pytorch_computer_vision_exercise_solutions.ipynb) (try the exercises *before* looking at this)\n",
        "\n",
        "1. What are 3 areas in industry where computer vision is currently being used?\n",
        "2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find.\n",
        "3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those.\n",
        "4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "    * Upload your own example image using the \"upload\" button and see what happens in each layer of a CNN as your image passes through it.\n",
        "5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets.\n",
        "6. Visualize at least 5 different samples of the MNIST training dataset.\n",
        "7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`.\n",
        "8. Recreate `model_2` used in this notebook (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset.\n",
        "9. Train the model you built in exercise 8. on CPU and GPU and see how long it takes on each.\n",
        "10. Make predictions using your trained model and visualize at least 5 of them comparing the prediction to the target label.\n",
        "11. Plot a confusion matrix comparing your model's predictions to the truth labels.\n",
        "12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?\n",
        "13. Use a model similar to the trained `model_2` from this notebook to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "    * Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "    * After visualizing these predictions do you think it's more of a modelling error or a data error?\n",
        "    * As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?\n",
        "\n",
        "## Extra-curriculum\n",
        "* **Watch:** [MIT's Introduction to Deep Computer Vision](https://www.youtube.com/watch?v=iaSUYvmCekI&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=3) lecture. This will give you a great intuition behind convolutional neural networks.\n",
        "* Spend 10-minutes clicking through the different options of the [PyTorch vision library](https://pytorch.org/vision/stable/index.html), what different modules are available?\n",
        "* Lookup \"most common convolutional neural networks\", what architectures do you find? Are any of them contained within the [`torchvision.models`](https://pytorch.org/vision/stable/models.html) library? What do you think you could do with these?\n",
        "* For a large number of pretrained PyTorch computer vision models as well as many different extensions to PyTorch's computer vision functionalities check out the [PyTorch Image Models library `timm`](https://github.com/rwightman/pytorch-image-models/) (Torch Image Models) by Ross Wightman."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87f9c23c5cc0462097fae4365de26ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f08f1421d4b84a44b86ee429fc1259a0",
              "IPY_MODEL_a6d1862ff3d242aaad2819ddc3e4a6b9",
              "IPY_MODEL_94db0d40b8294b7e9513dd65ca1d29f1"
            ],
            "layout": "IPY_MODEL_549a3d3188364ee98d57faf6585a7389"
          }
        },
        "f08f1421d4b84a44b86ee429fc1259a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afe33f448a004b12807976a181980d3d",
            "placeholder": "​",
            "style": "IPY_MODEL_d6b40b425b824b97bc90e7c8a19ddb7a",
            "value": "Epochs: 100%"
          }
        },
        "a6d1862ff3d242aaad2819ddc3e4a6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa7b72b547614745bb206721e7728617",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34415457a256458a819486efa8accbed",
            "value": 3
          }
        },
        "94db0d40b8294b7e9513dd65ca1d29f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b6ae6ab9074b1782d5e2eaac0984b2",
            "placeholder": "​",
            "style": "IPY_MODEL_43cf24a0b3334a6c8a8001ae2de37b09",
            "value": " 3/3 [00:27&lt;00:00,  9.20s/it]"
          }
        },
        "549a3d3188364ee98d57faf6585a7389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe33f448a004b12807976a181980d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b40b425b824b97bc90e7c8a19ddb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa7b72b547614745bb206721e7728617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34415457a256458a819486efa8accbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0b6ae6ab9074b1782d5e2eaac0984b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43cf24a0b3334a6c8a8001ae2de37b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ffaa66bc057400486d70bc842ca88a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07f2e53ff753409d933310405fabe541",
              "IPY_MODEL_27bdc6862d92470fa95355ba78ed203a",
              "IPY_MODEL_5bf2ebae378f4f9594bf7627d3511caf"
            ],
            "layout": "IPY_MODEL_8cc1bde438bd4831a7afb163eec20db7"
          }
        },
        "07f2e53ff753409d933310405fabe541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7381dcb147491791787f3f795c974f",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f199600dcf45aa901e73340f1edd91",
            "value": "Training Epochs: 100%"
          }
        },
        "27bdc6862d92470fa95355ba78ed203a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddaa91cfc62a4a62bab8c292bd68a490",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49ce3ce1cf094a1bacfedad4e62c4d97",
            "value": 3
          }
        },
        "5bf2ebae378f4f9594bf7627d3511caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_588397756cf846c0acbe716171ad5b61",
            "placeholder": "​",
            "style": "IPY_MODEL_98fe13f15b434c819f14e8542260cb3d",
            "value": " 3/3 [00:33&lt;00:00, 11.22s/it]"
          }
        },
        "8cc1bde438bd4831a7afb163eec20db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7381dcb147491791787f3f795c974f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f199600dcf45aa901e73340f1edd91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddaa91cfc62a4a62bab8c292bd68a490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ce3ce1cf094a1bacfedad4e62c4d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "588397756cf846c0acbe716171ad5b61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fe13f15b434c819f14e8542260cb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc4f55a9fd4a4dfa849d905855608d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f741bdfd8d79480a83860b6264e76deb",
              "IPY_MODEL_be23dd80ee8240ea871f4956960b9461",
              "IPY_MODEL_9ad8e6897f3c4cf285fdc0637e715b36"
            ],
            "layout": "IPY_MODEL_6daacc8d48334140a4bd5944f828a515"
          }
        },
        "f741bdfd8d79480a83860b6264e76deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34482e6598e433fa04779c8b69920e3",
            "placeholder": "​",
            "style": "IPY_MODEL_6893d1c839e34fff9c471e5b82260d4b",
            "value": "100%"
          }
        },
        "be23dd80ee8240ea871f4956960b9461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e80c739b4c4875a00bc5845026b960",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04f624f7b381429eae976160008d28e3",
            "value": 3
          }
        },
        "9ad8e6897f3c4cf285fdc0637e715b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2827a62ca4e848168d4b91c79f2f00aa",
            "placeholder": "​",
            "style": "IPY_MODEL_3a99c2822bba457b94da64fe9c633c53",
            "value": " 3/3 [00:37&lt;00:00, 12.40s/it]"
          }
        },
        "6daacc8d48334140a4bd5944f828a515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34482e6598e433fa04779c8b69920e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6893d1c839e34fff9c471e5b82260d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e80c739b4c4875a00bc5845026b960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f624f7b381429eae976160008d28e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2827a62ca4e848168d4b91c79f2f00aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a99c2822bba457b94da64fe9c633c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32db1b84061e4e218634ba021bc81481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73e63981596b4babbebd7e18759f57cb",
              "IPY_MODEL_7f50a6150d1d49c2b657e0d91dced714",
              "IPY_MODEL_a63770aefd0547c7a717546140bde484"
            ],
            "layout": "IPY_MODEL_2327683466df4f16b277cae05c74b618"
          }
        },
        "73e63981596b4babbebd7e18759f57cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_789f27bf9746414898c1370936895de2",
            "placeholder": "​",
            "style": "IPY_MODEL_e8f72070a6454b25b5f91c90d3cbff81",
            "value": "Making predictions: 100%"
          }
        },
        "7f50a6150d1d49c2b657e0d91dced714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18bdc9633a9e453fb83ec588128cc2ca",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa7c0f5e9ddb4efdb12a95045bcdbac4",
            "value": 313
          }
        },
        "a63770aefd0547c7a717546140bde484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e677df5a5eca4e708a1f68447335eead",
            "placeholder": "​",
            "style": "IPY_MODEL_9a8103b05c824003bd1243df2a8b77fd",
            "value": " 313/313 [00:01&lt;00:00, 239.51it/s]"
          }
        },
        "2327683466df4f16b277cae05c74b618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "789f27bf9746414898c1370936895de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f72070a6454b25b5f91c90d3cbff81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18bdc9633a9e453fb83ec588128cc2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7c0f5e9ddb4efdb12a95045bcdbac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e677df5a5eca4e708a1f68447335eead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8103b05c824003bd1243df2a8b77fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}